[1/38] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/general_kernels.cu -o general_kernels.cuda.o 
[2/38] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/transform_kernels_new.cu -o transform_kernels_new.cuda.o 
[3/38] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/cublas_wrappers.cu -o cublas_wrappers.cuda.o 
[4/38] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/embedding_kernels.cu -o embedding_kernels.cuda.o 
[5/38] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/normalize_kernels.cu -o normalize_kernels.cuda.o 
[6/38] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/transform_kernels.cu -o transform_kernels.cuda.o 
[7/38] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/dropout_kernels.cu -o dropout_kernels.cuda.o 
/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/dropout_kernels.cu(1509): warning: variable "thread_cmax_out_grad" was declared but never referenced
          detected during instantiation of "void launch_ls_quant_dropout_act_bias_bwd<act_type,T>(T *, T *, T *, T *, const int8_t *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, int, float, cudaStream_t, __nv_bool) [with act_type=ActivationType::kRelu, T=float]" 
(1601): here

/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/dropout_kernels.cu(1513): warning: variable "temp_cmax_out_grad" was declared but never referenced
          detected during instantiation of "void launch_ls_quant_dropout_act_bias_bwd<act_type,T>(T *, T *, T *, T *, const int8_t *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, int, float, cudaStream_t, __nv_bool) [with act_type=ActivationType::kRelu, T=float]" 
(1601): here

/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/dropout_kernels.cu(1545): warning: variable "block_cmax_out_grad" was declared but never referenced
          detected during instantiation of "void launch_ls_quant_dropout_act_bias_bwd<act_type,T>(T *, T *, T *, T *, const int8_t *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, int, float, cudaStream_t, __nv_bool) [with act_type=ActivationType::kRelu, T=float]" 
(1601): here

/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/dropout_kernels.cu(1667): warning: variable "cmax_in_val" was declared but never referenced
          detected during:
            instantiation of "void ls_quant_dropout_act_bias_bwd_kernel<act_type,T>(T *, T *, T *, T *, const T *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, float, int) [with act_type=ActivationType::kRelu, T=float]" 
(1751): here
            instantiation of "void launch_ls_quant_dropout_act_bias_bwd<act_type,T>(T *, T *, T *, T *, const T *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, int, float, cudaStream_t) [with act_type=ActivationType::kRelu, T=float]" 
(1754): here

/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/dropout_kernels.cu(1667): warning: variable "cmax_in_val" was declared but never referenced
          detected during:
            instantiation of "void ls_quant_dropout_act_bias_bwd_kernel<act_type,T>(T *, T *, T *, T *, const T *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, float, int) [with act_type=ActivationType::kGelu, T=float]" 
(1751): here
            instantiation of "void launch_ls_quant_dropout_act_bias_bwd<act_type,T>(T *, T *, T *, T *, const T *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, int, float, cudaStream_t) [with act_type=ActivationType::kGelu, T=float]" 
(1770): here

[8/38] c++ -MMD -MF layer.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/layer.cpp -o layer.o 
[9/38] c++ -MMD -MF node.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/node.cpp -o node.o 
[10/38] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/softmax_kernels.cu -o softmax_kernels.cuda.o 
[11/38] c++ -MMD -MF context.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/context.cpp -o context.o 
[12/38] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/crf.cu -o crf.cuda.o 
[13/38] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/softmax_kernels_new.cu -o softmax_kernels_new.cuda.o 
[14/38] c++ -MMD -MF tensor.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/tensor.cpp -o tensor.o 
[15/38] c++ -MMD -MF manager.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/manager.cpp -o manager.o 
[16/38] c++ -MMD -MF bias_act_dropout.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/bias_act_dropout.cpp -o bias_act_dropout.o 
[17/38] c++ -MMD -MF bias_dropout_residual.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/bias_dropout_residual.cpp -o bias_dropout_residual.o 
[18/38] c++ -MMD -MF linear.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/linear.cpp -o linear.o 
[19/38] c++ -MMD -MF strided_batch_gemm.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/strided_batch_gemm.cpp -o strided_batch_gemm.o 
[20/38] c++ -MMD -MF layer_normalize.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/layer_normalize.cpp -o layer_normalize.o 
[21/38] c++ -MMD -MF bias_add_transform_20314.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/bias_add_transform_20314.cpp -o bias_add_transform_20314.o 
[22/38] c++ -MMD -MF dropout.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/dropout.cpp -o dropout.o 
[23/38] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/cross_entropy.cu -o cross_entropy.cuda.o 
[24/38] c++ -MMD -MF softmax.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/softmax.cpp -o softmax.o 
[25/38] c++ -MMD -MF launch_concat3_dim1.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/launch_concat3_dim1.cpp -o launch_concat3_dim1.o 
[26/38] c++ -MMD -MF transform_0213.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/transform_0213.cpp -o transform_0213.o 
[27/38] c++ -MMD -MF crf.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/crf.cpp -o crf.o 
[28/38] c++ -MMD -MF encdec_kv_layer.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/encdec_kv_layer.cpp -o encdec_kv_layer.o 
[29/38] c++ -MMD -MF transformer_encoder_layer.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/transformer_encoder_layer.cpp -o transformer_encoder_layer.o 
[30/38] c++ -MMD -MF feed_forward_layer.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/feed_forward_layer.cpp -o feed_forward_layer.o 
[31/38] c++ -MMD -MF multihead_attention_layer.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/multihead_attention_layer.cpp -o multihead_attention_layer.o 
[32/38] c++ -MMD -MF crf_layer.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/crf_layer.cpp -o crf_layer.o 
[33/38] c++ -MMD -MF dec_enc_attention_layer.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/dec_enc_attention_layer.cpp -o dec_enc_attention_layer.o 
[34/38] c++ -MMD -MF dec_self_attention_layer.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/dec_self_attention_layer.cpp -o dec_self_attention_layer.o 
[35/38] c++ -MMD -MF transformer_decoder_layer.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/transformer_decoder_layer.cpp -o transformer_decoder_layer.o 
[36/38] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/cuda_util.cu -o cuda_util.cuda.o 
[37/38] c++ -MMD -MF pybind_layer_new.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/pybind/pybind_layer_new.cpp -o pybind_layer_new.o 
[38/38] c++ cublas_wrappers.cuda.o transform_kernels.cuda.o transform_kernels_new.cuda.o dropout_kernels.cuda.o normalize_kernels.cuda.o softmax_kernels.cuda.o softmax_kernels_new.cuda.o general_kernels.cuda.o cuda_util.cuda.o embedding_kernels.cuda.o cross_entropy.cuda.o crf.cuda.o context.o layer.o manager.o node.o tensor.o bias_act_dropout.o bias_dropout_residual.o linear.o layer_normalize.o strided_batch_gemm.o bias_add_transform_20314.o dropout.o softmax.o launch_concat3_dim1.o transform_0213.o crf.o feed_forward_layer.o multihead_attention_layer.o transformer_encoder_layer.o dec_self_attention_layer.o encdec_kv_layer.o dec_enc_attention_layer.o transformer_decoder_layer.o crf_layer.o pybind_layer_new.o -shared -L/opt/conda/lib/python3.7/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda_cu -ltorch_cuda_cpp -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o lightseq_layers_new.so
Time to load lightseq_layers_new op: 51.821330070495605 seconds
[1/18] c++ -MMD -MF cublas_wrappers.o.d -DTORCH_EXTENSION_NAME=lightseq_layers -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/cublas_wrappers.cpp -o cublas_wrappers.o 
[2/18] c++ -MMD -MF cublas_algo_map.o.d -DTORCH_EXTENSION_NAME=lightseq_layers -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/cublas_algo_map.cpp -o cublas_algo_map.o 
[3/18] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/quantize_kernels.cu -o quantize_kernels.cuda.o 
[4/18] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/general_kernels.cu -o general_kernels.cuda.o 
[5/18] c++ -MMD -MF cross_entropy_layer.o.d -DTORCH_EXTENSION_NAME=lightseq_layers -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/cross_entropy_layer.cpp -o cross_entropy_layer.o 
[6/18] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/normalize_kernels.cu -o normalize_kernels.cuda.o 
[7/18] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/transform_kernels.cu -o transform_kernels.cuda.o 
[8/18] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/embedding_kernels.cu -o embedding_kernels.cuda.o 
[9/18] c++ -MMD -MF quant_linear_layer.o.d -DTORCH_EXTENSION_NAME=lightseq_layers -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/quant_linear_layer.cpp -o quant_linear_layer.o 
[10/18] c++ -MMD -MF transformer_embedding_layer.o.d -DTORCH_EXTENSION_NAME=lightseq_layers -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/transformer_embedding_layer.cpp -o transformer_embedding_layer.o 
[11/18] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/dropout_kernels.cu -o dropout_kernels.cuda.o 
/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/dropout_kernels.cu(1509): warning: variable "thread_cmax_out_grad" was declared but never referenced
          detected during instantiation of "void launch_ls_quant_dropout_act_bias_bwd<act_type,T>(T *, T *, T *, T *, const int8_t *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, int, float, cudaStream_t, __nv_bool) [with act_type=ActivationType::kRelu, T=float]" 
(1601): here

/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/dropout_kernels.cu(1513): warning: variable "temp_cmax_out_grad" was declared but never referenced
          detected during instantiation of "void launch_ls_quant_dropout_act_bias_bwd<act_type,T>(T *, T *, T *, T *, const int8_t *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, int, float, cudaStream_t, __nv_bool) [with act_type=ActivationType::kRelu, T=float]" 
(1601): here

/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/dropout_kernels.cu(1545): warning: variable "block_cmax_out_grad" was declared but never referenced
          detected during instantiation of "void launch_ls_quant_dropout_act_bias_bwd<act_type,T>(T *, T *, T *, T *, const int8_t *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, int, float, cudaStream_t, __nv_bool) [with act_type=ActivationType::kRelu, T=float]" 
(1601): here

/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/dropout_kernels.cu(1667): warning: variable "cmax_in_val" was declared but never referenced
          detected during:
            instantiation of "void ls_quant_dropout_act_bias_bwd_kernel<act_type,T>(T *, T *, T *, T *, const T *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, float, int) [with act_type=ActivationType::kRelu, T=float]" 
(1751): here
            instantiation of "void launch_ls_quant_dropout_act_bias_bwd<act_type,T>(T *, T *, T *, T *, const T *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, int, float, cudaStream_t) [with act_type=ActivationType::kRelu, T=float]" 
(1754): here

/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/dropout_kernels.cu(1667): warning: variable "cmax_in_val" was declared but never referenced
          detected during:
            instantiation of "void ls_quant_dropout_act_bias_bwd_kernel<act_type,T>(T *, T *, T *, T *, const T *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, float, int) [with act_type=ActivationType::kGelu, T=float]" 
(1751): here
            instantiation of "void launch_ls_quant_dropout_act_bias_bwd<act_type,T>(T *, T *, T *, T *, const T *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, int, float, cudaStream_t) [with act_type=ActivationType::kGelu, T=float]" 
(1770): here

[12/18] c++ -MMD -MF transformer_encoder_layer.o.d -DTORCH_EXTENSION_NAME=lightseq_layers -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/transformer_encoder_layer.cpp -o transformer_encoder_layer.o 
[13/18] c++ -MMD -MF transformer_decoder_layer.o.d -DTORCH_EXTENSION_NAME=lightseq_layers -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/transformer_decoder_layer.cpp -o transformer_decoder_layer.o 
[14/18] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/softmax_kernels.cu -o softmax_kernels.cuda.o 
[15/18] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/cross_entropy.cu -o cross_entropy.cuda.o 
[16/18] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/cuda_util.cu -o cuda_util.cuda.o 
[17/18] c++ -MMD -MF pybind_layer.o.d -DTORCH_EXTENSION_NAME=lightseq_layers -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/pybind/pybind_layer.cpp -o pybind_layer.o 
[18/18] c++ cublas_algo_map.o cublas_wrappers.o quantize_kernels.cuda.o transform_kernels.cuda.o dropout_kernels.cuda.o normalize_kernels.cuda.o softmax_kernels.cuda.o general_kernels.cuda.o cuda_util.cuda.o embedding_kernels.cuda.o cross_entropy.cuda.o cross_entropy_layer.o quant_linear_layer.o transformer_encoder_layer.o transformer_decoder_layer.o transformer_embedding_layer.o pybind_layer.o -shared -L/opt/conda/lib/python3.7/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda_cu -ltorch_cuda_cpp -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o lightseq_layers.so
Time to load lightseq_layers op: 40.46244215965271 seconds
Time to load lightseq_layers op: 0.035150766372680664 seconds
Time to load lightseq_layers op: 0.03729367256164551 seconds
Time to load lightseq_layers op: 0.0351412296295166 seconds
[1/14] c++ -MMD -MF gemm_test.o.d -DTORCH_EXTENSION_NAME=lightseq_kernels -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/gemm_test.cpp -o gemm_test.o 
[2/14] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_kernels -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/general_kernels.cu -o general_kernels.cuda.o 
[3/14] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_kernels -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/transform_kernels.cu -o transform_kernels.cuda.o 
[4/14] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_kernels -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/transform_kernels_new.cu -o transform_kernels_new.cuda.o 
[5/14] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_kernels -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/embedding_kernels.cu -o embedding_kernels.cuda.o 
[6/14] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_kernels -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/normalize_kernels.cu -o normalize_kernels.cuda.o 
[7/14] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_kernels -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/quantize_kernels.cu -o quantize_kernels.cuda.o 
[8/14] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_kernels -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/dropout_kernels.cu -o dropout_kernels.cuda.o 
/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/dropout_kernels.cu(1509): warning: variable "thread_cmax_out_grad" was declared but never referenced
          detected during instantiation of "void launch_ls_quant_dropout_act_bias_bwd<act_type,T>(T *, T *, T *, T *, const int8_t *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, int, float, cudaStream_t, __nv_bool) [with act_type=ActivationType::kRelu, T=float]" 
(1601): here

/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/dropout_kernels.cu(1513): warning: variable "temp_cmax_out_grad" was declared but never referenced
          detected during instantiation of "void launch_ls_quant_dropout_act_bias_bwd<act_type,T>(T *, T *, T *, T *, const int8_t *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, int, float, cudaStream_t, __nv_bool) [with act_type=ActivationType::kRelu, T=float]" 
(1601): here

/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/dropout_kernels.cu(1545): warning: variable "block_cmax_out_grad" was declared but never referenced
          detected during instantiation of "void launch_ls_quant_dropout_act_bias_bwd<act_type,T>(T *, T *, T *, T *, const int8_t *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, int, float, cudaStream_t, __nv_bool) [with act_type=ActivationType::kRelu, T=float]" 
(1601): here

/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/dropout_kernels.cu(1667): warning: variable "cmax_in_val" was declared but never referenced
          detected during:
            instantiation of "void ls_quant_dropout_act_bias_bwd_kernel<act_type,T>(T *, T *, T *, T *, const T *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, float, int) [with act_type=ActivationType::kRelu, T=float]" 
(1751): here
            instantiation of "void launch_ls_quant_dropout_act_bias_bwd<act_type,T>(T *, T *, T *, T *, const T *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, int, float, cudaStream_t) [with act_type=ActivationType::kRelu, T=float]" 
(1754): here

/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/dropout_kernels.cu(1667): warning: variable "cmax_in_val" was declared but never referenced
          detected during:
            instantiation of "void ls_quant_dropout_act_bias_bwd_kernel<act_type,T>(T *, T *, T *, T *, const T *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, float, int) [with act_type=ActivationType::kGelu, T=float]" 
(1751): here
            instantiation of "void launch_ls_quant_dropout_act_bias_bwd<act_type,T>(T *, T *, T *, T *, const T *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, int, float, cudaStream_t) [with act_type=ActivationType::kGelu, T=float]" 
(1770): here

[9/14] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_kernels -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/softmax_kernels.cu -o softmax_kernels.cuda.o 
[10/14] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_kernels -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/crf.cu -o crf.cuda.o 
[11/14] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_kernels -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/softmax_kernels_new.cu -o softmax_kernels_new.cuda.o 
[12/14] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_kernels -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/cuda_util.cu -o cuda_util.cuda.o 
[13/14] c++ -MMD -MF pybind_kernel.o.d -DTORCH_EXTENSION_NAME=lightseq_kernels -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/pybind/pybind_kernel.cpp -o pybind_kernel.o 
[14/14] c++ gemm_test.o cuda_util.cuda.o transform_kernels.cuda.o transform_kernels_new.cuda.o softmax_kernels.cuda.o softmax_kernels_new.cuda.o general_kernels.cuda.o normalize_kernels.cuda.o dropout_kernels.cuda.o embedding_kernels.cuda.o quantize_kernels.cuda.o crf.cuda.o pybind_kernel.o -shared -L/opt/conda/lib/python3.7/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda_cu -ltorch_cuda_cpp -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o lightseq_kernels.so
Time to load lightseq_kernels op: 39.44764256477356 seconds
2024-12-12 05:02:20 | INFO | fairseq_cli.train | Namespace(GCQ_quantile=0.99, activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='ls_transformer_wmt_en_de_big_t2t', attention_dropout=0.1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='ls_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/tmp/wmt14_en_de/', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=1024, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, enable_GCQ=False, enable_quant=False, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=True, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format='simple', log_interval=10, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=300, max_target_positions=300, max_tokens=4096, max_tokens_valid=4096, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=True, min_loss_scale=0.0001, min_lr=-1.0, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, optimizer='ls_adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_mode='qat', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0.05, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, use_torch_layer=False, user_dir='/opt/conda/lib/python3.7/site-packages/lightseq/training/cli/fs_modules', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none')
2024-12-12 05:02:20 | INFO | fairseq.tasks.translation | [en] dictionary: 40480 types
2024-12-12 05:02:20 | INFO | fairseq.tasks.translation | [de] dictionary: 42720 types
2024-12-12 05:02:20 | INFO | fairseq.data.data_utils | loaded 39414 examples from: /tmp/wmt14_en_de/valid.en-de.en
2024-12-12 05:02:20 | INFO | fairseq.data.data_utils | loaded 39414 examples from: /tmp/wmt14_en_de/valid.en-de.de
2024-12-12 05:02:20 | INFO | fairseq.tasks.translation | /tmp/wmt14_en_de/ valid en-de 39414 examples
Initial Context, status_type: Training
Embedding layer #0 is created with date type [half].
Embedding layer #1 is created with date type [half].
Get igemm config from /home/mwm2166/.lightseq/igemm_configs/
[WARNING] /home/mwm2166/.lightseq/igemm_configs/ is not found; using default GEMM algo
Encoder layer #0 allocate shared memory size: 40632320
Encoder layer #0 allocate shared quant memory size: 25165824
Encoder layer #0 is created with date type [half].
Get igemm config from /home/mwm2166/.lightseq/igemm_configs/
[WARNING] /home/mwm2166/.lightseq/igemm_configs/ is not found; using default GEMM algo
Encoder layer #1 is created with date type [half].
Get igemm config from /home/mwm2166/.lightseq/igemm_configs/
[WARNING] /home/mwm2166/.lightseq/igemm_configs/ is not found; using default GEMM algo
Encoder layer #2 is created with date type [half].
Get igemm config from /home/mwm2166/.lightseq/igemm_configs/
[WARNING] /home/mwm2166/.lightseq/igemm_configs/ is not found; using default GEMM algo
Encoder layer #3 is created with date type [half].
Get igemm config from /home/mwm2166/.lightseq/igemm_configs/
[WARNING] /home/mwm2166/.lightseq/igemm_configs/ is not found; using default GEMM algo
Encoder layer #4 is created with date type [half].
Get igemm config from /home/mwm2166/.lightseq/igemm_configs/
[WARNING] /home/mwm2166/.lightseq/igemm_configs/ is not found; using default GEMM algo
Encoder layer #5 is created with date type [half].
Get igemm config from /home/mwm2166/.lightseq/igemm_configs/
[WARNING] /home/mwm2166/.lightseq/igemm_configs/ is not found; using default GEMM algo
Decoder layer #0 allocate shared memory size: 40632320
Decoder layer #0 allocate shared quant memory size: 25165824
Decoder layer #0 is created with date type [half].
Get igemm config from /home/mwm2166/.lightseq/igemm_configs/
[WARNING] /home/mwm2166/.lightseq/igemm_configs/ is not found; using default GEMM algo
Decoder layer #1 is created with date type [half].
Get igemm config from /home/mwm2166/.lightseq/igemm_configs/
[WARNING] /home/mwm2166/.lightseq/igemm_configs/ is not found; using default GEMM algo
Decoder layer #2 is created with date type [half].
Get igemm config from /home/mwm2166/.lightseq/igemm_configs/
[WARNING] /home/mwm2166/.lightseq/igemm_configs/ is not found; using default GEMM algo
Decoder layer #3 is created with date type [half].
Get igemm config from /home/mwm2166/.lightseq/igemm_configs/
[WARNING] /home/mwm2166/.lightseq/igemm_configs/ is not found; using default GEMM algo
Decoder layer #4 is created with date type [half].
Get igemm config from /home/mwm2166/.lightseq/igemm_configs/
[WARNING] /home/mwm2166/.lightseq/igemm_configs/ is not found; using default GEMM algo
Decoder layer #5 is created with date type [half].
QuantLinearLayer is created with date type [half].
CrossEntropyLayer is created with date type [half].
Lightseq Transformer config is  {'max_batch_tokens': 4096, 'max_seq_len': 300, 'hidden_size': 1024, 'intermediate_size': 4096, 'nhead': 16, 'attn_prob_dropout_ratio': 0.1, 'activation_dropout_ratio': 0.1, 'hidden_dropout_ratio': 0.3, 'pre_layer_norm': True, 'fp16': True, 'local_rank': 0, 'activation_fn': 'relu', 'layer_id': 0}
Lightseq Transformer config is  {'max_batch_tokens': 4096, 'max_seq_len': 300, 'hidden_size': 1024, 'intermediate_size': 4096, 'nhead': 16, 'attn_prob_dropout_ratio': 0.1, 'activation_dropout_ratio': 0.1, 'hidden_dropout_ratio': 0.3, 'pre_layer_norm': True, 'fp16': True, 'local_rank': 0, 'activation_fn': 'relu', 'layer_id': 1}
Lightseq Transformer config is  {'max_batch_tokens': 4096, 'max_seq_len': 300, 'hidden_size': 1024, 'intermediate_size': 4096, 'nhead': 16, 'attn_prob_dropout_ratio': 0.1, 'activation_dropout_ratio': 0.1, 'hidden_dropout_ratio': 0.3, 'pre_layer_norm': True, 'fp16': True, 'local_rank': 0, 'activation_fn': 'relu', 'layer_id': 2}
Lightseq Transformer config is  {'max_batch_tokens': 4096, 'max_seq_len': 300, 'hidden_size': 1024, 'intermediate_size': 4096, 'nhead': 16, 'attn_prob_dropout_ratio': 0.1, 'activation_dropout_ratio': 0.1, 'hidden_dropout_ratio': 0.3, 'pre_layer_norm': True, 'fp16': True, 'local_rank': 0, 'activation_fn': 'relu', 'layer_id': 3}
Lightseq Transformer config is  {'max_batch_tokens': 4096, 'max_seq_len': 300, 'hidden_size': 1024, 'intermediate_size': 4096, 'nhead': 16, 'attn_prob_dropout_ratio': 0.1, 'activation_dropout_ratio': 0.1, 'hidden_dropout_ratio': 0.3, 'pre_layer_norm': True, 'fp16': True, 'local_rank': 0, 'activation_fn': 'relu', 'layer_id': 4}
Lightseq Transformer config is  {'max_batch_tokens': 4096, 'max_seq_len': 300, 'hidden_size': 1024, 'intermediate_size': 4096, 'nhead': 16, 'attn_prob_dropout_ratio': 0.1, 'activation_dropout_ratio': 0.1, 'hidden_dropout_ratio': 0.3, 'pre_layer_norm': True, 'fp16': True, 'local_rank': 0, 'activation_fn': 'relu', 'layer_id': 5}
Lightseq Transformer config is  {'max_batch_tokens': 4096, 'max_seq_len': 300, 'hidden_size': 1024, 'intermediate_size': 4096, 'nhead': 16, 'attn_prob_dropout_ratio': 0.1, 'activation_dropout_ratio': 0.1, 'hidden_dropout_ratio': 0.3, 'pre_layer_norm': True, 'fp16': True, 'local_rank': 0, 'nlayer': 6, 'activation_fn': 'relu', 'has_cross_attn': True, 'layer_id': 0}
Lightseq Transformer config is  {'max_batch_tokens': 4096, 'max_seq_len': 300, 'hidden_size': 1024, 'intermediate_size': 4096, 'nhead': 16, 'attn_prob_dropout_ratio': 0.1, 'activation_dropout_ratio': 0.1, 'hidden_dropout_ratio': 0.3, 'pre_layer_norm': True, 'fp16': True, 'local_rank': 0, 'nlayer': 6, 'activation_fn': 'relu', 'has_cross_attn': True, 'layer_id': 1}
Lightseq Transformer config is  {'max_batch_tokens': 4096, 'max_seq_len': 300, 'hidden_size': 1024, 'intermediate_size': 4096, 'nhead': 16, 'attn_prob_dropout_ratio': 0.1, 'activation_dropout_ratio': 0.1, 'hidden_dropout_ratio': 0.3, 'pre_layer_norm': True, 'fp16': True, 'local_rank': 0, 'nlayer': 6, 'activation_fn': 'relu', 'has_cross_attn': True, 'layer_id': 2}
Lightseq Transformer config is  {'max_batch_tokens': 4096, 'max_seq_len': 300, 'hidden_size': 1024, 'intermediate_size': 4096, 'nhead': 16, 'attn_prob_dropout_ratio': 0.1, 'activation_dropout_ratio': 0.1, 'hidden_dropout_ratio': 0.3, 'pre_layer_norm': True, 'fp16': True, 'local_rank': 0, 'nlayer': 6, 'activation_fn': 'relu', 'has_cross_attn': True, 'layer_id': 3}
Lightseq Transformer config is  {'max_batch_tokens': 4096, 'max_seq_len': 300, 'hidden_size': 1024, 'intermediate_size': 4096, 'nhead': 16, 'attn_prob_dropout_ratio': 0.1, 'activation_dropout_ratio': 0.1, 'hidden_dropout_ratio': 0.3, 'pre_layer_norm': True, 'fp16': True, 'local_rank': 0, 'nlayer': 6, 'activation_fn': 'relu', 'has_cross_attn': True, 'layer_id': 4}
Lightseq Transformer config is  {'max_batch_tokens': 4096, 'max_seq_len': 300, 'hidden_size': 1024, 'intermediate_size': 4096, 'nhead': 16, 'attn_prob_dropout_ratio': 0.1, 'activation_dropout_ratio': 0.1, 'hidden_dropout_ratio': 0.3, 'pre_layer_norm': True, 'fp16': True, 'local_rank': 0, 'nlayer': 6, 'activation_fn': 'relu', 'has_cross_attn': True, 'layer_id': 5}
Time to load lightseq_layers op: 0.05022263526916504 seconds
Time to load lightseq_layers op: 0.03931832313537598 seconds
2024-12-12 05:02:22 | INFO | fairseq_cli.train | LSTransformerModel(
  (encoder): LSTransformerEncoder(
    (embed_tokens): LSTransformerEmbeddingLayer()
    (layers): ModuleList(
      (0): LSTransformerEncoderLayer()
      (1): LSTransformerEncoderLayer()
      (2): LSTransformerEncoderLayer()
      (3): LSTransformerEncoderLayer()
      (4): LSTransformerEncoderLayer()
      (5): LSTransformerEncoderLayer()
    )
    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): LSTransformerDecoder(
    (embed_tokens): LSTransformerEmbeddingLayer()
    (layers): ModuleList(
      (0): LSFSTransformerDecoderLayer()
      (1): LSFSTransformerDecoderLayer()
      (2): LSFSTransformerDecoderLayer()
      (3): LSFSTransformerDecoderLayer()
      (4): LSFSTransformerDecoderLayer()
      (5): LSFSTransformerDecoderLayer()
    )
    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (output_projection): LSQuantLinearLayer()
  )
)
2024-12-12 05:02:22 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2024-12-12 05:02:22 | INFO | fairseq_cli.train | model: ls_transformer_wmt_en_de_big_t2t (LSTransformerModel)
2024-12-12 05:02:22 | INFO | fairseq_cli.train | criterion: ls_label_smoothed_cross_entropy (LSLabelSmoothedCrossEntropyCriterion)
2024-12-12 05:02:22 | INFO | fairseq_cli.train | num. model params: 261558490 (num. trained: 261558490)
2024-12-12 05:02:23 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-12-12 05:02:23 | INFO | fairseq.utils | rank   0: capabilities =  7.0  ; total memory = 15.782 GB ; name = Tesla V100-SXM2-16GB                    
2024-12-12 05:02:23 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-12-12 05:02:23 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2024-12-12 05:02:23 | INFO | fairseq_cli.train | max tokens per GPU = 4096 and max sentences per GPU = None
2024-12-12 05:02:23 | INFO | fairseq.trainer | no existing checkpoint found checkpoints/checkpoint_last.pt
2024-12-12 05:02:23 | INFO | fairseq.trainer | loading train data for epoch 1
2024-12-12 05:02:23 | INFO | fairseq.data.data_utils | loaded 3900502 examples from: /tmp/wmt14_en_de/train.en-de.en
2024-12-12 05:02:23 | INFO | fairseq.data.data_utils | loaded 3900502 examples from: /tmp/wmt14_en_de/train.en-de.de
2024-12-12 05:02:23 | INFO | fairseq.tasks.translation | /tmp/wmt14_en_de/ train en-de 3900502 examples
2024-12-12 05:02:27 | INFO | fs_modules.ls_adam | using LightSeq Adam
[1/3] c++ -MMD -MF pybind_adam.o.d -DTORCH_EXTENSION_NAME=adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/pybind/pybind_adam.cpp -o pybind_adam.o 
[2/3] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/fused_adam_kernel.cu -o fused_adam_kernel.cuda.o 
[3/3] c++ fused_adam_kernel.cuda.o pybind_adam.o -shared -L/opt/conda/lib/python3.7/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda_cu -ltorch_cuda_cpp -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o adam.so
Time to load adam op: 55.97872447967529 seconds
2024-12-12 05:03:23 | INFO | fairseq.trainer | begin training epoch 1
TransformerEmbeddingLayer #0 bind weights and grads.
TransformerEncoderLayer #0 bind weights and grads.
TransformerEncoderLayer #1 bind weights and grads.
TransformerEncoderLayer #2 bind weights and grads.
TransformerEncoderLayer #3 bind weights and grads.
TransformerEncoderLayer #4 bind weights and grads.
TransformerEncoderLayer #5 bind weights and grads.
TransformerEmbeddingLayer #1 bind weights and grads.
TransformerDecoderLayer #0 bind weights and grads.
Decoder layer #0 allocate encdec_kv memory
TransformerDecoderLayer #1 bind weights and grads.
TransformerDecoderLayer #2 bind weights and grads.
TransformerDecoderLayer #3 bind weights and grads.
TransformerDecoderLayer #4 bind weights and grads.
TransformerDecoderLayer #5 bind weights and grads.
2024-12-12 05:03:23 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 64.0
2024-12-12 05:03:24 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2024-12-12 05:03:24 | INFO | train_inner | epoch 001:     12 / 31388 loss=25.668, nll_loss=25.669, ppl=5.33668e+07, wps=33031.8, ups=8.91, wpb=3702.3, bsz=105.6, num_updates=10, lr=1.25e-06, gnorm=13.826, loss_scale=32, train_wall=1, wall=61
2024-12-12 05:03:25 | INFO | train_inner | epoch 001:     22 / 31388 loss=25.371, nll_loss=25.373, ppl=4.34635e+07, wps=36584.4, ups=9.71, wpb=3769.2, bsz=111.2, num_updates=20, lr=2.5e-06, gnorm=14.376, loss_scale=32, train_wall=1, wall=62
2024-12-12 05:03:26 | INFO | train_inner | epoch 001:     32 / 31388 loss=23.725, nll_loss=23.721, ppl=1.38228e+07, wps=36058.8, ups=9.69, wpb=3722.4, bsz=175.2, num_updates=30, lr=3.75e-06, gnorm=15.187, loss_scale=32, train_wall=1, wall=63
2024-12-12 05:03:27 | INFO | train_inner | epoch 001:     42 / 31388 loss=20.61, nll_loss=20.6, ppl=1.58888e+06, wps=35605.6, ups=9.62, wpb=3701.6, bsz=135.2, num_updates=40, lr=5e-06, gnorm=14.467, loss_scale=32, train_wall=1, wall=64
2024-12-12 05:03:28 | INFO | train_inner | epoch 001:     52 / 31388 loss=17.037, nll_loss=17.016, ppl=132508, wps=36086.8, ups=9.8, wpb=3682.3, bsz=108, num_updates=50, lr=6.25e-06, gnorm=6.407, loss_scale=32, train_wall=1, wall=65
2024-12-12 05:03:29 | INFO | train_inner | epoch 001:     62 / 31388 loss=15.942, nll_loss=15.891, ppl=60775.3, wps=36931.5, ups=9.53, wpb=3876, bsz=146.4, num_updates=60, lr=7.5e-06, gnorm=3.373, loss_scale=32, train_wall=1, wall=67
2024-12-12 05:03:30 | INFO | train_inner | epoch 001:     72 / 31388 loss=15.514, nll_loss=15.429, ppl=44118.2, wps=36958.6, ups=9.68, wpb=3820, bsz=119.2, num_updates=70, lr=8.75e-06, gnorm=2.632, loss_scale=32, train_wall=1, wall=68
2024-12-12 05:03:31 | INFO | train_inner | epoch 001:     82 / 31388 loss=15.13, nll_loss=15.001, ppl=32780.3, wps=35697.8, ups=9.56, wpb=3735.8, bsz=134.4, num_updates=80, lr=1e-05, gnorm=2.344, loss_scale=32, train_wall=1, wall=69
2024-12-12 05:03:32 | INFO | train_inner | epoch 001:     92 / 31388 loss=14.809, nll_loss=14.641, ppl=25549.9, wps=37572.7, ups=9.73, wpb=3859.6, bsz=102.4, num_updates=90, lr=1.125e-05, gnorm=1.92, loss_scale=32, train_wall=1, wall=70
2024-12-12 05:03:33 | INFO | train_inner | epoch 001:    102 / 31388 loss=14.424, nll_loss=14.211, ppl=18962.7, wps=36717.8, ups=9.73, wpb=3772.8, bsz=136, num_updates=100, lr=1.25e-05, gnorm=1.764, loss_scale=32, train_wall=1, wall=71
2024-12-12 05:03:34 | INFO | train_inner | epoch 001:    112 / 31388 loss=14.139, nll_loss=13.895, ppl=15231.2, wps=37108.8, ups=9.76, wpb=3803.3, bsz=113.6, num_updates=110, lr=1.375e-05, gnorm=1.488, loss_scale=32, train_wall=1, wall=72
2024-12-12 05:03:35 | INFO | train_inner | epoch 001:    122 / 31388 loss=13.75, nll_loss=13.465, ppl=11308.5, wps=36264.4, ups=9.6, wpb=3777.6, bsz=162.4, num_updates=120, lr=1.5e-05, gnorm=1.6, loss_scale=32, train_wall=1, wall=73
2024-12-12 05:03:36 | INFO | train_inner | epoch 001:    132 / 31388 loss=13.555, nll_loss=13.249, ppl=9735.3, wps=38156.2, ups=9.9, wpb=3852.8, bsz=129.6, num_updates=130, lr=1.625e-05, gnorm=1.288, loss_scale=32, train_wall=1, wall=74
2024-12-12 05:03:37 | INFO | train_inner | epoch 001:    142 / 31388 loss=13.297, nll_loss=12.964, ppl=7987.74, wps=34914.3, ups=9.73, wpb=3587.7, bsz=148, num_updates=140, lr=1.75e-05, gnorm=1.332, loss_scale=32, train_wall=1, wall=75
2024-12-12 05:03:38 | INFO | train_inner | epoch 001:    152 / 31388 loss=13.175, nll_loss=12.829, ppl=7275.64, wps=36953.7, ups=9.75, wpb=3791.9, bsz=115.2, num_updates=150, lr=1.875e-05, gnorm=1.257, loss_scale=32, train_wall=1, wall=76
2024-12-12 05:03:39 | INFO | train_inner | epoch 001:    162 / 31388 loss=12.988, nll_loss=12.62, ppl=6297.03, wps=36631.5, ups=9.64, wpb=3800.2, bsz=110.4, num_updates=160, lr=2e-05, gnorm=1.082, loss_scale=32, train_wall=1, wall=77
2024-12-12 05:03:40 | INFO | train_inner | epoch 001:    172 / 31388 loss=12.776, nll_loss=12.383, ppl=5342.03, wps=37880.3, ups=9.59, wpb=3948.9, bsz=136, num_updates=170, lr=2.125e-05, gnorm=1.156, loss_scale=32, train_wall=1, wall=78
2024-12-12 05:03:41 | INFO | train_inner | epoch 001:    182 / 31388 loss=12.639, nll_loss=12.227, ppl=4794.54, wps=34899.5, ups=9.57, wpb=3647.1, bsz=126.4, num_updates=180, lr=2.25e-05, gnorm=1.142, loss_scale=32, train_wall=1, wall=79
2024-12-12 05:03:43 | INFO | train_inner | epoch 001:    192 / 31388 loss=12.507, nll_loss=12.078, ppl=4322.77, wps=36381.1, ups=9.69, wpb=3753.6, bsz=140.8, num_updates=190, lr=2.375e-05, gnorm=1.057, loss_scale=32, train_wall=1, wall=80
2024-12-12 05:03:44 | INFO | train_inner | epoch 001:    202 / 31388 loss=12.384, nll_loss=11.936, ppl=3919.34, wps=37160, ups=9.5, wpb=3912.8, bsz=144.8, num_updates=200, lr=2.5e-05, gnorm=1.107, loss_scale=32, train_wall=1, wall=81
2024-12-12 05:03:45 | INFO | train_inner | epoch 001:    212 / 31388 loss=12.252, nll_loss=11.786, ppl=3532.53, wps=36268.6, ups=9.52, wpb=3809.7, bsz=138.4, num_updates=210, lr=2.625e-05, gnorm=1.1, loss_scale=32, train_wall=1, wall=82
2024-12-12 05:03:46 | INFO | train_inner | epoch 001:    222 / 31388 loss=12.006, nll_loss=11.502, ppl=2899.78, wps=36116.9, ups=9.4, wpb=3843.2, bsz=220, num_updates=220, lr=2.75e-05, gnorm=1.59, loss_scale=32, train_wall=1, wall=83
2024-12-12 05:03:47 | INFO | train_inner | epoch 001:    232 / 31388 loss=12.101, nll_loss=11.607, ppl=3120.13, wps=36435.4, ups=10.05, wpb=3625.6, bsz=102.4, num_updates=230, lr=2.875e-05, gnorm=0.978, loss_scale=32, train_wall=1, wall=84
2024-12-12 05:03:48 | INFO | train_inner | epoch 001:    242 / 31388 loss=12.002, nll_loss=11.491, ppl=2877.86, wps=36736.8, ups=9.52, wpb=3857.4, bsz=132, num_updates=240, lr=3e-05, gnorm=0.969, loss_scale=32, train_wall=1, wall=85
2024-12-12 05:03:49 | INFO | train_inner | epoch 001:    252 / 31388 loss=11.932, nll_loss=11.403, ppl=2708.44, wps=35245.9, ups=9.41, wpb=3744.8, bsz=141.6, num_updates=250, lr=3.125e-05, gnorm=1.072, loss_scale=32, train_wall=1, wall=86
2024-12-12 05:03:50 | INFO | train_inner | epoch 001:    262 / 31388 loss=11.82, nll_loss=11.275, ppl=2478.03, wps=37191.5, ups=9.61, wpb=3871.3, bsz=156.8, num_updates=260, lr=3.25e-05, gnorm=1.312, loss_scale=32, train_wall=1, wall=87
2024-12-12 05:03:51 | INFO | train_inner | epoch 001:    272 / 31388 loss=11.941, nll_loss=11.397, ppl=2696.23, wps=33813.5, ups=9.57, wpb=3532.4, bsz=124.8, num_updates=270, lr=3.375e-05, gnorm=1.039, loss_scale=32, train_wall=1, wall=88
2024-12-12 05:03:52 | INFO | train_inner | epoch 001:    282 / 31388 loss=11.739, nll_loss=11.173, ppl=2308.66, wps=36433.4, ups=9.51, wpb=3832, bsz=116, num_updates=280, lr=3.5e-05, gnorm=0.77, loss_scale=32, train_wall=1, wall=89
2024-12-12 05:03:53 | INFO | train_inner | epoch 001:    292 / 31388 loss=11.728, nll_loss=11.156, ppl=2281.66, wps=37734.7, ups=9.77, wpb=3863, bsz=118.4, num_updates=290, lr=3.625e-05, gnorm=0.885, loss_scale=32, train_wall=1, wall=90
2024-12-12 05:03:54 | INFO | train_inner | epoch 001:    302 / 31388 loss=11.538, nll_loss=10.93, ppl=1951.62, wps=35924, ups=9.48, wpb=3787.8, bsz=184, num_updates=300, lr=3.75e-05, gnorm=1.528, loss_scale=32, train_wall=1, wall=91
2024-12-12 05:03:55 | INFO | train_inner | epoch 001:    312 / 31388 loss=11.712, nll_loss=11.126, ppl=2235.11, wps=36055.8, ups=9.65, wpb=3735, bsz=91.2, num_updates=310, lr=3.875e-05, gnorm=0.982, loss_scale=32, train_wall=1, wall=92
2024-12-12 05:03:56 | INFO | train_inner | epoch 001:    322 / 31388 loss=11.679, nll_loss=11.089, ppl=2178.04, wps=35250.1, ups=9.67, wpb=3644.8, bsz=110.4, num_updates=320, lr=4e-05, gnorm=0.828, loss_scale=32, train_wall=1, wall=93
2024-12-12 05:03:57 | INFO | train_inner | epoch 001:    332 / 31388 loss=11.651, nll_loss=11.05, ppl=2119.84, wps=35233, ups=9.62, wpb=3661.2, bsz=92, num_updates=330, lr=4.125e-05, gnorm=0.973, loss_scale=32, train_wall=1, wall=95
2024-12-12 05:03:58 | INFO | train_inner | epoch 001:    342 / 31388 loss=11.758, nll_loss=11.167, ppl=2299.25, wps=35762.4, ups=9.73, wpb=3675.1, bsz=90.4, num_updates=340, lr=4.25e-05, gnorm=1.069, loss_scale=32, train_wall=1, wall=96
2024-12-12 05:03:59 | INFO | train_inner | epoch 001:    352 / 31388 loss=11.669, nll_loss=11.069, ppl=2147.73, wps=35172.2, ups=9.96, wpb=3531.1, bsz=88.8, num_updates=350, lr=4.375e-05, gnorm=0.835, loss_scale=32, train_wall=1, wall=97
2024-12-12 05:04:00 | INFO | train_inner | epoch 001:    362 / 31388 loss=11.422, nll_loss=10.781, ppl=1759.51, wps=34508.8, ups=9.4, wpb=3669.6, bsz=192, num_updates=360, lr=4.5e-05, gnorm=1.069, loss_scale=32, train_wall=1, wall=98
2024-12-12 05:04:01 | INFO | train_inner | epoch 001:    372 / 31388 loss=11.589, nll_loss=10.967, ppl=2002.38, wps=36630.6, ups=9.88, wpb=3708.8, bsz=125.6, num_updates=370, lr=4.625e-05, gnorm=1.001, loss_scale=32, train_wall=1, wall=99
2024-12-12 05:04:02 | INFO | train_inner | epoch 001:    382 / 31388 loss=11.518, nll_loss=10.889, ppl=1896.32, wps=36863.2, ups=9.64, wpb=3825.8, bsz=120, num_updates=380, lr=4.75e-05, gnorm=1.135, loss_scale=32, train_wall=1, wall=100
2024-12-12 05:04:03 | INFO | train_inner | epoch 001:    392 / 31388 loss=11.495, nll_loss=10.862, ppl=1860.86, wps=35771.6, ups=9.62, wpb=3719.2, bsz=108.8, num_updates=390, lr=4.875e-05, gnorm=1.016, loss_scale=32, train_wall=1, wall=101
2024-12-12 05:04:04 | INFO | train_inner | epoch 001:    402 / 31388 loss=11.468, nll_loss=10.827, ppl=1816.83, wps=37453, ups=9.52, wpb=3935.3, bsz=130.4, num_updates=400, lr=5e-05, gnorm=0.954, loss_scale=32, train_wall=1, wall=102
2024-12-12 05:04:05 | INFO | train_inner | epoch 001:    412 / 31388 loss=11.386, nll_loss=10.735, ppl=1704.19, wps=36687, ups=9.44, wpb=3887, bsz=137.6, num_updates=410, lr=5.125e-05, gnorm=0.898, loss_scale=32, train_wall=1, wall=103
2024-12-12 05:04:06 | INFO | train_inner | epoch 001:    422 / 31388 loss=11.463, nll_loss=10.821, ppl=1808.65, wps=35136.4, ups=9.58, wpb=3668, bsz=122.4, num_updates=420, lr=5.25e-05, gnorm=1.008, loss_scale=32, train_wall=1, wall=104
2024-12-12 05:04:07 | INFO | train_inner | epoch 001:    432 / 31388 loss=11.415, nll_loss=10.766, ppl=1741.89, wps=36802.6, ups=9.71, wpb=3791.4, bsz=136.8, num_updates=430, lr=5.375e-05, gnorm=1.406, loss_scale=32, train_wall=1, wall=105
2024-12-12 05:04:09 | INFO | train_inner | epoch 001:    442 / 31388 loss=11.23, nll_loss=10.556, ppl=1505.23, wps=35162.1, ups=9.53, wpb=3690.6, bsz=180.8, num_updates=440, lr=5.5e-05, gnorm=1.604, loss_scale=32, train_wall=1, wall=106
2024-12-12 05:04:10 | INFO | train_inner | epoch 001:    452 / 31388 loss=11.239, nll_loss=10.566, ppl=1516.09, wps=36476.2, ups=9.27, wpb=3936, bsz=164.8, num_updates=450, lr=5.625e-05, gnorm=1.364, loss_scale=32, train_wall=1, wall=107
2024-12-12 05:04:11 | INFO | train_inner | epoch 001:    462 / 31388 loss=11.321, nll_loss=10.657, ppl=1614.16, wps=36569.6, ups=9.4, wpb=3892, bsz=143.2, num_updates=460, lr=5.75e-05, gnorm=1.113, loss_scale=32, train_wall=1, wall=108
2024-12-12 05:04:12 | INFO | train_inner | epoch 001:    472 / 31388 loss=11.408, nll_loss=10.759, ppl=1732.38, wps=35682.9, ups=9.75, wpb=3658.3, bsz=113.6, num_updates=470, lr=5.875e-05, gnorm=1.018, loss_scale=32, train_wall=1, wall=109
2024-12-12 05:04:13 | INFO | train_inner | epoch 001:    482 / 31388 loss=11.421, nll_loss=10.772, ppl=1748.24, wps=36544.5, ups=9.72, wpb=3760.2, bsz=114.4, num_updates=480, lr=6e-05, gnorm=1.022, loss_scale=32, train_wall=1, wall=110
2024-12-12 05:04:14 | INFO | train_inner | epoch 001:    492 / 31388 loss=11.27, nll_loss=10.602, ppl=1554.28, wps=35450.1, ups=9.65, wpb=3672.8, bsz=123.2, num_updates=490, lr=6.125e-05, gnorm=1.256, loss_scale=32, train_wall=1, wall=111
2024-12-12 05:04:15 | INFO | train_inner | epoch 001:    502 / 31388 loss=11.362, nll_loss=10.708, ppl=1673.18, wps=37488.5, ups=9.89, wpb=3791.1, bsz=110.4, num_updates=500, lr=6.25e-05, gnorm=1.397, loss_scale=32, train_wall=1, wall=112
2024-12-12 05:04:16 | INFO | train_inner | epoch 001:    512 / 31388 loss=11.29, nll_loss=10.622, ppl=1576.46, wps=35955, ups=9.52, wpb=3776.8, bsz=114.4, num_updates=510, lr=6.375e-05, gnorm=1.28, loss_scale=32, train_wall=1, wall=113
2024-12-12 05:04:17 | INFO | train_inner | epoch 001:    522 / 31388 loss=11.314, nll_loss=10.651, ppl=1607.55, wps=37173.5, ups=9.55, wpb=3891.9, bsz=122.4, num_updates=520, lr=6.5e-05, gnorm=1.043, loss_scale=32, train_wall=1, wall=114
2024-12-12 05:04:18 | INFO | train_inner | epoch 001:    532 / 31388 loss=11.201, nll_loss=10.522, ppl=1470.88, wps=35883.3, ups=9.6, wpb=3738.4, bsz=134.4, num_updates=530, lr=6.625e-05, gnorm=1.215, loss_scale=32, train_wall=1, wall=115
2024-12-12 05:04:19 | INFO | train_inner | epoch 001:    542 / 31388 loss=11.145, nll_loss=10.461, ppl=1409.38, wps=35971, ups=9.92, wpb=3626.4, bsz=124.8, num_updates=540, lr=6.75e-05, gnorm=1.553, loss_scale=32, train_wall=1, wall=116
2024-12-12 05:04:20 | INFO | train_inner | epoch 001:    552 / 31388 loss=11.276, nll_loss=10.591, ppl=1542.46, wps=36138.1, ups=9.72, wpb=3717.1, bsz=114.4, num_updates=550, lr=6.875e-05, gnorm=1.41, loss_scale=32, train_wall=1, wall=117
2024-12-12 05:04:21 | INFO | train_inner | epoch 001:    562 / 31388 loss=11.19, nll_loss=10.507, ppl=1454.88, wps=35788.6, ups=9.67, wpb=3700, bsz=108.8, num_updates=560, lr=7e-05, gnorm=0.935, loss_scale=32, train_wall=1, wall=118
2024-12-12 05:04:22 | INFO | train_inner | epoch 001:    572 / 31388 loss=11.038, nll_loss=10.335, ppl=1292.08, wps=35953.4, ups=9.64, wpb=3730.4, bsz=116, num_updates=570, lr=7.125e-05, gnorm=0.965, loss_scale=32, train_wall=1, wall=119
2024-12-12 05:04:23 | INFO | train_inner | epoch 001:    582 / 31388 loss=11.027, nll_loss=10.324, ppl=1281.96, wps=36139.1, ups=9.53, wpb=3791, bsz=127.2, num_updates=580, lr=7.25e-05, gnorm=1.277, loss_scale=32, train_wall=1, wall=121
2024-12-12 05:04:24 | INFO | train_inner | epoch 001:    592 / 31388 loss=10.523, nll_loss=9.75, ppl=861.12, wps=36402.7, ups=9.33, wpb=3901.6, bsz=280.8, num_updates=590, lr=7.375e-05, gnorm=1.909, loss_scale=32, train_wall=1, wall=122
2024-12-12 05:04:25 | INFO | train_inner | epoch 001:    602 / 31388 loss=11.109, nll_loss=10.418, ppl=1368.32, wps=36484, ups=9.71, wpb=3757.8, bsz=126.4, num_updates=600, lr=7.5e-05, gnorm=1.259, loss_scale=32, train_wall=1, wall=123
2024-12-12 05:04:26 | INFO | train_inner | epoch 001:    612 / 31388 loss=11.017, nll_loss=10.312, ppl=1271.03, wps=35143.1, ups=9.75, wpb=3605.6, bsz=112.8, num_updates=610, lr=7.625e-05, gnorm=0.869, loss_scale=32, train_wall=1, wall=124
2024-12-12 05:04:27 | INFO | train_inner | epoch 001:    622 / 31388 loss=10.95, nll_loss=10.238, ppl=1207.34, wps=36439.6, ups=9.58, wpb=3802.8, bsz=130.4, num_updates=620, lr=7.75e-05, gnorm=1.054, loss_scale=32, train_wall=1, wall=125
2024-12-12 05:04:28 | INFO | train_inner | epoch 001:    632 / 31388 loss=10.959, nll_loss=10.247, ppl=1215.42, wps=36333.5, ups=9.56, wpb=3798.7, bsz=137.6, num_updates=630, lr=7.875e-05, gnorm=1.146, loss_scale=32, train_wall=1, wall=126
2024-12-12 05:04:29 | INFO | train_inner | epoch 001:    642 / 31388 loss=10.986, nll_loss=10.274, ppl=1238.43, wps=36525.6, ups=9.72, wpb=3756.4, bsz=135.2, num_updates=640, lr=8e-05, gnorm=1.48, loss_scale=32, train_wall=1, wall=127
2024-12-12 05:04:30 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2024-12-12 05:04:30 | INFO | train_inner | epoch 001:    653 / 31388 loss=10.953, nll_loss=10.238, ppl=1207.25, wps=33146.2, ups=8.7, wpb=3808, bsz=96, num_updates=650, lr=8.125e-05, gnorm=1.047, loss_scale=16, train_wall=1, wall=128
2024-12-12 05:04:32 | INFO | train_inner | epoch 001:    663 / 31388 loss=10.977, nll_loss=10.27, ppl=1234.9, wps=37284.7, ups=9.62, wpb=3876.8, bsz=110.4, num_updates=660, lr=8.25e-05, gnorm=0.998, loss_scale=16, train_wall=1, wall=129
2024-12-12 05:04:33 | INFO | train_inner | epoch 001:    673 / 31388 loss=10.872, nll_loss=10.148, ppl=1135, wps=36212.3, ups=9.45, wpb=3832.7, bsz=140, num_updates=670, lr=8.375e-05, gnorm=0.989, loss_scale=16, train_wall=1, wall=130
2024-12-12 05:04:34 | INFO | train_inner | epoch 001:    683 / 31388 loss=10.923, nll_loss=10.204, ppl=1179.74, wps=34976.9, ups=9.92, wpb=3527.4, bsz=90.4, num_updates=680, lr=8.5e-05, gnorm=1.09, loss_scale=16, train_wall=1, wall=131
2024-12-12 05:04:35 | INFO | train_inner | epoch 001:    693 / 31388 loss=10.769, nll_loss=10.027, ppl=1043.7, wps=36337.3, ups=9.34, wpb=3890.8, bsz=147.2, num_updates=690, lr=8.625e-05, gnorm=0.999, loss_scale=16, train_wall=1, wall=132
2024-12-12 05:04:36 | INFO | train_inner | epoch 001:    703 / 31388 loss=10.732, nll_loss=9.989, ppl=1016.53, wps=35818.2, ups=9.34, wpb=3835.6, bsz=125.6, num_updates=700, lr=8.75e-05, gnorm=1.181, loss_scale=16, train_wall=1, wall=133
2024-12-12 05:04:37 | INFO | train_inner | epoch 001:    713 / 31388 loss=10.778, nll_loss=10.037, ppl=1050.39, wps=35831.9, ups=9.8, wpb=3657.6, bsz=115.2, num_updates=710, lr=8.875e-05, gnorm=1.358, loss_scale=16, train_wall=1, wall=134
2024-12-12 05:04:38 | INFO | train_inner | epoch 001:    723 / 31388 loss=10.766, nll_loss=10.019, ppl=1037.25, wps=35260.9, ups=9.79, wpb=3603.5, bsz=141.6, num_updates=720, lr=9e-05, gnorm=1.716, loss_scale=16, train_wall=1, wall=135
2024-12-12 05:04:39 | INFO | train_inner | epoch 001:    733 / 31388 loss=10.646, nll_loss=9.887, ppl=947.05, wps=35753.8, ups=9.86, wpb=3627.4, bsz=156.8, num_updates=730, lr=9.125e-05, gnorm=1.188, loss_scale=16, train_wall=1, wall=136
2024-12-12 05:04:40 | INFO | train_inner | epoch 001:    743 / 31388 loss=10.807, nll_loss=10.066, ppl=1072.21, wps=36919.1, ups=9.75, wpb=3786.2, bsz=112.8, num_updates=740, lr=9.25e-05, gnorm=1.166, loss_scale=16, train_wall=1, wall=137
2024-12-12 05:04:41 | INFO | train_inner | epoch 001:    753 / 31388 loss=10.452, nll_loss=9.665, ppl=811.83, wps=36197.2, ups=9.31, wpb=3887.2, bsz=164, num_updates=750, lr=9.375e-05, gnorm=1.429, loss_scale=16, train_wall=1, wall=138
2024-12-12 05:04:42 | INFO | train_inner | epoch 001:    763 / 31388 loss=10.778, nll_loss=10.042, ppl=1053.95, wps=36177.8, ups=9.63, wpb=3756.2, bsz=97.6, num_updates=760, lr=9.5e-05, gnorm=1.228, loss_scale=16, train_wall=1, wall=139
2024-12-12 05:04:43 | INFO | train_inner | epoch 001:    773 / 31388 loss=10.631, nll_loss=9.866, ppl=933.29, wps=36815.3, ups=9.65, wpb=3813.5, bsz=107.2, num_updates=770, lr=9.625e-05, gnorm=1.035, loss_scale=16, train_wall=1, wall=140
2024-12-12 05:04:44 | INFO | train_inner | epoch 001:    783 / 31388 loss=10.719, nll_loss=9.971, ppl=1003.81, wps=35689.5, ups=9.82, wpb=3635.2, bsz=96.8, num_updates=780, lr=9.75e-05, gnorm=0.863, loss_scale=16, train_wall=1, wall=141
2024-12-12 05:04:45 | INFO | train_inner | epoch 001:    793 / 31388 loss=10.579, nll_loss=9.81, ppl=897.94, wps=37066.3, ups=9.66, wpb=3836.4, bsz=136.8, num_updates=790, lr=9.875e-05, gnorm=1.354, loss_scale=16, train_wall=1, wall=142
2024-12-12 05:04:46 | INFO | train_inner | epoch 001:    803 / 31388 loss=10.378, nll_loss=9.583, ppl=766.77, wps=36080.8, ups=9.59, wpb=3761.6, bsz=138.4, num_updates=800, lr=0.0001, gnorm=0.973, loss_scale=16, train_wall=1, wall=143
2024-12-12 05:04:47 | INFO | train_inner | epoch 001:    813 / 31388 loss=10.629, nll_loss=9.865, ppl=932.72, wps=34774.2, ups=9.78, wpb=3555.1, bsz=122.4, num_updates=810, lr=0.00010125, gnorm=1.252, loss_scale=16, train_wall=1, wall=145
2024-12-12 05:04:48 | INFO | train_inner | epoch 001:    823 / 31388 loss=10.49, nll_loss=9.707, ppl=835.99, wps=35396.9, ups=9.59, wpb=3692.2, bsz=130.4, num_updates=820, lr=0.0001025, gnorm=1.079, loss_scale=16, train_wall=1, wall=146
2024-12-12 05:04:49 | INFO | train_inner | epoch 001:    833 / 31388 loss=10.588, nll_loss=9.82, ppl=903.8, wps=34810, ups=9.69, wpb=3593.3, bsz=99.2, num_updates=830, lr=0.00010375, gnorm=1.056, loss_scale=16, train_wall=1, wall=147
2024-12-12 05:04:50 | INFO | train_inner | epoch 001:    843 / 31388 loss=10.437, nll_loss=9.646, ppl=801.43, wps=35635.5, ups=9.45, wpb=3770.4, bsz=116.8, num_updates=840, lr=0.000105, gnorm=1.057, loss_scale=16, train_wall=1, wall=148
2024-12-12 05:04:51 | INFO | train_inner | epoch 001:    853 / 31388 loss=10.522, nll_loss=9.739, ppl=854.8, wps=36945.3, ups=9.61, wpb=3843.7, bsz=130.4, num_updates=850, lr=0.00010625, gnorm=1.012, loss_scale=16, train_wall=1, wall=149
2024-12-12 05:04:52 | INFO | train_inner | epoch 001:    863 / 31388 loss=10.409, nll_loss=9.613, ppl=783.04, wps=36101.6, ups=9.71, wpb=3718.6, bsz=112.8, num_updates=860, lr=0.0001075, gnorm=0.918, loss_scale=16, train_wall=1, wall=150
2024-12-12 05:04:53 | INFO | train_inner | epoch 001:    873 / 31388 loss=10.423, nll_loss=9.628, ppl=791.3, wps=36048.9, ups=9.79, wpb=3683.6, bsz=128.8, num_updates=870, lr=0.00010875, gnorm=1.118, loss_scale=16, train_wall=1, wall=151
2024-12-12 05:04:54 | INFO | train_inner | epoch 001:    883 / 31388 loss=10.376, nll_loss=9.572, ppl=761.23, wps=35579.3, ups=9.56, wpb=3720.3, bsz=109.6, num_updates=880, lr=0.00011, gnorm=1.121, loss_scale=16, train_wall=1, wall=152
2024-12-12 05:04:55 | INFO | train_inner | epoch 001:    893 / 31388 loss=10.21, nll_loss=9.386, ppl=669.01, wps=36970.3, ups=9.7, wpb=3811.2, bsz=168, num_updates=890, lr=0.00011125, gnorm=1.36, loss_scale=16, train_wall=1, wall=153
2024-12-12 05:04:56 | INFO | train_inner | epoch 001:    903 / 31388 loss=10.354, nll_loss=9.549, ppl=749.32, wps=36082.3, ups=9.62, wpb=3750.9, bsz=128, num_updates=900, lr=0.0001125, gnorm=1.162, loss_scale=16, train_wall=1, wall=154
2024-12-12 05:04:58 | INFO | train_inner | epoch 001:    913 / 31388 loss=10.357, nll_loss=9.552, ppl=750.87, wps=35203.7, ups=9.26, wpb=3801, bsz=132, num_updates=910, lr=0.00011375, gnorm=1.316, loss_scale=16, train_wall=1, wall=155
2024-12-12 05:04:59 | INFO | train_inner | epoch 001:    923 / 31388 loss=10.392, nll_loss=9.59, ppl=770.57, wps=35091.2, ups=9.82, wpb=3573.3, bsz=113.6, num_updates=920, lr=0.000115, gnorm=1.068, loss_scale=16, train_wall=1, wall=156
2024-12-12 05:05:00 | INFO | train_inner | epoch 001:    933 / 31388 loss=10.34, nll_loss=9.532, ppl=740.19, wps=36850.7, ups=9.79, wpb=3764.4, bsz=100.8, num_updates=930, lr=0.00011625, gnorm=0.931, loss_scale=16, train_wall=1, wall=157
2024-12-12 05:05:01 | INFO | train_inner | epoch 001:    943 / 31388 loss=10.101, nll_loss=9.262, ppl=613.88, wps=36507.8, ups=9.53, wpb=3830.7, bsz=123.2, num_updates=940, lr=0.0001175, gnorm=0.951, loss_scale=16, train_wall=1, wall=158
2024-12-12 05:05:02 | INFO | train_inner | epoch 001:    953 / 31388 loss=10.245, nll_loss=9.42, ppl=685.1, wps=35041.2, ups=9.31, wpb=3762, bsz=129.6, num_updates=950, lr=0.00011875, gnorm=1.179, loss_scale=16, train_wall=1, wall=159
2024-12-12 05:05:03 | INFO | train_inner | epoch 001:    963 / 31388 loss=10.193, nll_loss=9.365, ppl=659.48, wps=35497.2, ups=9.35, wpb=3798.4, bsz=125.6, num_updates=960, lr=0.00012, gnorm=1.152, loss_scale=16, train_wall=1, wall=160
2024-12-12 05:05:04 | INFO | train_inner | epoch 001:    973 / 31388 loss=10.207, nll_loss=9.378, ppl=665.55, wps=36156.5, ups=9.64, wpb=3750.9, bsz=128.8, num_updates=970, lr=0.00012125, gnorm=1.095, loss_scale=16, train_wall=1, wall=161
2024-12-12 05:05:05 | INFO | train_inner | epoch 001:    983 / 31388 loss=10.29, nll_loss=9.468, ppl=708.14, wps=36136.9, ups=9.84, wpb=3673.1, bsz=100.8, num_updates=980, lr=0.0001225, gnorm=1.179, loss_scale=16, train_wall=1, wall=162
2024-12-12 05:05:06 | INFO | train_inner | epoch 001:    993 / 31388 loss=10.083, nll_loss=9.242, ppl=605.48, wps=36349.8, ups=9.55, wpb=3806.2, bsz=155.2, num_updates=990, lr=0.00012375, gnorm=1.033, loss_scale=16, train_wall=1, wall=163
2024-12-12 05:05:07 | INFO | train_inner | epoch 001:   1003 / 31388 loss=10.185, nll_loss=9.351, ppl=653.05, wps=35009.2, ups=9.82, wpb=3566.4, bsz=113.6, num_updates=1000, lr=0.000125, gnorm=1.066, loss_scale=16, train_wall=1, wall=164
2024-12-12 05:05:08 | INFO | train_inner | epoch 001:   1013 / 31388 loss=10.417, nll_loss=9.614, ppl=783.82, wps=35407.1, ups=10.06, wpb=3521.3, bsz=88.8, num_updates=1010, lr=0.00012625, gnorm=1.174, loss_scale=16, train_wall=1, wall=165
2024-12-12 05:05:09 | INFO | train_inner | epoch 001:   1023 / 31388 loss=9.991, nll_loss=9.13, ppl=560.28, wps=35778.9, ups=9.46, wpb=3783.9, bsz=165.6, num_updates=1020, lr=0.0001275, gnorm=1.387, loss_scale=16, train_wall=1, wall=166
2024-12-12 05:05:10 | INFO | train_inner | epoch 001:   1033 / 31388 loss=10.016, nll_loss=9.156, ppl=570.5, wps=36751.6, ups=9.35, wpb=3929.6, bsz=140, num_updates=1030, lr=0.00012875, gnorm=0.97, loss_scale=16, train_wall=1, wall=167
2024-12-12 05:05:11 | INFO | train_inner | epoch 001:   1043 / 31388 loss=9.929, nll_loss=9.06, ppl=533.79, wps=36137.8, ups=9.31, wpb=3879.8, bsz=140, num_updates=1040, lr=0.00013, gnorm=0.986, loss_scale=16, train_wall=1, wall=168
2024-12-12 05:05:12 | INFO | train_inner | epoch 001:   1053 / 31388 loss=9.977, nll_loss=9.115, ppl=554.54, wps=35763.8, ups=9.52, wpb=3755.2, bsz=127.2, num_updates=1050, lr=0.00013125, gnorm=1.025, loss_scale=16, train_wall=1, wall=170
2024-12-12 05:05:13 | INFO | train_inner | epoch 001:   1063 / 31388 loss=9.835, nll_loss=8.952, ppl=495.32, wps=36507.5, ups=9.62, wpb=3794.4, bsz=143.2, num_updates=1060, lr=0.0001325, gnorm=0.943, loss_scale=16, train_wall=1, wall=171
2024-12-12 05:05:14 | INFO | train_inner | epoch 001:   1073 / 31388 loss=10.113, nll_loss=9.262, ppl=613.76, wps=36167.8, ups=9.58, wpb=3776.8, bsz=129.6, num_updates=1070, lr=0.00013375, gnorm=1.531, loss_scale=16, train_wall=1, wall=172
2024-12-12 05:05:15 | INFO | train_inner | epoch 001:   1083 / 31388 loss=9.956, nll_loss=9.096, ppl=547.39, wps=35925.2, ups=9.73, wpb=3692.1, bsz=154.4, num_updates=1080, lr=0.000135, gnorm=1.103, loss_scale=16, train_wall=1, wall=173
2024-12-12 05:05:16 | INFO | train_inner | epoch 001:   1093 / 31388 loss=10.025, nll_loss=9.166, ppl=574.4, wps=36919.9, ups=9.73, wpb=3794.4, bsz=114.4, num_updates=1090, lr=0.00013625, gnorm=0.91, loss_scale=16, train_wall=1, wall=174
2024-12-12 05:05:17 | INFO | train_inner | epoch 001:   1103 / 31388 loss=9.997, nll_loss=9.139, ppl=563.59, wps=37151.4, ups=9.63, wpb=3858.4, bsz=108.8, num_updates=1100, lr=0.0001375, gnorm=0.817, loss_scale=16, train_wall=1, wall=175
2024-12-12 05:05:18 | INFO | train_inner | epoch 001:   1113 / 31388 loss=9.903, nll_loss=9.03, ppl=522.77, wps=33567.9, ups=9.87, wpb=3401.4, bsz=112, num_updates=1110, lr=0.00013875, gnorm=1.071, loss_scale=16, train_wall=1, wall=176
2024-12-12 05:05:19 | INFO | train_inner | epoch 001:   1123 / 31388 loss=9.831, nll_loss=8.946, ppl=493.31, wps=36607.6, ups=9.56, wpb=3829.4, bsz=139.2, num_updates=1120, lr=0.00014, gnorm=1.443, loss_scale=16, train_wall=1, wall=177
2024-12-12 05:05:20 | INFO | train_inner | epoch 001:   1133 / 31388 loss=9.623, nll_loss=8.702, ppl=416.36, wps=36576.9, ups=9.68, wpb=3779.2, bsz=191.2, num_updates=1130, lr=0.00014125, gnorm=1.117, loss_scale=16, train_wall=1, wall=178
2024-12-12 05:05:21 | INFO | train_inner | epoch 001:   1143 / 31388 loss=9.859, nll_loss=8.988, ppl=507.87, wps=37069.5, ups=9.64, wpb=3844, bsz=134.4, num_updates=1140, lr=0.0001425, gnorm=0.926, loss_scale=16, train_wall=1, wall=179
2024-12-12 05:05:22 | INFO | train_inner | epoch 001:   1153 / 31388 loss=9.769, nll_loss=8.868, ppl=467.1, wps=36800.8, ups=9.42, wpb=3905.6, bsz=146.4, num_updates=1150, lr=0.00014375, gnorm=1.013, loss_scale=16, train_wall=1, wall=180
2024-12-12 05:05:23 | INFO | fairseq_cli.train | begin save checkpoint
2024-12-12 05:05:27 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 1 @ 1151 updates, score None) (writing took 4.350577488999988 seconds)
2024-12-12 05:05:27 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2024-12-12 05:05:27 | INFO | train | epoch 001 | loss 11.744 | nll_loss 11.108 | ppl 2206.76 | wps 34818.5 | ups 9.27 | wpb 3755.6 | bsz 129.5 | num_updates 1151 | lr 0.000143875 | gnorm 1.708 | loss_scale 16 | train_wall 119 | wall 184
2024-12-12 05:05:27 | INFO | fairseq_cli.train | done training in 124.3 seconds
