[1/38] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/general_kernels.cu -o general_kernels.cuda.o 
[2/38] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/transform_kernels_new.cu -o transform_kernels_new.cuda.o 
[3/38] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/embedding_kernels.cu -o embedding_kernels.cuda.o 
[4/38] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/cublas_wrappers.cu -o cublas_wrappers.cuda.o 
[5/38] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/transform_kernels.cu -o transform_kernels.cuda.o 
[6/38] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/normalize_kernels.cu -o normalize_kernels.cuda.o 
[7/38] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/dropout_kernels.cu -o dropout_kernels.cuda.o 
/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/dropout_kernels.cu(1509): warning: variable "thread_cmax_out_grad" was declared but never referenced
          detected during instantiation of "void launch_ls_quant_dropout_act_bias_bwd<act_type,T>(T *, T *, T *, T *, const int8_t *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, int, float, cudaStream_t, __nv_bool) [with act_type=ActivationType::kRelu, T=float]" 
(1601): here

/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/dropout_kernels.cu(1513): warning: variable "temp_cmax_out_grad" was declared but never referenced
          detected during instantiation of "void launch_ls_quant_dropout_act_bias_bwd<act_type,T>(T *, T *, T *, T *, const int8_t *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, int, float, cudaStream_t, __nv_bool) [with act_type=ActivationType::kRelu, T=float]" 
(1601): here

/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/dropout_kernels.cu(1545): warning: variable "block_cmax_out_grad" was declared but never referenced
          detected during instantiation of "void launch_ls_quant_dropout_act_bias_bwd<act_type,T>(T *, T *, T *, T *, const int8_t *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, int, float, cudaStream_t, __nv_bool) [with act_type=ActivationType::kRelu, T=float]" 
(1601): here

/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/dropout_kernels.cu(1667): warning: variable "cmax_in_val" was declared but never referenced
          detected during:
            instantiation of "void ls_quant_dropout_act_bias_bwd_kernel<act_type,T>(T *, T *, T *, T *, const T *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, float, int) [with act_type=ActivationType::kRelu, T=float]" 
(1751): here
            instantiation of "void launch_ls_quant_dropout_act_bias_bwd<act_type,T>(T *, T *, T *, T *, const T *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, int, float, cudaStream_t) [with act_type=ActivationType::kRelu, T=float]" 
(1754): here

/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/dropout_kernels.cu(1667): warning: variable "cmax_in_val" was declared but never referenced
          detected during:
            instantiation of "void ls_quant_dropout_act_bias_bwd_kernel<act_type,T>(T *, T *, T *, T *, const T *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, float, int) [with act_type=ActivationType::kGelu, T=float]" 
(1751): here
            instantiation of "void launch_ls_quant_dropout_act_bias_bwd<act_type,T>(T *, T *, T *, T *, const T *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, int, float, cudaStream_t) [with act_type=ActivationType::kGelu, T=float]" 
(1770): here

[8/38] c++ -MMD -MF layer.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/layer.cpp -o layer.o 
[9/38] c++ -MMD -MF node.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/node.cpp -o node.o 
[10/38] c++ -MMD -MF context.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/context.cpp -o context.o 
[11/38] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/softmax_kernels.cu -o softmax_kernels.cuda.o 
[12/38] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/crf.cu -o crf.cuda.o 
[13/38] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/softmax_kernels_new.cu -o softmax_kernels_new.cuda.o 
[14/38] c++ -MMD -MF manager.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/manager.cpp -o manager.o 
[15/38] c++ -MMD -MF tensor.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/tensor.cpp -o tensor.o 
[16/38] c++ -MMD -MF bias_act_dropout.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/bias_act_dropout.cpp -o bias_act_dropout.o 
[17/38] c++ -MMD -MF bias_dropout_residual.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/bias_dropout_residual.cpp -o bias_dropout_residual.o 
[18/38] c++ -MMD -MF linear.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/linear.cpp -o linear.o 
[19/38] c++ -MMD -MF strided_batch_gemm.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/strided_batch_gemm.cpp -o strided_batch_gemm.o 
[20/38] c++ -MMD -MF layer_normalize.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/layer_normalize.cpp -o layer_normalize.o 
[21/38] c++ -MMD -MF bias_add_transform_20314.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/bias_add_transform_20314.cpp -o bias_add_transform_20314.o 
[22/38] c++ -MMD -MF dropout.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/dropout.cpp -o dropout.o 
[23/38] c++ -MMD -MF softmax.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/softmax.cpp -o softmax.o 
[24/38] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/cross_entropy.cu -o cross_entropy.cuda.o 
[25/38] c++ -MMD -MF transform_0213.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/transform_0213.cpp -o transform_0213.o 
[26/38] c++ -MMD -MF launch_concat3_dim1.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/launch_concat3_dim1.cpp -o launch_concat3_dim1.o 
[27/38] c++ -MMD -MF crf.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/crf.cpp -o crf.o 
[28/38] c++ -MMD -MF feed_forward_layer.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/feed_forward_layer.cpp -o feed_forward_layer.o 
[29/38] c++ -MMD -MF transformer_encoder_layer.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/transformer_encoder_layer.cpp -o transformer_encoder_layer.o 
[30/38] c++ -MMD -MF encdec_kv_layer.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/encdec_kv_layer.cpp -o encdec_kv_layer.o 
[31/38] c++ -MMD -MF multihead_attention_layer.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/multihead_attention_layer.cpp -o multihead_attention_layer.o 
[32/38] c++ -MMD -MF dec_self_attention_layer.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/dec_self_attention_layer.cpp -o dec_self_attention_layer.o 
[33/38] c++ -MMD -MF crf_layer.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/crf_layer.cpp -o crf_layer.o 
[34/38] c++ -MMD -MF dec_enc_attention_layer.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/dec_enc_attention_layer.cpp -o dec_enc_attention_layer.o 
[35/38] c++ -MMD -MF transformer_decoder_layer.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/transformer_decoder_layer.cpp -o transformer_decoder_layer.o 
[36/38] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/cuda_util.cu -o cuda_util.cuda.o 
[37/38] c++ -MMD -MF pybind_layer_new.o.d -DTORCH_EXTENSION_NAME=lightseq_layers_new -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops_new/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/lsflow/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers_new/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -DPYBIND_LAYER -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/pybind/pybind_layer_new.cpp -o pybind_layer_new.o 
[38/38] c++ cublas_wrappers.cuda.o transform_kernels.cuda.o transform_kernels_new.cuda.o dropout_kernels.cuda.o normalize_kernels.cuda.o softmax_kernels.cuda.o softmax_kernels_new.cuda.o general_kernels.cuda.o cuda_util.cuda.o embedding_kernels.cuda.o cross_entropy.cuda.o crf.cuda.o context.o layer.o manager.o node.o tensor.o bias_act_dropout.o bias_dropout_residual.o linear.o layer_normalize.o strided_batch_gemm.o bias_add_transform_20314.o dropout.o softmax.o launch_concat3_dim1.o transform_0213.o crf.o feed_forward_layer.o multihead_attention_layer.o transformer_encoder_layer.o dec_self_attention_layer.o encdec_kv_layer.o dec_enc_attention_layer.o transformer_decoder_layer.o crf_layer.o pybind_layer_new.o -shared -L/opt/conda/lib/python3.7/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda_cu -ltorch_cuda_cpp -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o lightseq_layers_new.so
Time to load lightseq_layers_new op: 51.69141411781311 seconds
[1/18] c++ -MMD -MF cublas_wrappers.o.d -DTORCH_EXTENSION_NAME=lightseq_layers -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/cublas_wrappers.cpp -o cublas_wrappers.o 
[2/18] c++ -MMD -MF cublas_algo_map.o.d -DTORCH_EXTENSION_NAME=lightseq_layers -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/cublas_algo_map.cpp -o cublas_algo_map.o 
[3/18] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/general_kernels.cu -o general_kernels.cuda.o 
[4/18] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/quantize_kernels.cu -o quantize_kernels.cuda.o 
[5/18] c++ -MMD -MF cross_entropy_layer.o.d -DTORCH_EXTENSION_NAME=lightseq_layers -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/cross_entropy_layer.cpp -o cross_entropy_layer.o 
[6/18] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/transform_kernels.cu -o transform_kernels.cuda.o 
[7/18] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/embedding_kernels.cu -o embedding_kernels.cuda.o 
[8/18] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/normalize_kernels.cu -o normalize_kernels.cuda.o 
[9/18] c++ -MMD -MF quant_linear_layer.o.d -DTORCH_EXTENSION_NAME=lightseq_layers -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/quant_linear_layer.cpp -o quant_linear_layer.o 
[10/18] c++ -MMD -MF transformer_embedding_layer.o.d -DTORCH_EXTENSION_NAME=lightseq_layers -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/transformer_embedding_layer.cpp -o transformer_embedding_layer.o 
[11/18] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/dropout_kernels.cu -o dropout_kernels.cuda.o 
/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/dropout_kernels.cu(1509): warning: variable "thread_cmax_out_grad" was declared but never referenced
          detected during instantiation of "void launch_ls_quant_dropout_act_bias_bwd<act_type,T>(T *, T *, T *, T *, const int8_t *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, int, float, cudaStream_t, __nv_bool) [with act_type=ActivationType::kRelu, T=float]" 
(1601): here

/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/dropout_kernels.cu(1513): warning: variable "temp_cmax_out_grad" was declared but never referenced
          detected during instantiation of "void launch_ls_quant_dropout_act_bias_bwd<act_type,T>(T *, T *, T *, T *, const int8_t *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, int, float, cudaStream_t, __nv_bool) [with act_type=ActivationType::kRelu, T=float]" 
(1601): here

/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/dropout_kernels.cu(1545): warning: variable "block_cmax_out_grad" was declared but never referenced
          detected during instantiation of "void launch_ls_quant_dropout_act_bias_bwd<act_type,T>(T *, T *, T *, T *, const int8_t *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, int, float, cudaStream_t, __nv_bool) [with act_type=ActivationType::kRelu, T=float]" 
(1601): here

/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/dropout_kernels.cu(1667): warning: variable "cmax_in_val" was declared but never referenced
          detected during:
            instantiation of "void ls_quant_dropout_act_bias_bwd_kernel<act_type,T>(T *, T *, T *, T *, const T *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, float, int) [with act_type=ActivationType::kRelu, T=float]" 
(1751): here
            instantiation of "void launch_ls_quant_dropout_act_bias_bwd<act_type,T>(T *, T *, T *, T *, const T *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, int, float, cudaStream_t) [with act_type=ActivationType::kRelu, T=float]" 
(1754): here

/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/dropout_kernels.cu(1667): warning: variable "cmax_in_val" was declared but never referenced
          detected during:
            instantiation of "void ls_quant_dropout_act_bias_bwd_kernel<act_type,T>(T *, T *, T *, T *, const T *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, float, int) [with act_type=ActivationType::kGelu, T=float]" 
(1751): here
            instantiation of "void launch_ls_quant_dropout_act_bias_bwd<act_type,T>(T *, T *, T *, T *, const T *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, int, float, cudaStream_t) [with act_type=ActivationType::kGelu, T=float]" 
(1770): here

[12/18] c++ -MMD -MF transformer_encoder_layer.o.d -DTORCH_EXTENSION_NAME=lightseq_layers -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/transformer_encoder_layer.cpp -o transformer_encoder_layer.o 
[13/18] c++ -MMD -MF transformer_decoder_layer.o.d -DTORCH_EXTENSION_NAME=lightseq_layers -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/transformer_decoder_layer.cpp -o transformer_decoder_layer.o 
[14/18] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/softmax_kernels.cu -o softmax_kernels.cuda.o 
[15/18] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/cross_entropy.cu -o cross_entropy.cuda.o 
[16/18] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_layers -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/cuda_util.cu -o cuda_util.cuda.o 
[17/18] c++ -MMD -MF pybind_layer.o.d -DTORCH_EXTENSION_NAME=lightseq_layers -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/pybind/pybind_layer.cpp -o pybind_layer.o 
[18/18] c++ cublas_algo_map.o cublas_wrappers.o quantize_kernels.cuda.o transform_kernels.cuda.o dropout_kernels.cuda.o normalize_kernels.cuda.o softmax_kernels.cuda.o general_kernels.cuda.o cuda_util.cuda.o embedding_kernels.cuda.o cross_entropy.cuda.o cross_entropy_layer.o quant_linear_layer.o transformer_encoder_layer.o transformer_decoder_layer.o transformer_embedding_layer.o pybind_layer.o -shared -L/opt/conda/lib/python3.7/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda_cu -ltorch_cuda_cpp -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o lightseq_layers.so
Time to load lightseq_layers op: 39.5047607421875 seconds
Time to load lightseq_layers op: 0.039556264877319336 seconds
Time to load lightseq_layers op: 0.036057472229003906 seconds
Time to load lightseq_layers op: 0.031131744384765625 seconds
[1/14] c++ -MMD -MF gemm_test.o.d -DTORCH_EXTENSION_NAME=lightseq_kernels -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/gemm_test.cpp -o gemm_test.o 
[2/14] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_kernels -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/general_kernels.cu -o general_kernels.cuda.o 
[3/14] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_kernels -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/transform_kernels_new.cu -o transform_kernels_new.cuda.o 
[4/14] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_kernels -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/embedding_kernels.cu -o embedding_kernels.cuda.o 
[5/14] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_kernels -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/transform_kernels.cu -o transform_kernels.cuda.o 
[6/14] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_kernels -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/normalize_kernels.cu -o normalize_kernels.cuda.o 
[7/14] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_kernels -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/dropout_kernels.cu -o dropout_kernels.cuda.o 
/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/dropout_kernels.cu(1509): warning: variable "thread_cmax_out_grad" was declared but never referenced
          detected during instantiation of "void launch_ls_quant_dropout_act_bias_bwd<act_type,T>(T *, T *, T *, T *, const int8_t *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, int, float, cudaStream_t, __nv_bool) [with act_type=ActivationType::kRelu, T=float]" 
(1601): here

/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/dropout_kernels.cu(1513): warning: variable "temp_cmax_out_grad" was declared but never referenced
          detected during instantiation of "void launch_ls_quant_dropout_act_bias_bwd<act_type,T>(T *, T *, T *, T *, const int8_t *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, int, float, cudaStream_t, __nv_bool) [with act_type=ActivationType::kRelu, T=float]" 
(1601): here

/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/dropout_kernels.cu(1545): warning: variable "block_cmax_out_grad" was declared but never referenced
          detected during instantiation of "void launch_ls_quant_dropout_act_bias_bwd<act_type,T>(T *, T *, T *, T *, const int8_t *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, int, float, cudaStream_t, __nv_bool) [with act_type=ActivationType::kRelu, T=float]" 
(1601): here

/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/dropout_kernels.cu(1667): warning: variable "cmax_in_val" was declared but never referenced
          detected during:
            instantiation of "void ls_quant_dropout_act_bias_bwd_kernel<act_type,T>(T *, T *, T *, T *, const T *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, float, int) [with act_type=ActivationType::kRelu, T=float]" 
(1751): here
            instantiation of "void launch_ls_quant_dropout_act_bias_bwd<act_type,T>(T *, T *, T *, T *, const T *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, int, float, cudaStream_t) [with act_type=ActivationType::kRelu, T=float]" 
(1754): here

/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/dropout_kernels.cu(1667): warning: variable "cmax_in_val" was declared but never referenced
          detected during:
            instantiation of "void ls_quant_dropout_act_bias_bwd_kernel<act_type,T>(T *, T *, T *, T *, const T *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, float, int) [with act_type=ActivationType::kGelu, T=float]" 
(1751): here
            instantiation of "void launch_ls_quant_dropout_act_bias_bwd<act_type,T>(T *, T *, T *, T *, const T *, const T *, const uint8_t *, const uint8_t *, const T *, const T *, const uint8_t *, int, int, float, cudaStream_t) [with act_type=ActivationType::kGelu, T=float]" 
(1770): here

[8/14] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_kernels -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/quantize_kernels.cu -o quantize_kernels.cuda.o 
[9/14] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_kernels -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/crf.cu -o crf.cuda.o 
[10/14] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_kernels -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/softmax_kernels.cu -o softmax_kernels.cuda.o 
[11/14] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_kernels -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/softmax_kernels_new.cu -o softmax_kernels_new.cuda.o 
[12/14] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=lightseq_kernels -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -DTHRUST_IGNORE_CUB_VERSION_CHECK -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/cuda_util.cu -o cuda_util.cuda.o 
[13/14] c++ -MMD -MF pybind_kernel.o.d -DTORCH_EXTENSION_NAME=lightseq_kernels -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/pybind/pybind_kernel.cpp -o pybind_kernel.o 
[14/14] c++ gemm_test.o cuda_util.cuda.o transform_kernels.cuda.o transform_kernels_new.cuda.o softmax_kernels.cuda.o softmax_kernels_new.cuda.o general_kernels.cuda.o normalize_kernels.cuda.o dropout_kernels.cuda.o embedding_kernels.cuda.o quantize_kernels.cuda.o crf.cuda.o pybind_kernel.o -shared -L/opt/conda/lib/python3.7/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda_cu -ltorch_cuda_cpp -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o lightseq_kernels.so
Time to load lightseq_kernels op: 38.52218317985535 seconds
2024-12-12 04:46:09 | INFO | fairseq_cli.train | Namespace(GCQ_quantile=0.99, activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='ls_transformer_wmt_en_de_big_t2t', attention_dropout=0.1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='ls_label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/tmp/wmt14_en_de/', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=1024, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, enable_GCQ=False, enable_quant=False, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=True, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format='simple', log_interval=10, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=300, max_target_positions=300, max_tokens=512, max_tokens_valid=512, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=True, min_loss_scale=0.0001, min_lr=-1.0, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, optimizer='ls_adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_mode='qat', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0.05, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, use_torch_layer=False, user_dir='/opt/conda/lib/python3.7/site-packages/lightseq/training/cli/fs_modules', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none')
2024-12-12 04:46:09 | INFO | fairseq.tasks.translation | [en] dictionary: 40480 types
2024-12-12 04:46:09 | INFO | fairseq.tasks.translation | [de] dictionary: 42720 types
2024-12-12 04:46:09 | INFO | fairseq.data.data_utils | loaded 39414 examples from: /tmp/wmt14_en_de/valid.en-de.en
2024-12-12 04:46:09 | INFO | fairseq.data.data_utils | loaded 39414 examples from: /tmp/wmt14_en_de/valid.en-de.de
2024-12-12 04:46:09 | INFO | fairseq.tasks.translation | /tmp/wmt14_en_de/ valid en-de 39414 examples
Initial Context, status_type: Training
Embedding layer #0 is created with date type [half].
Embedding layer #1 is created with date type [half].
Get igemm config from http://lf3-nlp-opensource.bytetos.com/obj/nlp-opensource/lightseq/igemm_configs/
[WARNING] /home/mwm2166/.lightseq/igemm_configs/ is not found; using default GEMM algo
Encoder layer #0 allocate shared memory size: 5079040
Encoder layer #0 allocate shared quant memory size: 6815744
Encoder layer #0 is created with date type [half].
Get igemm config from /home/mwm2166/.lightseq/igemm_configs/
[WARNING] /home/mwm2166/.lightseq/igemm_configs/ is not found; using default GEMM algo
Encoder layer #1 is created with date type [half].
Get igemm config from /home/mwm2166/.lightseq/igemm_configs/
[WARNING] /home/mwm2166/.lightseq/igemm_configs/ is not found; using default GEMM algo
Encoder layer #2 is created with date type [half].
Get igemm config from /home/mwm2166/.lightseq/igemm_configs/
[WARNING] /home/mwm2166/.lightseq/igemm_configs/ is not found; using default GEMM algo
Encoder layer #3 is created with date type [half].
Get igemm config from /home/mwm2166/.lightseq/igemm_configs/
[WARNING] /home/mwm2166/.lightseq/igemm_configs/ is not found; using default GEMM algo
Encoder layer #4 is created with date type [half].
Get igemm config from /home/mwm2166/.lightseq/igemm_configs/
[WARNING] /home/mwm2166/.lightseq/igemm_configs/ is not found; using default GEMM algo
Encoder layer #5 is created with date type [half].
Get igemm config from /home/mwm2166/.lightseq/igemm_configs/
[WARNING] /home/mwm2166/.lightseq/igemm_configs/ is not found; using default GEMM algo
Decoder layer #0 allocate shared memory size: 5079040
Decoder layer #0 allocate shared quant memory size: 6815744
Decoder layer #0 is created with date type [half].
Get igemm config from /home/mwm2166/.lightseq/igemm_configs/
[WARNING] /home/mwm2166/.lightseq/igemm_configs/ is not found; using default GEMM algo
Decoder layer #1 is created with date type [half].
Get igemm config from /home/mwm2166/.lightseq/igemm_configs/
[WARNING] /home/mwm2166/.lightseq/igemm_configs/ is not found; using default GEMM algo
Decoder layer #2 is created with date type [half].
Get igemm config from /home/mwm2166/.lightseq/igemm_configs/
[WARNING] /home/mwm2166/.lightseq/igemm_configs/ is not found; using default GEMM algo
Decoder layer #3 is created with date type [half].
Get igemm config from /home/mwm2166/.lightseq/igemm_configs/
[WARNING] /home/mwm2166/.lightseq/igemm_configs/ is not found; using default GEMM algo
Decoder layer #4 is created with date type [half].
Get igemm config from /home/mwm2166/.lightseq/igemm_configs/
[WARNING] /home/mwm2166/.lightseq/igemm_configs/ is not found; using default GEMM algo
Decoder layer #5 is created with date type [half].
QuantLinearLayer is created with date type [half].
CrossEntropyLayer is created with date type [half].
Lightseq Transformer config is  {'max_batch_tokens': 512, 'max_seq_len': 300, 'hidden_size': 1024, 'intermediate_size': 4096, 'nhead': 16, 'attn_prob_dropout_ratio': 0.1, 'activation_dropout_ratio': 0.1, 'hidden_dropout_ratio': 0.3, 'pre_layer_norm': True, 'fp16': True, 'local_rank': 0, 'activation_fn': 'relu', 'layer_id': 0}
Lightseq Transformer config is  {'max_batch_tokens': 512, 'max_seq_len': 300, 'hidden_size': 1024, 'intermediate_size': 4096, 'nhead': 16, 'attn_prob_dropout_ratio': 0.1, 'activation_dropout_ratio': 0.1, 'hidden_dropout_ratio': 0.3, 'pre_layer_norm': True, 'fp16': True, 'local_rank': 0, 'activation_fn': 'relu', 'layer_id': 1}
Lightseq Transformer config is  {'max_batch_tokens': 512, 'max_seq_len': 300, 'hidden_size': 1024, 'intermediate_size': 4096, 'nhead': 16, 'attn_prob_dropout_ratio': 0.1, 'activation_dropout_ratio': 0.1, 'hidden_dropout_ratio': 0.3, 'pre_layer_norm': True, 'fp16': True, 'local_rank': 0, 'activation_fn': 'relu', 'layer_id': 2}
Lightseq Transformer config is  {'max_batch_tokens': 512, 'max_seq_len': 300, 'hidden_size': 1024, 'intermediate_size': 4096, 'nhead': 16, 'attn_prob_dropout_ratio': 0.1, 'activation_dropout_ratio': 0.1, 'hidden_dropout_ratio': 0.3, 'pre_layer_norm': True, 'fp16': True, 'local_rank': 0, 'activation_fn': 'relu', 'layer_id': 3}
Lightseq Transformer config is  {'max_batch_tokens': 512, 'max_seq_len': 300, 'hidden_size': 1024, 'intermediate_size': 4096, 'nhead': 16, 'attn_prob_dropout_ratio': 0.1, 'activation_dropout_ratio': 0.1, 'hidden_dropout_ratio': 0.3, 'pre_layer_norm': True, 'fp16': True, 'local_rank': 0, 'activation_fn': 'relu', 'layer_id': 4}
Lightseq Transformer config is  {'max_batch_tokens': 512, 'max_seq_len': 300, 'hidden_size': 1024, 'intermediate_size': 4096, 'nhead': 16, 'attn_prob_dropout_ratio': 0.1, 'activation_dropout_ratio': 0.1, 'hidden_dropout_ratio': 0.3, 'pre_layer_norm': True, 'fp16': True, 'local_rank': 0, 'activation_fn': 'relu', 'layer_id': 5}
Lightseq Transformer config is  {'max_batch_tokens': 512, 'max_seq_len': 300, 'hidden_size': 1024, 'intermediate_size': 4096, 'nhead': 16, 'attn_prob_dropout_ratio': 0.1, 'activation_dropout_ratio': 0.1, 'hidden_dropout_ratio': 0.3, 'pre_layer_norm': True, 'fp16': True, 'local_rank': 0, 'nlayer': 6, 'activation_fn': 'relu', 'has_cross_attn': True, 'layer_id': 0}
Lightseq Transformer config is  {'max_batch_tokens': 512, 'max_seq_len': 300, 'hidden_size': 1024, 'intermediate_size': 4096, 'nhead': 16, 'attn_prob_dropout_ratio': 0.1, 'activation_dropout_ratio': 0.1, 'hidden_dropout_ratio': 0.3, 'pre_layer_norm': True, 'fp16': True, 'local_rank': 0, 'nlayer': 6, 'activation_fn': 'relu', 'has_cross_attn': True, 'layer_id': 1}
Lightseq Transformer config is  {'max_batch_tokens': 512, 'max_seq_len': 300, 'hidden_size': 1024, 'intermediate_size': 4096, 'nhead': 16, 'attn_prob_dropout_ratio': 0.1, 'activation_dropout_ratio': 0.1, 'hidden_dropout_ratio': 0.3, 'pre_layer_norm': True, 'fp16': True, 'local_rank': 0, 'nlayer': 6, 'activation_fn': 'relu', 'has_cross_attn': True, 'layer_id': 2}
Lightseq Transformer config is  {'max_batch_tokens': 512, 'max_seq_len': 300, 'hidden_size': 1024, 'intermediate_size': 4096, 'nhead': 16, 'attn_prob_dropout_ratio': 0.1, 'activation_dropout_ratio': 0.1, 'hidden_dropout_ratio': 0.3, 'pre_layer_norm': True, 'fp16': True, 'local_rank': 0, 'nlayer': 6, 'activation_fn': 'relu', 'has_cross_attn': True, 'layer_id': 3}
Lightseq Transformer config is  {'max_batch_tokens': 512, 'max_seq_len': 300, 'hidden_size': 1024, 'intermediate_size': 4096, 'nhead': 16, 'attn_prob_dropout_ratio': 0.1, 'activation_dropout_ratio': 0.1, 'hidden_dropout_ratio': 0.3, 'pre_layer_norm': True, 'fp16': True, 'local_rank': 0, 'nlayer': 6, 'activation_fn': 'relu', 'has_cross_attn': True, 'layer_id': 4}
Lightseq Transformer config is  {'max_batch_tokens': 512, 'max_seq_len': 300, 'hidden_size': 1024, 'intermediate_size': 4096, 'nhead': 16, 'attn_prob_dropout_ratio': 0.1, 'activation_dropout_ratio': 0.1, 'hidden_dropout_ratio': 0.3, 'pre_layer_norm': True, 'fp16': True, 'local_rank': 0, 'nlayer': 6, 'activation_fn': 'relu', 'has_cross_attn': True, 'layer_id': 5}
Time to load lightseq_layers op: 0.04262518882751465 seconds
Time to load lightseq_layers op: 0.040509700775146484 seconds
2024-12-12 04:46:13 | INFO | fairseq_cli.train | LSTransformerModel(
  (encoder): LSTransformerEncoder(
    (embed_tokens): LSTransformerEmbeddingLayer()
    (layers): ModuleList(
      (0): LSTransformerEncoderLayer()
      (1): LSTransformerEncoderLayer()
      (2): LSTransformerEncoderLayer()
      (3): LSTransformerEncoderLayer()
      (4): LSTransformerEncoderLayer()
      (5): LSTransformerEncoderLayer()
    )
    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
  )
  (decoder): LSTransformerDecoder(
    (embed_tokens): LSTransformerEmbeddingLayer()
    (layers): ModuleList(
      (0): LSFSTransformerDecoderLayer()
      (1): LSFSTransformerDecoderLayer()
      (2): LSFSTransformerDecoderLayer()
      (3): LSFSTransformerDecoderLayer()
      (4): LSFSTransformerDecoderLayer()
      (5): LSFSTransformerDecoderLayer()
    )
    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (output_projection): LSQuantLinearLayer()
  )
)
2024-12-12 04:46:13 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2024-12-12 04:46:13 | INFO | fairseq_cli.train | model: ls_transformer_wmt_en_de_big_t2t (LSTransformerModel)
2024-12-12 04:46:13 | INFO | fairseq_cli.train | criterion: ls_label_smoothed_cross_entropy (LSLabelSmoothedCrossEntropyCriterion)
2024-12-12 04:46:13 | INFO | fairseq_cli.train | num. model params: 261558490 (num. trained: 261558490)
2024-12-12 04:46:13 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-12-12 04:46:13 | INFO | fairseq.utils | rank   0: capabilities =  7.0  ; total memory = 15.782 GB ; name = Tesla V100-SXM2-16GB                    
2024-12-12 04:46:13 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-12-12 04:46:13 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2024-12-12 04:46:13 | INFO | fairseq_cli.train | max tokens per GPU = 512 and max sentences per GPU = None
2024-12-12 04:46:13 | INFO | fairseq.trainer | no existing checkpoint found checkpoints/checkpoint_last.pt
2024-12-12 04:46:13 | INFO | fairseq.trainer | loading train data for epoch 1
2024-12-12 04:46:14 | INFO | fairseq.data.data_utils | loaded 3900502 examples from: /tmp/wmt14_en_de/train.en-de.en
2024-12-12 04:46:14 | INFO | fairseq.data.data_utils | loaded 3900502 examples from: /tmp/wmt14_en_de/train.en-de.de
2024-12-12 04:46:14 | INFO | fairseq.tasks.translation | /tmp/wmt14_en_de/ train en-de 3900502 examples
2024-12-12 04:46:18 | INFO | fs_modules.ls_adam | using LightSeq Adam
[1/3] c++ -MMD -MF pybind_adam.o.d -DTORCH_EXTENSION_NAME=adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++14 -O3 -std=c++14 -g -Wno-reorder -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/pybind/pybind_adam.cpp -o pybind_adam.o 
[2/3] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/ops/includes -I/opt/conda/lib/python3.7/site-packages/lightseq/csrc/layers/includes -isystem /opt/conda/lib/python3.7/site-packages/torch/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.7/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.7/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /opt/conda/include/python3.7m -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_70,code=compute_70 -gencode=arch=compute_70,code=sm_70 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_70,code=sm_70 -gencode=arch=compute_70,code=compute_70 -c /opt/conda/lib/python3.7/site-packages/lightseq/csrc/kernels/fused_adam_kernel.cu -o fused_adam_kernel.cuda.o 
[3/3] c++ fused_adam_kernel.cuda.o pybind_adam.o -shared -L/opt/conda/lib/python3.7/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda_cu -ltorch_cuda_cpp -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o adam.so
Time to load adam op: 54.54823923110962 seconds
2024-12-12 04:47:13 | INFO | fairseq.trainer | begin training epoch 1
TransformerEmbeddingLayer #0 bind weights and grads.
TransformerEncoderLayer #0 bind weights and grads.
TransformerEncoderLayer #1 bind weights and grads.
TransformerEncoderLayer #2 bind weights and grads.
TransformerEncoderLayer #3 bind weights and grads.
TransformerEncoderLayer #4 bind weights and grads.
TransformerEncoderLayer #5 bind weights and grads.
TransformerEmbeddingLayer #1 bind weights and grads.
TransformerDecoderLayer #0 bind weights and grads.
Decoder layer #0 allocate encdec_kv memory
TransformerDecoderLayer #1 bind weights and grads.
TransformerDecoderLayer #2 bind weights and grads.
TransformerDecoderLayer #3 bind weights and grads.
TransformerDecoderLayer #4 bind weights and grads.
TransformerDecoderLayer #5 bind weights and grads.
2024-12-12 04:47:13 | INFO | train_inner | epoch 001:     10 / 312876 loss=25.396, nll_loss=25.389, ppl=4.39443e+07, wps=8896.8, ups=28.29, wpb=330.4, bsz=12, num_updates=10, lr=1.25e-06, gnorm=14.904, loss_scale=128, train_wall=0, wall=60
2024-12-12 04:47:13 | INFO | train_inner | epoch 001:     20 / 312876 loss=25.542, nll_loss=25.538, ppl=4.87319e+07, wps=9669.5, ups=28, wpb=345.3, bsz=7.4, num_updates=20, lr=2.5e-06, gnorm=15.499, loss_scale=128, train_wall=0, wall=60
2024-12-12 04:47:14 | INFO | train_inner | epoch 001:     30 / 312876 loss=24.205, nll_loss=24.205, ppl=1.93405e+07, wps=10691.1, ups=26.6, wpb=401.9, bsz=11.7, num_updates=30, lr=3.75e-06, gnorm=16.346, loss_scale=128, train_wall=0, wall=60
2024-12-12 04:47:14 | INFO | train_inner | epoch 001:     40 / 312876 loss=21.027, nll_loss=21.018, ppl=2.12379e+06, wps=10058, ups=26.75, wpb=376, bsz=13.6, num_updates=40, lr=5e-06, gnorm=15.547, loss_scale=128, train_wall=0, wall=61
2024-12-12 04:47:14 | INFO | train_inner | epoch 001:     50 / 312876 loss=17.375, nll_loss=17.361, ppl=168291, wps=11323.7, ups=27.69, wpb=408.9, bsz=16.5, num_updates=50, lr=6.25e-06, gnorm=7.957, loss_scale=128, train_wall=0, wall=61
2024-12-12 04:47:15 | INFO | train_inner | epoch 001:     60 / 312876 loss=16.07, nll_loss=16.027, ppl=66752.9, wps=11586.4, ups=29.45, wpb=393.4, bsz=12.2, num_updates=60, lr=7.5e-06, gnorm=4.14, loss_scale=128, train_wall=0, wall=61
2024-12-12 04:47:15 | INFO | train_inner | epoch 001:     70 / 312876 loss=15.663, nll_loss=15.593, ppl=49418.3, wps=10513.8, ups=30.07, wpb=349.6, bsz=11.8, num_updates=70, lr=8.75e-06, gnorm=3.667, loss_scale=128, train_wall=0, wall=62
2024-12-12 04:47:16 | INFO | train_inner | epoch 001:     80 / 312876 loss=15.274, nll_loss=15.161, ppl=36635.7, wps=10008.5, ups=29.24, wpb=342.3, bsz=10.1, num_updates=80, lr=1e-05, gnorm=3.395, loss_scale=128, train_wall=0, wall=62
2024-12-12 04:47:16 | INFO | train_inner | epoch 001:     90 / 312876 loss=14.888, nll_loss=14.728, ppl=27136.3, wps=11019.4, ups=29.03, wpb=379.6, bsz=17.4, num_updates=90, lr=1.125e-05, gnorm=3.182, loss_scale=128, train_wall=0, wall=62
2024-12-12 04:47:16 | INFO | train_inner | epoch 001:    100 / 312876 loss=14.707, nll_loss=14.522, ppl=23530.1, wps=10729, ups=29.43, wpb=364.6, bsz=13.5, num_updates=100, lr=1.25e-05, gnorm=2.846, loss_scale=128, train_wall=0, wall=63
2024-12-12 04:47:17 | INFO | train_inner | epoch 001:    110 / 312876 loss=14.387, nll_loss=14.165, ppl=18374.4, wps=10758.3, ups=29.43, wpb=365.6, bsz=12.8, num_updates=110, lr=1.375e-05, gnorm=2.629, loss_scale=128, train_wall=0, wall=63
2024-12-12 04:47:17 | INFO | train_inner | epoch 001:    120 / 312876 loss=14.121, nll_loss=13.87, ppl=14975.8, wps=12261.2, ups=29.32, wpb=418.2, bsz=10.3, num_updates=120, lr=1.5e-05, gnorm=2.451, loss_scale=128, train_wall=0, wall=63
2024-12-12 04:47:17 | INFO | train_inner | epoch 001:    130 / 312876 loss=13.878, nll_loss=13.602, ppl=12433.9, wps=11903.9, ups=29.65, wpb=401.5, bsz=8.5, num_updates=130, lr=1.625e-05, gnorm=2.24, loss_scale=128, train_wall=0, wall=64
2024-12-12 04:47:18 | INFO | train_inner | epoch 001:    140 / 312876 loss=13.557, nll_loss=13.245, ppl=9711.16, wps=11593.7, ups=29.28, wpb=396, bsz=14.4, num_updates=140, lr=1.75e-05, gnorm=2.236, loss_scale=128, train_wall=0, wall=64
2024-12-12 04:47:18 | INFO | train_inner | epoch 001:    150 / 312876 loss=13.362, nll_loss=13.026, ppl=8343.28, wps=10740.7, ups=27.04, wpb=397.2, bsz=14.6, num_updates=150, lr=1.875e-05, gnorm=2.255, loss_scale=128, train_wall=0, wall=64
2024-12-12 04:47:18 | INFO | train_inner | epoch 001:    160 / 312876 loss=13.302, nll_loss=12.959, ppl=7961.9, wps=12802.3, ups=29.33, wpb=436.5, bsz=12.3, num_updates=160, lr=2e-05, gnorm=1.973, loss_scale=128, train_wall=0, wall=65
2024-12-12 04:47:19 | INFO | train_inner | epoch 001:    170 / 312876 loss=12.982, nll_loss=12.6, ppl=6206.51, wps=12042.8, ups=29.87, wpb=403.2, bsz=10.4, num_updates=170, lr=2.125e-05, gnorm=1.953, loss_scale=128, train_wall=0, wall=65
2024-12-12 04:47:19 | INFO | train_inner | epoch 001:    180 / 312876 loss=13.014, nll_loss=12.631, ppl=6342.59, wps=10331.4, ups=29.99, wpb=344.5, bsz=8.7, num_updates=180, lr=2.25e-05, gnorm=2.05, loss_scale=128, train_wall=0, wall=65
2024-12-12 04:47:19 | INFO | train_inner | epoch 001:    190 / 312876 loss=12.786, nll_loss=12.375, ppl=5310.17, wps=11134.7, ups=30.43, wpb=365.9, bsz=9.8, num_updates=190, lr=2.375e-05, gnorm=2.021, loss_scale=128, train_wall=0, wall=66
2024-12-12 04:47:20 | INFO | train_inner | epoch 001:    200 / 312876 loss=12.64, nll_loss=12.205, ppl=4722.6, wps=10345.3, ups=30.7, wpb=337, bsz=8.5, num_updates=200, lr=2.5e-05, gnorm=2.009, loss_scale=128, train_wall=0, wall=66
2024-12-12 04:47:20 | INFO | train_inner | epoch 001:    210 / 312876 loss=12.618, nll_loss=12.176, ppl=4628.69, wps=11951.4, ups=29.55, wpb=404.4, bsz=13.2, num_updates=210, lr=2.625e-05, gnorm=1.96, loss_scale=128, train_wall=0, wall=66
2024-12-12 04:47:20 | INFO | train_inner | epoch 001:    220 / 312876 loss=12.434, nll_loss=11.964, ppl=3995.31, wps=10253.9, ups=30.16, wpb=340, bsz=12.8, num_updates=220, lr=2.75e-05, gnorm=2.002, loss_scale=128, train_wall=0, wall=67
2024-12-12 04:47:21 | INFO | train_inner | epoch 001:    230 / 312876 loss=12.518, nll_loss=12.051, ppl=4242.76, wps=11772.7, ups=30.03, wpb=392, bsz=8.4, num_updates=230, lr=2.875e-05, gnorm=1.792, loss_scale=128, train_wall=0, wall=67
2024-12-12 04:47:21 | INFO | train_inner | epoch 001:    240 / 312876 loss=12.311, nll_loss=11.815, ppl=3602.73, wps=11719.2, ups=29.59, wpb=396, bsz=14.4, num_updates=240, lr=3e-05, gnorm=1.888, loss_scale=128, train_wall=0, wall=67
2024-12-12 04:47:21 | INFO | train_inner | epoch 001:    250 / 312876 loss=11.977, nll_loss=11.434, ppl=2767.02, wps=10462.3, ups=29.45, wpb=355.2, bsz=17.6, num_updates=250, lr=3.125e-05, gnorm=2.099, loss_scale=128, train_wall=0, wall=68
2024-12-12 04:47:22 | INFO | train_inner | epoch 001:    260 / 312876 loss=12.13, nll_loss=11.598, ppl=3100.23, wps=12069.7, ups=29.82, wpb=404.8, bsz=16, num_updates=260, lr=3.25e-05, gnorm=1.869, loss_scale=128, train_wall=0, wall=68
2024-12-12 04:47:22 | INFO | train_inner | epoch 001:    270 / 312876 loss=12.092, nll_loss=11.552, ppl=3002.83, wps=12018.2, ups=29.75, wpb=404, bsz=14.4, num_updates=270, lr=3.375e-05, gnorm=1.839, loss_scale=128, train_wall=0, wall=68
2024-12-12 04:47:22 | INFO | train_inner | epoch 001:    280 / 312876 loss=11.996, nll_loss=11.438, ppl=2775.28, wps=11320.9, ups=29.14, wpb=388.5, bsz=12.7, num_updates=280, lr=3.5e-05, gnorm=1.932, loss_scale=128, train_wall=0, wall=69
2024-12-12 04:47:23 | INFO | train_inner | epoch 001:    290 / 312876 loss=12.202, nll_loss=11.663, ppl=3241.72, wps=10736, ups=30.37, wpb=353.5, bsz=10, num_updates=290, lr=3.625e-05, gnorm=1.892, loss_scale=128, train_wall=0, wall=69
2024-12-12 04:47:23 | INFO | train_inner | epoch 001:    300 / 312876 loss=12.105, nll_loss=11.549, ppl=2996.1, wps=11548.6, ups=30.28, wpb=381.4, bsz=12.4, num_updates=300, lr=3.75e-05, gnorm=1.996, loss_scale=128, train_wall=0, wall=69
2024-12-12 04:47:23 | INFO | train_inner | epoch 001:    310 / 312876 loss=12.207, nll_loss=11.657, ppl=3230.26, wps=10762, ups=29.56, wpb=364.1, bsz=13, num_updates=310, lr=3.875e-05, gnorm=2.026, loss_scale=128, train_wall=0, wall=70
2024-12-12 04:47:24 | INFO | train_inner | epoch 001:    320 / 312876 loss=11.999, nll_loss=11.426, ppl=2750.57, wps=11222.1, ups=28.5, wpb=393.8, bsz=10.9, num_updates=320, lr=4e-05, gnorm=1.843, loss_scale=128, train_wall=0, wall=70
2024-12-12 04:47:24 | INFO | train_inner | epoch 001:    330 / 312876 loss=11.687, nll_loss=11.07, ppl=2149.82, wps=11237.5, ups=29.43, wpb=381.9, bsz=13.1, num_updates=330, lr=4.125e-05, gnorm=1.873, loss_scale=128, train_wall=0, wall=71
2024-12-12 04:47:24 | INFO | train_inner | epoch 001:    340 / 312876 loss=11.776, nll_loss=11.161, ppl=2289.35, wps=11676.3, ups=30.16, wpb=387.2, bsz=16.6, num_updates=340, lr=4.25e-05, gnorm=2.075, loss_scale=128, train_wall=0, wall=71
2024-12-12 04:47:25 | INFO | train_inner | epoch 001:    350 / 312876 loss=11.765, nll_loss=11.143, ppl=2260.93, wps=10834.7, ups=30.01, wpb=361, bsz=13.5, num_updates=350, lr=4.375e-05, gnorm=2.076, loss_scale=128, train_wall=0, wall=71
2024-12-12 04:47:25 | INFO | train_inner | epoch 001:    360 / 312876 loss=11.887, nll_loss=11.283, ppl=2491.42, wps=10924.9, ups=30.52, wpb=358, bsz=11, num_updates=360, lr=4.5e-05, gnorm=1.888, loss_scale=128, train_wall=0, wall=72
2024-12-12 04:47:25 | INFO | train_inner | epoch 001:    370 / 312876 loss=11.791, nll_loss=11.173, ppl=2309.68, wps=10990.8, ups=29.77, wpb=369.2, bsz=11.5, num_updates=370, lr=4.625e-05, gnorm=1.851, loss_scale=128, train_wall=0, wall=72
2024-12-12 04:47:26 | INFO | train_inner | epoch 001:    380 / 312876 loss=11.916, nll_loss=11.312, ppl=2542.59, wps=11850.8, ups=29.69, wpb=399.2, bsz=12.8, num_updates=380, lr=4.75e-05, gnorm=1.831, loss_scale=128, train_wall=0, wall=72
2024-12-12 04:47:26 | INFO | train_inner | epoch 001:    390 / 312876 loss=11.702, nll_loss=11.073, ppl=2154.74, wps=10248.5, ups=29.72, wpb=344.8, bsz=9.6, num_updates=390, lr=4.875e-05, gnorm=1.918, loss_scale=128, train_wall=0, wall=73
2024-12-12 04:47:26 | INFO | train_inner | epoch 001:    400 / 312876 loss=11.673, nll_loss=11.03, ppl=2090.89, wps=10770.2, ups=29.74, wpb=362.2, bsz=11.9, num_updates=400, lr=5e-05, gnorm=1.831, loss_scale=128, train_wall=0, wall=73
2024-12-12 04:47:27 | INFO | train_inner | epoch 001:    410 / 312876 loss=12.053, nll_loss=11.457, ppl=2810.48, wps=11121.9, ups=29.62, wpb=375.5, bsz=8.8, num_updates=410, lr=5.125e-05, gnorm=2.056, loss_scale=128, train_wall=0, wall=73
2024-12-12 04:47:27 | INFO | train_inner | epoch 001:    420 / 312876 loss=11.569, nll_loss=10.916, ppl=1932.17, wps=10639.8, ups=30.02, wpb=354.4, bsz=13.6, num_updates=420, lr=5.25e-05, gnorm=1.909, loss_scale=128, train_wall=0, wall=74
2024-12-12 04:47:27 | INFO | train_inner | epoch 001:    430 / 312876 loss=11.62, nll_loss=10.969, ppl=2004.8, wps=11296.1, ups=30.15, wpb=374.7, bsz=12.5, num_updates=430, lr=5.375e-05, gnorm=1.881, loss_scale=128, train_wall=0, wall=74
2024-12-12 04:47:28 | INFO | train_inner | epoch 001:    440 / 312876 loss=11.667, nll_loss=11.014, ppl=2067.98, wps=11468.5, ups=29.42, wpb=389.8, bsz=15, num_updates=440, lr=5.5e-05, gnorm=1.984, loss_scale=128, train_wall=0, wall=74
2024-12-12 04:47:28 | INFO | train_inner | epoch 001:    450 / 312876 loss=11.588, nll_loss=10.932, ppl=1954.16, wps=10849, ups=29.24, wpb=371, bsz=12.5, num_updates=450, lr=5.625e-05, gnorm=1.826, loss_scale=128, train_wall=0, wall=75
2024-12-12 04:47:28 | INFO | train_inner | epoch 001:    460 / 312876 loss=11.465, nll_loss=10.79, ppl=1770.65, wps=11039.9, ups=29.87, wpb=369.6, bsz=15.2, num_updates=460, lr=5.75e-05, gnorm=1.997, loss_scale=128, train_wall=0, wall=75
2024-12-12 04:47:29 | INFO | train_inner | epoch 001:    470 / 312876 loss=11.763, nll_loss=11.117, ppl=2220.98, wps=10916.9, ups=29.41, wpb=371.2, bsz=16.8, num_updates=470, lr=5.875e-05, gnorm=2.74, loss_scale=128, train_wall=0, wall=75
2024-12-12 04:47:29 | INFO | train_inner | epoch 001:    480 / 312876 loss=11.748, nll_loss=11.115, ppl=2217.48, wps=10621.7, ups=30.02, wpb=353.8, bsz=10.9, num_updates=480, lr=6e-05, gnorm=2.113, loss_scale=128, train_wall=0, wall=76
2024-12-12 04:47:29 | INFO | train_inner | epoch 001:    490 / 312876 loss=11.721, nll_loss=11.079, ppl=2163.45, wps=10141.6, ups=30.11, wpb=336.8, bsz=9.6, num_updates=490, lr=6.125e-05, gnorm=2.066, loss_scale=128, train_wall=0, wall=76
2024-12-12 04:47:30 | INFO | train_inner | epoch 001:    500 / 312876 loss=11.737, nll_loss=11.097, ppl=2190.08, wps=11295.7, ups=29.52, wpb=382.6, bsz=15.9, num_updates=500, lr=6.25e-05, gnorm=2.029, loss_scale=128, train_wall=0, wall=76
2024-12-12 04:47:30 | INFO | train_inner | epoch 001:    510 / 312876 loss=11.482, nll_loss=10.81, ppl=1795.02, wps=10544.2, ups=29.55, wpb=356.8, bsz=17.6, num_updates=510, lr=6.375e-05, gnorm=2.056, loss_scale=128, train_wall=0, wall=77
2024-12-12 04:47:30 | INFO | train_inner | epoch 001:    520 / 312876 loss=11.686, nll_loss=11.042, ppl=2108.98, wps=11096.7, ups=29.56, wpb=375.4, bsz=13.2, num_updates=520, lr=6.5e-05, gnorm=1.88, loss_scale=128, train_wall=0, wall=77
2024-12-12 04:47:31 | INFO | train_inner | epoch 001:    530 / 312876 loss=11.522, nll_loss=10.857, ppl=1854.44, wps=10925.9, ups=29.89, wpb=365.5, bsz=11.7, num_updates=530, lr=6.625e-05, gnorm=1.893, loss_scale=128, train_wall=0, wall=77
2024-12-12 04:47:31 | INFO | train_inner | epoch 001:    540 / 312876 loss=11.608, nll_loss=10.95, ppl=1977.68, wps=10909.2, ups=29.86, wpb=365.4, bsz=10.9, num_updates=540, lr=6.75e-05, gnorm=1.917, loss_scale=128, train_wall=0, wall=78
2024-12-12 04:47:31 | INFO | train_inner | epoch 001:    550 / 312876 loss=11.541, nll_loss=10.88, ppl=1884.25, wps=11932.4, ups=28.87, wpb=413.3, bsz=11.2, num_updates=550, lr=6.875e-05, gnorm=1.888, loss_scale=128, train_wall=0, wall=78
2024-12-12 04:47:32 | INFO | train_inner | epoch 001:    560 / 312876 loss=11.606, nll_loss=10.949, ppl=1977.18, wps=11456, ups=29.59, wpb=387.2, bsz=12.8, num_updates=560, lr=7e-05, gnorm=1.841, loss_scale=128, train_wall=0, wall=78
2024-12-12 04:47:32 | INFO | train_inner | epoch 001:    570 / 312876 loss=11.558, nll_loss=10.897, ppl=1906.58, wps=10679, ups=28.98, wpb=368.5, bsz=11.9, num_updates=570, lr=7.125e-05, gnorm=1.807, loss_scale=128, train_wall=0, wall=79
2024-12-12 04:47:32 | INFO | train_inner | epoch 001:    580 / 312876 loss=11.326, nll_loss=10.622, ppl=1576.44, wps=10984.2, ups=28.54, wpb=384.9, bsz=18.8, num_updates=580, lr=7.25e-05, gnorm=2.338, loss_scale=128, train_wall=0, wall=79
2024-12-12 04:47:33 | INFO | train_inner | epoch 001:    590 / 312876 loss=11.532, nll_loss=10.876, ppl=1878.99, wps=11751.3, ups=28.87, wpb=407, bsz=15.9, num_updates=590, lr=7.375e-05, gnorm=2.01, loss_scale=128, train_wall=0, wall=79
2024-12-12 04:47:33 | INFO | train_inner | epoch 001:    600 / 312876 loss=11.382, nll_loss=10.686, ppl=1647.61, wps=10809.5, ups=29.02, wpb=372.5, bsz=12.3, num_updates=600, lr=7.5e-05, gnorm=2.352, loss_scale=128, train_wall=0, wall=80
2024-12-12 04:47:33 | INFO | train_inner | epoch 001:    610 / 312876 loss=11.744, nll_loss=11.104, ppl=2201, wps=11199.2, ups=29.07, wpb=385.3, bsz=11, num_updates=610, lr=7.625e-05, gnorm=1.85, loss_scale=128, train_wall=0, wall=80
2024-12-12 04:47:34 | INFO | train_inner | epoch 001:    620 / 312876 loss=11.671, nll_loss=11.038, ppl=2102.31, wps=11840.6, ups=29.66, wpb=399.2, bsz=11, num_updates=620, lr=7.75e-05, gnorm=1.78, loss_scale=128, train_wall=0, wall=80
2024-12-12 04:47:34 | INFO | train_inner | epoch 001:    630 / 312876 loss=11.488, nll_loss=10.81, ppl=1795.56, wps=11376.7, ups=29.32, wpb=388, bsz=14.1, num_updates=630, lr=7.875e-05, gnorm=1.817, loss_scale=128, train_wall=0, wall=81
2024-12-12 04:47:34 | INFO | train_inner | epoch 001:    640 / 312876 loss=11.421, nll_loss=10.741, ppl=1711.86, wps=11357.2, ups=29.58, wpb=384, bsz=12.6, num_updates=640, lr=8e-05, gnorm=1.846, loss_scale=128, train_wall=0, wall=81
2024-12-12 04:47:35 | INFO | train_inner | epoch 001:    650 / 312876 loss=11.52, nll_loss=10.857, ppl=1855.23, wps=11059.6, ups=30.12, wpb=367.2, bsz=10.1, num_updates=650, lr=8.125e-05, gnorm=1.965, loss_scale=128, train_wall=0, wall=81
2024-12-12 04:47:35 | INFO | train_inner | epoch 001:    660 / 312876 loss=11.498, nll_loss=10.831, ppl=1821.37, wps=11513.3, ups=29.37, wpb=392, bsz=12.8, num_updates=660, lr=8.25e-05, gnorm=2.26, loss_scale=128, train_wall=0, wall=82
2024-12-12 04:47:35 | INFO | train_inner | epoch 001:    670 / 312876 loss=11.346, nll_loss=10.659, ppl=1616.6, wps=10159.2, ups=29.09, wpb=349.2, bsz=15, num_updates=670, lr=8.375e-05, gnorm=2.302, loss_scale=128, train_wall=0, wall=82
2024-12-12 04:47:36 | INFO | train_inner | epoch 001:    680 / 312876 loss=11.47, nll_loss=10.776, ppl=1753.23, wps=10375.5, ups=28.8, wpb=360.3, bsz=10.8, num_updates=680, lr=8.5e-05, gnorm=2.159, loss_scale=128, train_wall=0, wall=82
2024-12-12 04:47:36 | INFO | train_inner | epoch 001:    690 / 312876 loss=11.463, nll_loss=10.795, ppl=1777.29, wps=9450.6, ups=27.43, wpb=344.5, bsz=12.8, num_updates=690, lr=8.625e-05, gnorm=1.917, loss_scale=128, train_wall=0, wall=83
2024-12-12 04:47:37 | INFO | train_inner | epoch 001:    700 / 312876 loss=11.387, nll_loss=10.7, ppl=1663.09, wps=10406.2, ups=27.09, wpb=384.2, bsz=15.7, num_updates=700, lr=8.75e-05, gnorm=2.076, loss_scale=128, train_wall=0, wall=83
2024-12-12 04:47:37 | INFO | train_inner | epoch 001:    710 / 312876 loss=11.514, nll_loss=10.852, ppl=1847.8, wps=9947, ups=27.51, wpb=361.6, bsz=14.4, num_updates=710, lr=8.875e-05, gnorm=1.98, loss_scale=128, train_wall=0, wall=83
2024-12-12 04:47:37 | INFO | train_inner | epoch 001:    720 / 312876 loss=11.402, nll_loss=10.72, ppl=1687.06, wps=10588.7, ups=26.73, wpb=396.2, bsz=14.2, num_updates=720, lr=9e-05, gnorm=2.094, loss_scale=128, train_wall=0, wall=84
2024-12-12 04:47:38 | INFO | train_inner | epoch 001:    730 / 312876 loss=11.319, nll_loss=10.621, ppl=1574.57, wps=10217.9, ups=27.59, wpb=370.4, bsz=16, num_updates=730, lr=9.125e-05, gnorm=2.185, loss_scale=128, train_wall=0, wall=84
2024-12-12 04:47:38 | INFO | train_inner | epoch 001:    740 / 312876 loss=11.466, nll_loss=10.795, ppl=1777.08, wps=10032.9, ups=27.56, wpb=364, bsz=12, num_updates=740, lr=9.25e-05, gnorm=1.926, loss_scale=128, train_wall=0, wall=85
2024-12-12 04:47:38 | INFO | train_inner | epoch 001:    750 / 312876 loss=11.331, nll_loss=10.646, ppl=1601.96, wps=10079.1, ups=29.21, wpb=345, bsz=10.8, num_updates=750, lr=9.375e-05, gnorm=2.131, loss_scale=128, train_wall=0, wall=85
2024-12-12 04:47:39 | INFO | train_inner | epoch 001:    760 / 312876 loss=11.171, nll_loss=10.446, ppl=1394.93, wps=11299.1, ups=28.5, wpb=396.4, bsz=12.5, num_updates=760, lr=9.5e-05, gnorm=2.113, loss_scale=128, train_wall=0, wall=85
2024-12-12 04:47:39 | INFO | train_inner | epoch 001:    770 / 312876 loss=11.297, nll_loss=10.596, ppl=1547.91, wps=11131.4, ups=29.36, wpb=379.1, bsz=12.7, num_updates=770, lr=9.625e-05, gnorm=2.486, loss_scale=128, train_wall=0, wall=86
2024-12-12 04:47:39 | INFO | train_inner | epoch 001:    780 / 312876 loss=11.308, nll_loss=10.625, ppl=1579.47, wps=11482.2, ups=29.59, wpb=388, bsz=13.2, num_updates=780, lr=9.75e-05, gnorm=1.838, loss_scale=128, train_wall=0, wall=86
2024-12-12 04:47:40 | INFO | train_inner | epoch 001:    790 / 312876 loss=11.228, nll_loss=10.517, ppl=1464.89, wps=11247, ups=29.41, wpb=382.4, bsz=16, num_updates=790, lr=9.875e-05, gnorm=1.839, loss_scale=128, train_wall=0, wall=86
2024-12-12 04:47:40 | INFO | train_inner | epoch 001:    800 / 312876 loss=11.399, nll_loss=10.728, ppl=1696.26, wps=11277.3, ups=28.81, wpb=391.4, bsz=13.4, num_updates=800, lr=0.0001, gnorm=1.86, loss_scale=128, train_wall=0, wall=87
2024-12-12 04:47:40 | INFO | train_inner | epoch 001:    810 / 312876 loss=11.502, nll_loss=10.83, ppl=1820.58, wps=11292.3, ups=29.41, wpb=383.9, bsz=10.3, num_updates=810, lr=0.00010125, gnorm=1.88, loss_scale=128, train_wall=0, wall=87
2024-12-12 04:47:41 | INFO | train_inner | epoch 001:    820 / 312876 loss=11.51, nll_loss=10.854, ppl=1851.06, wps=10794.5, ups=29.84, wpb=361.8, bsz=10.2, num_updates=820, lr=0.0001025, gnorm=2.028, loss_scale=128, train_wall=0, wall=87
2024-12-12 04:47:41 | INFO | train_inner | epoch 001:    830 / 312876 loss=11.162, nll_loss=10.439, ppl=1388.06, wps=11006.5, ups=29.52, wpb=372.8, bsz=11.9, num_updates=830, lr=0.00010375, gnorm=1.985, loss_scale=128, train_wall=0, wall=88
2024-12-12 04:47:41 | INFO | train_inner | epoch 001:    840 / 312876 loss=11.041, nll_loss=10.314, ppl=1273.04, wps=10619.9, ups=29.76, wpb=356.8, bsz=12.8, num_updates=840, lr=0.000105, gnorm=2.457, loss_scale=128, train_wall=0, wall=88
2024-12-12 04:47:42 | INFO | train_inner | epoch 001:    850 / 312876 loss=11.229, nll_loss=10.524, ppl=1472.86, wps=9937.6, ups=30.12, wpb=329.9, bsz=10.3, num_updates=850, lr=0.00010625, gnorm=2.263, loss_scale=128, train_wall=0, wall=88
2024-12-12 04:47:42 | INFO | train_inner | epoch 001:    860 / 312876 loss=11.335, nll_loss=10.65, ppl=1606.84, wps=11379.2, ups=29.12, wpb=390.8, bsz=11.9, num_updates=860, lr=0.0001075, gnorm=1.831, loss_scale=128, train_wall=0, wall=89
2024-12-12 04:47:42 | INFO | train_inner | epoch 001:    870 / 312876 loss=11.165, nll_loss=10.451, ppl=1400.2, wps=11074.9, ups=29.44, wpb=376.2, bsz=11.7, num_updates=870, lr=0.00010875, gnorm=1.941, loss_scale=128, train_wall=0, wall=89
2024-12-12 04:47:43 | INFO | train_inner | epoch 001:    880 / 312876 loss=11.358, nll_loss=10.678, ppl=1638.59, wps=10763.9, ups=29.59, wpb=363.8, bsz=10.4, num_updates=880, lr=0.00011, gnorm=1.847, loss_scale=128, train_wall=0, wall=89
2024-12-12 04:47:43 | INFO | train_inner | epoch 001:    890 / 312876 loss=11.138, nll_loss=10.418, ppl=1367.8, wps=12163.4, ups=29.11, wpb=417.8, bsz=18.2, num_updates=890, lr=0.00011125, gnorm=1.988, loss_scale=128, train_wall=0, wall=90
2024-12-12 04:47:43 | INFO | train_inner | epoch 001:    900 / 312876 loss=11.228, nll_loss=10.515, ppl=1463.47, wps=11537, ups=28.9, wpb=399.2, bsz=13.2, num_updates=900, lr=0.0001125, gnorm=2.078, loss_scale=128, train_wall=0, wall=90
2024-12-12 04:47:44 | INFO | train_inner | epoch 001:    910 / 312876 loss=11.252, nll_loss=10.558, ppl=1507.15, wps=11021, ups=29.34, wpb=375.6, bsz=9.3, num_updates=910, lr=0.00011375, gnorm=1.849, loss_scale=128, train_wall=0, wall=90
2024-12-12 04:47:44 | INFO | train_inner | epoch 001:    920 / 312876 loss=11.306, nll_loss=10.614, ppl=1567.3, wps=11601.8, ups=29.13, wpb=398.3, bsz=10.3, num_updates=920, lr=0.000115, gnorm=1.876, loss_scale=128, train_wall=0, wall=91
2024-12-12 04:47:45 | INFO | train_inner | epoch 001:    930 / 312876 loss=11.34, nll_loss=10.659, ppl=1617.21, wps=10842.3, ups=29.39, wpb=368.9, bsz=10.7, num_updates=930, lr=0.00011625, gnorm=2.205, loss_scale=128, train_wall=0, wall=91
2024-12-12 04:47:45 | INFO | train_inner | epoch 001:    940 / 312876 loss=11.117, nll_loss=10.389, ppl=1340.82, wps=10903.4, ups=28.69, wpb=380, bsz=14.4, num_updates=940, lr=0.0001175, gnorm=2.38, loss_scale=128, train_wall=0, wall=91
2024-12-12 04:47:45 | INFO | train_inner | epoch 001:    950 / 312876 loss=11.216, nll_loss=10.484, ppl=1432.12, wps=10793.8, ups=28.65, wpb=376.8, bsz=19, num_updates=950, lr=0.00011875, gnorm=2.038, loss_scale=128, train_wall=0, wall=92
2024-12-12 04:47:46 | INFO | train_inner | epoch 001:    960 / 312876 loss=11.057, nll_loss=10.334, ppl=1290.44, wps=11503.1, ups=28.82, wpb=399.2, bsz=12, num_updates=960, lr=0.00012, gnorm=1.919, loss_scale=128, train_wall=0, wall=92
2024-12-12 04:47:46 | INFO | train_inner | epoch 001:    970 / 312876 loss=11.223, nll_loss=10.518, ppl=1465.99, wps=11584.8, ups=29.93, wpb=387.1, bsz=10.3, num_updates=970, lr=0.00012125, gnorm=1.883, loss_scale=128, train_wall=0, wall=92
2024-12-12 04:47:46 | INFO | train_inner | epoch 001:    980 / 312876 loss=10.946, nll_loss=10.203, ppl=1179.1, wps=11442.4, ups=28.74, wpb=398.1, bsz=16.7, num_updates=980, lr=0.0001225, gnorm=2.175, loss_scale=128, train_wall=0, wall=93
2024-12-12 04:47:47 | INFO | train_inner | epoch 001:    990 / 312876 loss=10.979, nll_loss=10.246, ppl=1214.21, wps=10305.3, ups=29, wpb=355.3, bsz=11.1, num_updates=990, lr=0.00012375, gnorm=2.015, loss_scale=128, train_wall=0, wall=93
2024-12-12 04:47:47 | INFO | train_inner | epoch 001:   1000 / 312876 loss=10.881, nll_loss=10.142, ppl=1130.17, wps=8726.1, ups=28.08, wpb=310.8, bsz=14.2, num_updates=1000, lr=0.000125, gnorm=2.306, loss_scale=128, train_wall=0, wall=93
2024-12-12 04:47:47 | INFO | train_inner | epoch 001:   1010 / 312876 loss=10.944, nll_loss=10.205, ppl=1180.35, wps=10845.3, ups=27.5, wpb=394.4, bsz=16, num_updates=1010, lr=0.00012625, gnorm=1.89, loss_scale=128, train_wall=0, wall=94
2024-12-12 04:47:48 | INFO | train_inner | epoch 001:   1020 / 312876 loss=11.074, nll_loss=10.358, ppl=1312.7, wps=10313, ups=28, wpb=368.3, bsz=10.2, num_updates=1020, lr=0.0001275, gnorm=2.037, loss_scale=128, train_wall=0, wall=94
2024-12-12 04:47:48 | INFO | train_inner | epoch 001:   1030 / 312876 loss=10.938, nll_loss=10.189, ppl=1167.33, wps=11408.1, ups=29.4, wpb=388, bsz=12.8, num_updates=1030, lr=0.00012875, gnorm=1.978, loss_scale=128, train_wall=0, wall=95
2024-12-12 04:47:48 | INFO | train_inner | epoch 001:   1040 / 312876 loss=11.051, nll_loss=10.334, ppl=1290.88, wps=10342.7, ups=29.72, wpb=348, bsz=14.4, num_updates=1040, lr=0.00013, gnorm=2.15, loss_scale=128, train_wall=0, wall=95
2024-12-12 04:47:49 | INFO | train_inner | epoch 001:   1050 / 312876 loss=11.15, nll_loss=10.435, ppl=1384.62, wps=10277.9, ups=29.45, wpb=349, bsz=10.6, num_updates=1050, lr=0.00013125, gnorm=2.173, loss_scale=128, train_wall=0, wall=95
2024-12-12 04:47:49 | INFO | train_inner | epoch 001:   1060 / 312876 loss=10.987, nll_loss=10.257, ppl=1224.03, wps=11301.9, ups=29.32, wpb=385.5, bsz=11.1, num_updates=1060, lr=0.0001325, gnorm=1.991, loss_scale=128, train_wall=0, wall=96
2024-12-12 04:47:49 | INFO | train_inner | epoch 001:   1070 / 312876 loss=11.111, nll_loss=10.394, ppl=1345.15, wps=10642, ups=29.24, wpb=364, bsz=11.2, num_updates=1070, lr=0.00013375, gnorm=2.01, loss_scale=128, train_wall=0, wall=96
2024-12-12 04:47:50 | INFO | train_inner | epoch 001:   1080 / 312876 loss=11.109, nll_loss=10.402, ppl=1352.83, wps=11630, ups=29.02, wpb=400.8, bsz=13.6, num_updates=1080, lr=0.000135, gnorm=1.806, loss_scale=128, train_wall=0, wall=96
2024-12-12 04:47:50 | INFO | train_inner | epoch 001:   1090 / 312876 loss=11.228, nll_loss=10.539, ppl=1487.97, wps=11500.2, ups=29.05, wpb=395.9, bsz=13.8, num_updates=1090, lr=0.00013625, gnorm=2.005, loss_scale=128, train_wall=0, wall=97
2024-12-12 04:47:50 | INFO | train_inner | epoch 001:   1100 / 312876 loss=10.868, nll_loss=10.106, ppl=1101.99, wps=11461.3, ups=29.02, wpb=395, bsz=17.5, num_updates=1100, lr=0.0001375, gnorm=2.119, loss_scale=128, train_wall=0, wall=97
2024-12-12 04:47:51 | INFO | train_inner | epoch 001:   1110 / 312876 loss=11.389, nll_loss=10.709, ppl=1673.69, wps=10238.9, ups=30.18, wpb=339.3, bsz=9.8, num_updates=1110, lr=0.00013875, gnorm=2.322, loss_scale=128, train_wall=0, wall=97
2024-12-12 04:47:51 | INFO | train_inner | epoch 001:   1120 / 312876 loss=10.852, nll_loss=10.112, ppl=1106.54, wps=10666.7, ups=29.43, wpb=362.4, bsz=12, num_updates=1120, lr=0.00014, gnorm=2.068, loss_scale=128, train_wall=0, wall=98
2024-12-12 04:47:51 | INFO | train_inner | epoch 001:   1130 / 312876 loss=10.977, nll_loss=10.236, ppl=1205.59, wps=11309.3, ups=29.87, wpb=378.6, bsz=12.8, num_updates=1130, lr=0.00014125, gnorm=1.924, loss_scale=128, train_wall=0, wall=98
2024-12-12 04:47:52 | INFO | train_inner | epoch 001:   1140 / 312876 loss=11.198, nll_loss=10.504, ppl=1452.1, wps=11667.8, ups=29.62, wpb=393.9, bsz=9.5, num_updates=1140, lr=0.0001425, gnorm=2.058, loss_scale=128, train_wall=0, wall=98
2024-12-12 04:47:52 | INFO | train_inner | epoch 001:   1150 / 312876 loss=10.855, nll_loss=10.092, ppl=1091.64, wps=11418.8, ups=29.86, wpb=382.4, bsz=16, num_updates=1150, lr=0.00014375, gnorm=2.231, loss_scale=128, train_wall=0, wall=99
2024-12-12 04:47:52 | INFO | train_inner | epoch 001:   1160 / 312876 loss=10.899, nll_loss=10.162, ppl=1145.64, wps=12446, ups=29.51, wpb=421.7, bsz=16.6, num_updates=1160, lr=0.000145, gnorm=1.841, loss_scale=128, train_wall=0, wall=99
2024-12-12 04:47:53 | INFO | train_inner | epoch 001:   1170 / 312876 loss=10.907, nll_loss=10.161, ppl=1145.16, wps=11386, ups=29.49, wpb=386.1, bsz=12.5, num_updates=1170, lr=0.00014625, gnorm=1.926, loss_scale=128, train_wall=0, wall=99
2024-12-12 04:47:53 | INFO | train_inner | epoch 001:   1180 / 312876 loss=11.213, nll_loss=10.518, ppl=1465.88, wps=10585.1, ups=29.48, wpb=359.1, bsz=7.2, num_updates=1180, lr=0.0001475, gnorm=2.018, loss_scale=128, train_wall=0, wall=100
2024-12-12 04:47:53 | INFO | train_inner | epoch 001:   1190 / 312876 loss=11.107, nll_loss=10.398, ppl=1349.76, wps=10251.8, ups=30.01, wpb=341.6, bsz=10.4, num_updates=1190, lr=0.00014875, gnorm=2.151, loss_scale=128, train_wall=0, wall=100
2024-12-12 04:47:54 | INFO | train_inner | epoch 001:   1200 / 312876 loss=11.182, nll_loss=10.483, ppl=1431.18, wps=11558.7, ups=29.85, wpb=387.2, bsz=13.6, num_updates=1200, lr=0.00015, gnorm=1.916, loss_scale=128, train_wall=0, wall=100
2024-12-12 04:47:54 | INFO | train_inner | epoch 001:   1210 / 312876 loss=11.019, nll_loss=10.298, ppl=1259.1, wps=11369.5, ups=30.11, wpb=377.6, bsz=15.2, num_updates=1210, lr=0.00015125, gnorm=2.217, loss_scale=128, train_wall=0, wall=101
2024-12-12 04:47:54 | INFO | train_inner | epoch 001:   1220 / 312876 loss=10.878, nll_loss=10.125, ppl=1116.52, wps=9990.1, ups=30.16, wpb=331.2, bsz=10.4, num_updates=1220, lr=0.0001525, gnorm=1.94, loss_scale=128, train_wall=0, wall=101
2024-12-12 04:47:55 | INFO | train_inner | epoch 001:   1230 / 312876 loss=11.006, nll_loss=10.28, ppl=1243.03, wps=11793, ups=29.13, wpb=404.8, bsz=14.4, num_updates=1230, lr=0.00015375, gnorm=2.083, loss_scale=128, train_wall=0, wall=101
2024-12-12 04:47:55 | INFO | train_inner | epoch 001:   1240 / 312876 loss=10.933, nll_loss=10.192, ppl=1169.88, wps=10771.2, ups=29.99, wpb=359.2, bsz=12, num_updates=1240, lr=0.000155, gnorm=2.075, loss_scale=128, train_wall=0, wall=102
2024-12-12 04:47:55 | INFO | train_inner | epoch 001:   1250 / 312876 loss=10.877, nll_loss=10.142, ppl=1130.02, wps=11105.3, ups=29.98, wpb=370.4, bsz=14.4, num_updates=1250, lr=0.00015625, gnorm=2.203, loss_scale=128, train_wall=0, wall=102
2024-12-12 04:47:56 | INFO | train_inner | epoch 001:   1260 / 312876 loss=11.093, nll_loss=10.37, ppl=1323.44, wps=9553.1, ups=29.83, wpb=320.2, bsz=8.6, num_updates=1260, lr=0.0001575, gnorm=2.163, loss_scale=128, train_wall=0, wall=102
2024-12-12 04:47:56 | INFO | train_inner | epoch 001:   1270 / 312876 loss=10.678, nll_loss=9.914, ppl=964.77, wps=11394.8, ups=29.81, wpb=382.2, bsz=18.7, num_updates=1270, lr=0.00015875, gnorm=2.145, loss_scale=128, train_wall=0, wall=103
2024-12-12 04:47:56 | INFO | train_inner | epoch 001:   1280 / 312876 loss=10.98, nll_loss=10.246, ppl=1214.37, wps=10485.2, ups=29.45, wpb=356, bsz=13.6, num_updates=1280, lr=0.00016, gnorm=1.949, loss_scale=128, train_wall=0, wall=103
2024-12-12 04:47:57 | INFO | train_inner | epoch 001:   1290 / 312876 loss=10.944, nll_loss=10.214, ppl=1187.34, wps=11281.4, ups=29.61, wpb=381, bsz=11.9, num_updates=1290, lr=0.00016125, gnorm=1.815, loss_scale=128, train_wall=0, wall=103
2024-12-12 04:47:57 | INFO | train_inner | epoch 001:   1300 / 312876 loss=10.831, nll_loss=10.083, ppl=1084.69, wps=10743.3, ups=29.58, wpb=363.2, bsz=12.4, num_updates=1300, lr=0.0001625, gnorm=2.099, loss_scale=128, train_wall=0, wall=104
2024-12-12 04:47:57 | INFO | train_inner | epoch 001:   1310 / 312876 loss=10.84, nll_loss=10.095, ppl=1094.02, wps=12145.2, ups=29.26, wpb=415.1, bsz=15.1, num_updates=1310, lr=0.00016375, gnorm=1.859, loss_scale=128, train_wall=0, wall=104
2024-12-12 04:47:58 | INFO | train_inner | epoch 001:   1320 / 312876 loss=11.012, nll_loss=10.294, ppl=1255.09, wps=11172.8, ups=29.62, wpb=377.2, bsz=14, num_updates=1320, lr=0.000165, gnorm=2.006, loss_scale=128, train_wall=0, wall=104
2024-12-12 04:47:58 | INFO | train_inner | epoch 001:   1330 / 312876 loss=10.881, nll_loss=10.132, ppl=1122.1, wps=10814.7, ups=29.92, wpb=361.4, bsz=13.2, num_updates=1330, lr=0.00016625, gnorm=2.253, loss_scale=128, train_wall=0, wall=105
2024-12-12 04:47:58 | INFO | train_inner | epoch 001:   1340 / 312876 loss=10.772, nll_loss=10.007, ppl=1029.11, wps=10914, ups=29.15, wpb=374.4, bsz=15.2, num_updates=1340, lr=0.0001675, gnorm=2.271, loss_scale=128, train_wall=0, wall=105
2024-12-12 04:47:59 | INFO | train_inner | epoch 001:   1350 / 312876 loss=10.948, nll_loss=10.219, ppl=1191.56, wps=11637.9, ups=29.25, wpb=397.9, bsz=8.8, num_updates=1350, lr=0.00016875, gnorm=1.935, loss_scale=128, train_wall=0, wall=105
2024-12-12 04:47:59 | INFO | train_inner | epoch 001:   1360 / 312876 loss=10.663, nll_loss=9.891, ppl=949.43, wps=10827.1, ups=29.68, wpb=364.8, bsz=18.4, num_updates=1360, lr=0.00017, gnorm=2.264, loss_scale=128, train_wall=0, wall=106
2024-12-12 04:47:59 | INFO | train_inner | epoch 001:   1370 / 312876 loss=11.176, nll_loss=10.472, ppl=1419.93, wps=10749.2, ups=30.47, wpb=352.8, bsz=12, num_updates=1370, lr=0.00017125, gnorm=1.868, loss_scale=128, train_wall=0, wall=106
2024-12-12 04:48:00 | INFO | train_inner | epoch 001:   1380 / 312876 loss=11.136, nll_loss=10.42, ppl=1370.23, wps=12038.9, ups=29.43, wpb=409, bsz=9.5, num_updates=1380, lr=0.0001725, gnorm=1.813, loss_scale=128, train_wall=0, wall=106
2024-12-12 04:48:00 | INFO | train_inner | epoch 001:   1390 / 312876 loss=10.868, nll_loss=10.129, ppl=1119.54, wps=11247.2, ups=29.11, wpb=386.4, bsz=9.3, num_updates=1390, lr=0.00017375, gnorm=1.963, loss_scale=128, train_wall=0, wall=107
2024-12-12 04:48:01 | INFO | train_inner | epoch 001:   1400 / 312876 loss=10.839, nll_loss=10.084, ppl=1085.31, wps=10064.1, ups=29.4, wpb=342.3, bsz=10.9, num_updates=1400, lr=0.000175, gnorm=1.982, loss_scale=128, train_wall=0, wall=107
2024-12-12 04:48:01 | INFO | train_inner | epoch 001:   1410 / 312876 loss=10.956, nll_loss=10.223, ppl=1195.4, wps=12042.5, ups=29.81, wpb=404, bsz=13.6, num_updates=1410, lr=0.00017625, gnorm=1.929, loss_scale=128, train_wall=0, wall=107
2024-12-12 04:48:01 | INFO | train_inner | epoch 001:   1420 / 312876 loss=10.948, nll_loss=10.22, ppl=1192.5, wps=11564.3, ups=30.22, wpb=382.7, bsz=10, num_updates=1420, lr=0.0001775, gnorm=1.953, loss_scale=128, train_wall=0, wall=108
2024-12-12 04:48:02 | INFO | train_inner | epoch 001:   1430 / 312876 loss=11.309, nll_loss=10.62, ppl=1573.68, wps=11278.3, ups=29.04, wpb=388.4, bsz=11, num_updates=1430, lr=0.00017875, gnorm=1.848, loss_scale=128, train_wall=0, wall=108
2024-12-12 04:48:02 | INFO | train_inner | epoch 001:   1440 / 312876 loss=11.022, nll_loss=10.315, ppl=1273.43, wps=11551.3, ups=28.59, wpb=404.1, bsz=13.8, num_updates=1440, lr=0.00018, gnorm=1.941, loss_scale=128, train_wall=0, wall=108
2024-12-12 04:48:02 | INFO | train_inner | epoch 001:   1450 / 312876 loss=11.042, nll_loss=10.309, ppl=1268.95, wps=11205.2, ups=29.1, wpb=385, bsz=11.7, num_updates=1450, lr=0.00018125, gnorm=1.894, loss_scale=128, train_wall=0, wall=109
2024-12-12 04:48:03 | INFO | train_inner | epoch 001:   1460 / 312876 loss=10.751, nll_loss=9.988, ppl=1015.52, wps=10881, ups=28.94, wpb=376, bsz=16, num_updates=1460, lr=0.0001825, gnorm=1.91, loss_scale=128, train_wall=0, wall=109
2024-12-12 04:48:03 | INFO | train_inner | epoch 001:   1470 / 312876 loss=10.776, nll_loss=10.028, ppl=1043.9, wps=10663.7, ups=29.1, wpb=366.4, bsz=12.8, num_updates=1470, lr=0.00018375, gnorm=1.9, loss_scale=128, train_wall=0, wall=109
2024-12-12 04:48:03 | INFO | train_inner | epoch 001:   1480 / 312876 loss=10.769, nll_loss=10.006, ppl=1028.38, wps=10612.7, ups=28.76, wpb=369, bsz=13.3, num_updates=1480, lr=0.000185, gnorm=1.925, loss_scale=128, train_wall=0, wall=110
2024-12-12 04:48:04 | INFO | train_inner | epoch 001:   1490 / 312876 loss=11.017, nll_loss=10.292, ppl=1253.83, wps=10515.7, ups=28.58, wpb=368, bsz=13.6, num_updates=1490, lr=0.00018625, gnorm=2.077, loss_scale=128, train_wall=0, wall=110
2024-12-12 04:48:04 | INFO | train_inner | epoch 001:   1500 / 312876 loss=11.042, nll_loss=10.313, ppl=1272.28, wps=11588.3, ups=29.31, wpb=395.4, bsz=11.6, num_updates=1500, lr=0.0001875, gnorm=2.239, loss_scale=128, train_wall=0, wall=111
2024-12-12 04:48:04 | INFO | train_inner | epoch 001:   1510 / 312876 loss=10.93, nll_loss=10.199, ppl=1175.7, wps=10298.3, ups=29.63, wpb=347.6, bsz=12.6, num_updates=1510, lr=0.00018875, gnorm=2.142, loss_scale=128, train_wall=0, wall=111
2024-12-12 04:48:05 | INFO | train_inner | epoch 001:   1520 / 312876 loss=10.905, nll_loss=10.162, ppl=1145.42, wps=11377.6, ups=29.69, wpb=383.2, bsz=11.8, num_updates=1520, lr=0.00019, gnorm=2.194, loss_scale=128, train_wall=0, wall=111
2024-12-12 04:48:05 | INFO | train_inner | epoch 001:   1530 / 312876 loss=10.824, nll_loss=10.074, ppl=1077.97, wps=11463.9, ups=28.79, wpb=398.2, bsz=13.1, num_updates=1530, lr=0.00019125, gnorm=1.899, loss_scale=128, train_wall=0, wall=112
2024-12-12 04:48:05 | INFO | train_inner | epoch 001:   1540 / 312876 loss=10.696, nll_loss=9.928, ppl=973.86, wps=12146.9, ups=29.4, wpb=413.1, bsz=10, num_updates=1540, lr=0.0001925, gnorm=1.935, loss_scale=128, train_wall=0, wall=112
2024-12-12 04:48:06 | INFO | train_inner | epoch 001:   1550 / 312876 loss=10.804, nll_loss=10.05, ppl=1060.32, wps=10992.8, ups=29.61, wpb=371.2, bsz=11.2, num_updates=1550, lr=0.00019375, gnorm=1.948, loss_scale=128, train_wall=0, wall=112
2024-12-12 04:48:06 | INFO | train_inner | epoch 001:   1560 / 312876 loss=10.427, nll_loss=9.617, ppl=785.02, wps=11544.9, ups=28.95, wpb=398.8, bsz=18, num_updates=1560, lr=0.000195, gnorm=2.137, loss_scale=128, train_wall=0, wall=113
2024-12-12 04:48:06 | INFO | train_inner | epoch 001:   1570 / 312876 loss=10.908, nll_loss=10.174, ppl=1155.53, wps=11846, ups=29.19, wpb=405.8, bsz=12.4, num_updates=1570, lr=0.00019625, gnorm=1.854, loss_scale=128, train_wall=0, wall=113
2024-12-12 04:48:07 | INFO | train_inner | epoch 001:   1580 / 312876 loss=10.696, nll_loss=9.926, ppl=972.74, wps=10941.2, ups=29.18, wpb=375, bsz=12.4, num_updates=1580, lr=0.0001975, gnorm=2.009, loss_scale=128, train_wall=0, wall=113
2024-12-12 04:48:07 | INFO | train_inner | epoch 001:   1590 / 312876 loss=10.599, nll_loss=9.809, ppl=896.94, wps=11443.9, ups=29.44, wpb=388.7, bsz=13.2, num_updates=1590, lr=0.00019875, gnorm=1.875, loss_scale=128, train_wall=0, wall=114
2024-12-12 04:48:07 | INFO | train_inner | epoch 001:   1600 / 312876 loss=10.844, nll_loss=10.106, ppl=1102.21, wps=11592.4, ups=29.21, wpb=396.8, bsz=14.4, num_updates=1600, lr=0.0002, gnorm=1.859, loss_scale=128, train_wall=0, wall=114
2024-12-12 04:48:08 | INFO | train_inner | epoch 001:   1610 / 312876 loss=10.679, nll_loss=9.899, ppl=954.96, wps=11615, ups=29.02, wpb=400.3, bsz=16, num_updates=1610, lr=0.00020125, gnorm=2.106, loss_scale=128, train_wall=0, wall=114
2024-12-12 04:48:08 | INFO | train_inner | epoch 001:   1620 / 312876 loss=10.582, nll_loss=9.798, ppl=890.03, wps=10378.7, ups=28.91, wpb=359, bsz=14.2, num_updates=1620, lr=0.0002025, gnorm=2.045, loss_scale=128, train_wall=0, wall=115
2024-12-12 04:48:08 | INFO | train_inner | epoch 001:   1630 / 312876 loss=10.819, nll_loss=10.077, ppl=1080.18, wps=11353, ups=28.55, wpb=397.7, bsz=15.2, num_updates=1630, lr=0.00020375, gnorm=1.848, loss_scale=128, train_wall=0, wall=115
2024-12-12 04:48:09 | INFO | train_inner | epoch 001:   1640 / 312876 loss=10.917, nll_loss=10.18, ppl=1160.26, wps=11103.4, ups=28.94, wpb=383.7, bsz=7.8, num_updates=1640, lr=0.000205, gnorm=2.022, loss_scale=128, train_wall=0, wall=115
2024-12-12 04:48:09 | INFO | train_inner | epoch 001:   1650 / 312876 loss=10.573, nll_loss=9.786, ppl=882.85, wps=11133.1, ups=29.25, wpb=380.6, bsz=14.3, num_updates=1650, lr=0.00020625, gnorm=2.005, loss_scale=128, train_wall=0, wall=116
2024-12-12 04:48:09 | INFO | train_inner | epoch 001:   1660 / 312876 loss=10.454, nll_loss=9.657, ppl=807.07, wps=12566.8, ups=28.56, wpb=440, bsz=16.8, num_updates=1660, lr=0.0002075, gnorm=1.852, loss_scale=128, train_wall=0, wall=116
2024-12-12 04:48:10 | INFO | train_inner | epoch 001:   1670 / 312876 loss=10.889, nll_loss=10.147, ppl=1133.74, wps=11641.4, ups=29.47, wpb=395, bsz=12.5, num_updates=1670, lr=0.00020875, gnorm=2.106, loss_scale=128, train_wall=0, wall=116
2024-12-12 04:48:10 | INFO | train_inner | epoch 001:   1680 / 312876 loss=10.523, nll_loss=9.73, ppl=849.21, wps=10433, ups=29.37, wpb=355.2, bsz=13.5, num_updates=1680, lr=0.00021, gnorm=2.121, loss_scale=128, train_wall=0, wall=117
2024-12-12 04:48:10 | INFO | train_inner | epoch 001:   1690 / 312876 loss=10.788, nll_loss=10.038, ppl=1051.11, wps=11621.8, ups=29.45, wpb=394.6, bsz=12.4, num_updates=1690, lr=0.00021125, gnorm=1.905, loss_scale=128, train_wall=0, wall=117
2024-12-12 04:48:11 | INFO | train_inner | epoch 001:   1700 / 312876 loss=10.657, nll_loss=9.878, ppl=941.13, wps=10092.6, ups=28.91, wpb=349.1, bsz=10.2, num_updates=1700, lr=0.0002125, gnorm=1.987, loss_scale=128, train_wall=0, wall=117
2024-12-12 04:48:11 | INFO | train_inner | epoch 001:   1710 / 312876 loss=10.772, nll_loss=10.012, ppl=1032.84, wps=10541.2, ups=29, wpb=363.5, bsz=9.1, num_updates=1710, lr=0.00021375, gnorm=1.904, loss_scale=128, train_wall=0, wall=118
2024-12-12 04:48:11 | INFO | train_inner | epoch 001:   1720 / 312876 loss=10.884, nll_loss=10.141, ppl=1129.44, wps=11300, ups=29.58, wpb=382, bsz=13.4, num_updates=1720, lr=0.000215, gnorm=1.891, loss_scale=128, train_wall=0, wall=118
2024-12-12 04:48:12 | INFO | train_inner | epoch 001:   1730 / 312876 loss=10.741, nll_loss=9.984, ppl=1012.84, wps=12248.8, ups=29.29, wpb=418.2, bsz=11.7, num_updates=1730, lr=0.00021625, gnorm=1.853, loss_scale=128, train_wall=0, wall=118
2024-12-12 04:48:12 | INFO | train_inner | epoch 001:   1740 / 312876 loss=10.795, nll_loss=10.046, ppl=1057.29, wps=11014.3, ups=28.98, wpb=380, bsz=10.6, num_updates=1740, lr=0.0002175, gnorm=2.023, loss_scale=128, train_wall=0, wall=119
2024-12-12 04:48:13 | INFO | train_inner | epoch 001:   1750 / 312876 loss=10.629, nll_loss=9.841, ppl=917.03, wps=11793.5, ups=29.32, wpb=402.2, bsz=11.6, num_updates=1750, lr=0.00021875, gnorm=1.975, loss_scale=128, train_wall=0, wall=119
2024-12-12 04:48:13 | INFO | train_inner | epoch 001:   1760 / 312876 loss=10.905, nll_loss=10.177, ppl=1157.29, wps=11678.6, ups=29.22, wpb=399.7, bsz=13.1, num_updates=1760, lr=0.00022, gnorm=1.91, loss_scale=128, train_wall=0, wall=119
2024-12-12 04:48:13 | INFO | train_inner | epoch 001:   1770 / 312876 loss=10.78, nll_loss=10.013, ppl=1033.62, wps=11140.6, ups=28.95, wpb=384.8, bsz=12, num_updates=1770, lr=0.00022125, gnorm=2.119, loss_scale=128, train_wall=0, wall=120
2024-12-12 04:48:14 | INFO | train_inner | epoch 001:   1780 / 312876 loss=10.854, nll_loss=10.109, ppl=1104.69, wps=11610.3, ups=29.18, wpb=397.9, bsz=12.7, num_updates=1780, lr=0.0002225, gnorm=2.271, loss_scale=128, train_wall=0, wall=120
2024-12-12 04:48:14 | INFO | train_inner | epoch 001:   1790 / 312876 loss=10.838, nll_loss=10.099, ppl=1096.44, wps=11471.8, ups=29.24, wpb=392.3, bsz=11, num_updates=1790, lr=0.00022375, gnorm=1.968, loss_scale=128, train_wall=0, wall=120
2024-12-12 04:48:14 | INFO | train_inner | epoch 001:   1800 / 312876 loss=10.806, nll_loss=10.035, ppl=1049.49, wps=12551.4, ups=28.86, wpb=434.9, bsz=12, num_updates=1800, lr=0.000225, gnorm=1.976, loss_scale=128, train_wall=0, wall=121
2024-12-12 04:48:15 | INFO | train_inner | epoch 001:   1810 / 312876 loss=10.72, nll_loss=9.957, ppl=993.85, wps=10296.7, ups=29.86, wpb=344.8, bsz=12, num_updates=1810, lr=0.00022625, gnorm=1.953, loss_scale=128, train_wall=0, wall=121
2024-12-12 04:48:15 | INFO | train_inner | epoch 001:   1820 / 312876 loss=10.671, nll_loss=9.906, ppl=959.42, wps=11189.2, ups=29.58, wpb=378.3, bsz=13.5, num_updates=1820, lr=0.0002275, gnorm=1.886, loss_scale=128, train_wall=0, wall=121
2024-12-12 04:48:15 | INFO | train_inner | epoch 001:   1830 / 312876 loss=10.781, nll_loss=10.023, ppl=1040.48, wps=11366.8, ups=29.34, wpb=387.4, bsz=11.5, num_updates=1830, lr=0.00022875, gnorm=1.853, loss_scale=128, train_wall=0, wall=122
2024-12-12 04:48:16 | INFO | train_inner | epoch 001:   1840 / 312876 loss=10.568, nll_loss=9.79, ppl=885, wps=11404.6, ups=29.15, wpb=391.2, bsz=14.2, num_updates=1840, lr=0.00023, gnorm=1.981, loss_scale=128, train_wall=0, wall=122
2024-12-12 04:48:16 | INFO | train_inner | epoch 001:   1850 / 312876 loss=10.877, nll_loss=10.133, ppl=1122.73, wps=10701.9, ups=29.69, wpb=360.4, bsz=9.4, num_updates=1850, lr=0.00023125, gnorm=1.947, loss_scale=128, train_wall=0, wall=122
2024-12-12 04:48:16 | INFO | train_inner | epoch 001:   1860 / 312876 loss=10.842, nll_loss=10.095, ppl=1093.89, wps=11739.4, ups=28.42, wpb=413.1, bsz=9.8, num_updates=1860, lr=0.0002325, gnorm=1.851, loss_scale=128, train_wall=0, wall=123
2024-12-12 04:48:17 | INFO | train_inner | epoch 001:   1870 / 312876 loss=10.762, nll_loss=10.001, ppl=1024.37, wps=10230.2, ups=28.63, wpb=357.3, bsz=9.6, num_updates=1870, lr=0.00023375, gnorm=1.948, loss_scale=128, train_wall=0, wall=123
2024-12-12 04:48:17 | INFO | train_inner | epoch 001:   1880 / 312876 loss=10.507, nll_loss=9.717, ppl=841.8, wps=9979.8, ups=29.15, wpb=342.4, bsz=12.8, num_updates=1880, lr=0.000235, gnorm=2.015, loss_scale=128, train_wall=0, wall=124
2024-12-12 04:48:17 | INFO | train_inner | epoch 001:   1890 / 312876 loss=10.761, nll_loss=9.997, ppl=1021.85, wps=10864.5, ups=28.59, wpb=380, bsz=9.4, num_updates=1890, lr=0.00023625, gnorm=1.951, loss_scale=128, train_wall=0, wall=124
2024-12-12 04:48:18 | INFO | train_inner | epoch 001:   1900 / 312876 loss=10.858, nll_loss=10.115, ppl=1108.8, wps=10707.7, ups=28.42, wpb=376.8, bsz=13.6, num_updates=1900, lr=0.0002375, gnorm=2.016, loss_scale=128, train_wall=0, wall=124
2024-12-12 04:48:18 | INFO | train_inner | epoch 001:   1910 / 312876 loss=10.861, nll_loss=10.125, ppl=1116.46, wps=11368.5, ups=28.56, wpb=398, bsz=10.7, num_updates=1910, lr=0.00023875, gnorm=1.914, loss_scale=128, train_wall=0, wall=125
2024-12-12 04:48:18 | INFO | train_inner | epoch 001:   1920 / 312876 loss=10.709, nll_loss=9.946, ppl=986.26, wps=10470.9, ups=29.84, wpb=350.9, bsz=13.6, num_updates=1920, lr=0.00024, gnorm=2.049, loss_scale=128, train_wall=0, wall=125
2024-12-12 04:48:19 | INFO | train_inner | epoch 001:   1930 / 312876 loss=10.372, nll_loss=9.557, ppl=753.06, wps=10879.8, ups=29.76, wpb=365.6, bsz=12.8, num_updates=1930, lr=0.00024125, gnorm=2.056, loss_scale=128, train_wall=0, wall=125
2024-12-12 04:48:19 | INFO | train_inner | epoch 001:   1940 / 312876 loss=10.678, nll_loss=9.9, ppl=955.64, wps=11088.5, ups=29.12, wpb=380.8, bsz=12, num_updates=1940, lr=0.0002425, gnorm=1.944, loss_scale=128, train_wall=0, wall=126
2024-12-12 04:48:19 | INFO | train_inner | epoch 001:   1950 / 312876 loss=10.567, nll_loss=9.79, ppl=885.01, wps=11378.7, ups=29.69, wpb=383.3, bsz=13.1, num_updates=1950, lr=0.00024375, gnorm=2.013, loss_scale=128, train_wall=0, wall=126
2024-12-12 04:48:20 | INFO | train_inner | epoch 001:   1960 / 312876 loss=10.481, nll_loss=9.677, ppl=818.41, wps=11753.5, ups=29.24, wpb=401.9, bsz=12.3, num_updates=1960, lr=0.000245, gnorm=1.859, loss_scale=128, train_wall=0, wall=126
2024-12-12 04:48:20 | INFO | train_inner | epoch 001:   1970 / 312876 loss=10.577, nll_loss=9.798, ppl=890.18, wps=11694.3, ups=29.47, wpb=396.8, bsz=9.8, num_updates=1970, lr=0.00024625, gnorm=1.82, loss_scale=128, train_wall=0, wall=127
2024-12-12 04:48:20 | INFO | train_inner | epoch 001:   1980 / 312876 loss=10.318, nll_loss=9.502, ppl=725.24, wps=11187.8, ups=29.88, wpb=374.4, bsz=11.2, num_updates=1980, lr=0.0002475, gnorm=1.982, loss_scale=128, train_wall=0, wall=127
2024-12-12 04:48:21 | INFO | train_inner | epoch 001:   1990 / 312876 loss=10.422, nll_loss=9.608, ppl=780.46, wps=11170.2, ups=29.4, wpb=380, bsz=16, num_updates=1990, lr=0.00024875, gnorm=1.856, loss_scale=128, train_wall=0, wall=127
2024-12-12 04:48:21 | INFO | train_inner | epoch 001:   2000 / 312876 loss=10.562, nll_loss=9.785, ppl=882.52, wps=11230.3, ups=29.56, wpb=379.9, bsz=11.9, num_updates=2000, lr=0.00025, gnorm=2.095, loss_scale=128, train_wall=0, wall=128
2024-12-12 04:48:21 | INFO | train_inner | epoch 001:   2010 / 312876 loss=10.315, nll_loss=9.491, ppl=719.42, wps=10339.8, ups=30.06, wpb=344, bsz=13.6, num_updates=2010, lr=0.00025125, gnorm=2.305, loss_scale=128, train_wall=0, wall=128
2024-12-12 04:48:22 | INFO | train_inner | epoch 001:   2020 / 312876 loss=10.473, nll_loss=9.658, ppl=807.63, wps=12152, ups=29.35, wpb=414, bsz=19.8, num_updates=2020, lr=0.0002525, gnorm=2.136, loss_scale=128, train_wall=0, wall=128
2024-12-12 04:48:22 | INFO | train_inner | epoch 001:   2030 / 312876 loss=10.451, nll_loss=9.644, ppl=800.07, wps=11963.5, ups=29.18, wpb=410, bsz=15, num_updates=2030, lr=0.00025375, gnorm=2.001, loss_scale=128, train_wall=0, wall=129
2024-12-12 04:48:22 | INFO | train_inner | epoch 001:   2040 / 312876 loss=10.491, nll_loss=9.701, ppl=832.32, wps=10022.1, ups=30.33, wpb=330.4, bsz=11.2, num_updates=2040, lr=0.000255, gnorm=1.914, loss_scale=128, train_wall=0, wall=129
2024-12-12 04:48:23 | INFO | train_inner | epoch 001:   2050 / 312876 loss=10.431, nll_loss=9.63, ppl=792.25, wps=10384.7, ups=29.84, wpb=348, bsz=12.4, num_updates=2050, lr=0.00025625, gnorm=2.018, loss_scale=128, train_wall=0, wall=129
2024-12-12 04:48:23 | INFO | train_inner | epoch 001:   2060 / 312876 loss=10.526, nll_loss=9.744, ppl=857.62, wps=10483, ups=30.05, wpb=348.8, bsz=12, num_updates=2060, lr=0.0002575, gnorm=1.941, loss_scale=128, train_wall=0, wall=130
2024-12-12 04:48:23 | INFO | train_inner | epoch 001:   2070 / 312876 loss=10.708, nll_loss=9.941, ppl=982.79, wps=12281.7, ups=28.76, wpb=427.1, bsz=12.3, num_updates=2070, lr=0.00025875, gnorm=1.946, loss_scale=128, train_wall=0, wall=130
2024-12-12 04:48:24 | INFO | train_inner | epoch 001:   2080 / 312876 loss=10.414, nll_loss=9.611, ppl=781.93, wps=10498, ups=29.32, wpb=358, bsz=12.4, num_updates=2080, lr=0.00026, gnorm=1.932, loss_scale=128, train_wall=0, wall=130
2024-12-12 04:48:24 | INFO | train_inner | epoch 001:   2090 / 312876 loss=10.681, nll_loss=9.919, ppl=967.96, wps=11166.4, ups=29.7, wpb=376, bsz=12.3, num_updates=2090, lr=0.00026125, gnorm=1.973, loss_scale=128, train_wall=0, wall=131
2024-12-12 04:48:24 | INFO | train_inner | epoch 001:   2100 / 312876 loss=10.548, nll_loss=9.748, ppl=859.77, wps=11912.8, ups=28.68, wpb=415.4, bsz=19, num_updates=2100, lr=0.0002625, gnorm=2.021, loss_scale=128, train_wall=0, wall=131
2024-12-12 04:48:25 | INFO | train_inner | epoch 001:   2110 / 312876 loss=10.514, nll_loss=9.726, ppl=846.67, wps=11112.6, ups=29.24, wpb=380, bsz=12, num_updates=2110, lr=0.00026375, gnorm=2.007, loss_scale=128, train_wall=0, wall=131
2024-12-12 04:48:25 | INFO | train_inner | epoch 001:   2120 / 312876 loss=10.62, nll_loss=9.836, ppl=913.93, wps=10572.7, ups=28.92, wpb=365.6, bsz=11.2, num_updates=2120, lr=0.000265, gnorm=1.97, loss_scale=128, train_wall=0, wall=132
2024-12-12 04:48:26 | INFO | train_inner | epoch 001:   2130 / 312876 loss=11.005, nll_loss=10.293, ppl=1254.75, wps=9977.2, ups=29.5, wpb=338.2, bsz=9.3, num_updates=2130, lr=0.00026625, gnorm=2.131, loss_scale=128, train_wall=0, wall=132
2024-12-12 04:48:26 | INFO | train_inner | epoch 001:   2140 / 312876 loss=10.551, nll_loss=9.758, ppl=866.09, wps=10136.2, ups=30.19, wpb=335.7, bsz=8.4, num_updates=2140, lr=0.0002675, gnorm=2.004, loss_scale=128, train_wall=0, wall=132
2024-12-12 04:48:26 | INFO | train_inner | epoch 001:   2150 / 312876 loss=10.695, nll_loss=9.933, ppl=977.23, wps=10852, ups=28.98, wpb=374.4, bsz=10, num_updates=2150, lr=0.00026875, gnorm=1.945, loss_scale=128, train_wall=0, wall=133
2024-12-12 04:48:27 | INFO | train_inner | epoch 001:   2160 / 312876 loss=10.822, nll_loss=10.076, ppl=1079.58, wps=11683.4, ups=29.6, wpb=394.7, bsz=11.9, num_updates=2160, lr=0.00027, gnorm=1.903, loss_scale=128, train_wall=0, wall=133
2024-12-12 04:48:27 | INFO | train_inner | epoch 001:   2170 / 312876 loss=10.493, nll_loss=9.69, ppl=825.8, wps=12378.9, ups=29.53, wpb=419.2, bsz=16, num_updates=2170, lr=0.00027125, gnorm=1.862, loss_scale=128, train_wall=0, wall=133
2024-12-12 04:48:27 | INFO | train_inner | epoch 001:   2180 / 312876 loss=10.462, nll_loss=9.659, ppl=808.5, wps=12543.8, ups=29.05, wpb=431.8, bsz=14, num_updates=2180, lr=0.0002725, gnorm=1.878, loss_scale=128, train_wall=0, wall=134
2024-12-12 04:48:28 | INFO | train_inner | epoch 001:   2190 / 312876 loss=10.573, nll_loss=9.803, ppl=893.53, wps=11145.8, ups=29.37, wpb=379.5, bsz=13, num_updates=2190, lr=0.00027375, gnorm=2.087, loss_scale=128, train_wall=0, wall=134
2024-12-12 04:48:28 | INFO | train_inner | epoch 001:   2200 / 312876 loss=10.349, nll_loss=9.518, ppl=733.26, wps=11186.1, ups=29.01, wpb=385.6, bsz=13.4, num_updates=2200, lr=0.000275, gnorm=1.861, loss_scale=128, train_wall=0, wall=134
2024-12-12 04:48:28 | INFO | train_inner | epoch 001:   2210 / 312876 loss=10.562, nll_loss=9.778, ppl=877.84, wps=10216.1, ups=29.56, wpb=345.6, bsz=13.6, num_updates=2210, lr=0.00027625, gnorm=2.165, loss_scale=128, train_wall=0, wall=135
2024-12-12 04:48:29 | INFO | train_inner | epoch 001:   2220 / 312876 loss=10.715, nll_loss=9.934, ppl=978.47, wps=10058.5, ups=30.08, wpb=334.4, bsz=8.8, num_updates=2220, lr=0.0002775, gnorm=2.105, loss_scale=128, train_wall=0, wall=135
2024-12-12 04:48:29 | INFO | train_inner | epoch 001:   2230 / 312876 loss=10.704, nll_loss=9.94, ppl=982.18, wps=10690.6, ups=30.03, wpb=356, bsz=11.2, num_updates=2230, lr=0.00027875, gnorm=2.109, loss_scale=128, train_wall=0, wall=135
2024-12-12 04:48:29 | INFO | train_inner | epoch 001:   2240 / 312876 loss=10.68, nll_loss=9.904, ppl=957.93, wps=11009.8, ups=29.57, wpb=372.3, bsz=10.3, num_updates=2240, lr=0.00028, gnorm=1.987, loss_scale=128, train_wall=0, wall=136
2024-12-12 04:48:30 | INFO | train_inner | epoch 001:   2250 / 312876 loss=10.406, nll_loss=9.603, ppl=777.59, wps=11371.1, ups=29.64, wpb=383.7, bsz=12.7, num_updates=2250, lr=0.00028125, gnorm=1.934, loss_scale=128, train_wall=0, wall=136
2024-12-12 04:48:30 | INFO | train_inner | epoch 001:   2260 / 312876 loss=10.472, nll_loss=9.672, ppl=815.91, wps=9946, ups=30.32, wpb=328, bsz=10.4, num_updates=2260, lr=0.0002825, gnorm=2.06, loss_scale=128, train_wall=0, wall=136
2024-12-12 04:48:30 | INFO | train_inner | epoch 001:   2270 / 312876 loss=10.488, nll_loss=9.691, ppl=826.37, wps=11831.7, ups=29.39, wpb=402.6, bsz=10.3, num_updates=2270, lr=0.00028375, gnorm=1.827, loss_scale=128, train_wall=0, wall=137
2024-12-12 04:48:31 | INFO | train_inner | epoch 001:   2280 / 312876 loss=10.47, nll_loss=9.668, ppl=813.43, wps=10804.7, ups=30.42, wpb=355.2, bsz=11.2, num_updates=2280, lr=0.000285, gnorm=1.959, loss_scale=128, train_wall=0, wall=137
2024-12-12 04:48:31 | INFO | train_inner | epoch 001:   2290 / 312876 loss=10.291, nll_loss=9.475, ppl=711.52, wps=11468.4, ups=29.99, wpb=382.4, bsz=18.4, num_updates=2290, lr=0.00028625, gnorm=1.83, loss_scale=128, train_wall=0, wall=137
2024-12-12 04:48:31 | INFO | train_inner | epoch 001:   2300 / 312876 loss=10.415, nll_loss=9.603, ppl=777.93, wps=10484.5, ups=30.34, wpb=345.6, bsz=9.6, num_updates=2300, lr=0.0002875, gnorm=1.871, loss_scale=128, train_wall=0, wall=138
2024-12-12 04:48:32 | INFO | train_inner | epoch 001:   2310 / 312876 loss=10.384, nll_loss=9.575, ppl=762.56, wps=11152.8, ups=29.4, wpb=379.4, bsz=11.7, num_updates=2310, lr=0.00028875, gnorm=1.885, loss_scale=128, train_wall=0, wall=138
2024-12-12 04:48:32 | INFO | train_inner | epoch 001:   2320 / 312876 loss=10.403, nll_loss=9.587, ppl=768.83, wps=11982.2, ups=28.8, wpb=416, bsz=11.7, num_updates=2320, lr=0.00029, gnorm=1.927, loss_scale=128, train_wall=0, wall=138
2024-12-12 04:48:32 | INFO | train_inner | epoch 001:   2330 / 312876 loss=10.596, nll_loss=9.819, ppl=902.96, wps=10898, ups=29.32, wpb=371.7, bsz=11.1, num_updates=2330, lr=0.00029125, gnorm=2.092, loss_scale=128, train_wall=0, wall=139
2024-12-12 04:48:33 | INFO | train_inner | epoch 001:   2340 / 312876 loss=10.357, nll_loss=9.541, ppl=745.03, wps=10686, ups=29.75, wpb=359.2, bsz=10.4, num_updates=2340, lr=0.0002925, gnorm=1.897, loss_scale=128, train_wall=0, wall=139
2024-12-12 04:48:33 | INFO | train_inner | epoch 001:   2350 / 312876 loss=10.372, nll_loss=9.552, ppl=750.85, wps=10633.5, ups=29.5, wpb=360.4, bsz=13.9, num_updates=2350, lr=0.00029375, gnorm=2.048, loss_scale=128, train_wall=0, wall=139
2024-12-12 04:48:33 | INFO | train_inner | epoch 001:   2360 / 312876 loss=10.407, nll_loss=9.601, ppl=776.55, wps=9240, ups=29.39, wpb=314.4, bsz=12.8, num_updates=2360, lr=0.000295, gnorm=2.141, loss_scale=128, train_wall=0, wall=140
2024-12-12 04:48:34 | INFO | train_inner | epoch 001:   2370 / 312876 loss=10.344, nll_loss=9.531, ppl=739.82, wps=11936.8, ups=29.4, wpb=406, bsz=14.3, num_updates=2370, lr=0.00029625, gnorm=1.901, loss_scale=128, train_wall=0, wall=140
2024-12-12 04:48:34 | INFO | train_inner | epoch 001:   2380 / 312876 loss=10.316, nll_loss=9.496, ppl=722.27, wps=11066.5, ups=29.25, wpb=378.4, bsz=12.4, num_updates=2380, lr=0.0002975, gnorm=2.002, loss_scale=128, train_wall=0, wall=141
2024-12-12 04:48:34 | INFO | train_inner | epoch 001:   2390 / 312876 loss=10.343, nll_loss=9.521, ppl=734.89, wps=11266.2, ups=29.01, wpb=388.4, bsz=18, num_updates=2390, lr=0.00029875, gnorm=1.875, loss_scale=128, train_wall=0, wall=141
2024-12-12 04:48:35 | INFO | train_inner | epoch 001:   2400 / 312876 loss=10.398, nll_loss=9.594, ppl=772.82, wps=10970.8, ups=30.07, wpb=364.8, bsz=9.4, num_updates=2400, lr=0.0003, gnorm=1.891, loss_scale=128, train_wall=0, wall=141
2024-12-12 04:48:35 | INFO | train_inner | epoch 001:   2410 / 312876 loss=10.504, nll_loss=9.703, ppl=833.22, wps=11602.4, ups=28.68, wpb=404.6, bsz=10.7, num_updates=2410, lr=0.00030125, gnorm=1.853, loss_scale=128, train_wall=0, wall=142
2024-12-12 04:48:35 | INFO | train_inner | epoch 001:   2420 / 312876 loss=10.45, nll_loss=9.658, ppl=807.79, wps=10180.1, ups=30.66, wpb=332, bsz=11.2, num_updates=2420, lr=0.0003025, gnorm=1.951, loss_scale=128, train_wall=0, wall=142
2024-12-12 04:48:36 | INFO | train_inner | epoch 001:   2430 / 312876 loss=10.701, nll_loss=9.926, ppl=972.8, wps=10240, ups=30.06, wpb=340.7, bsz=8.7, num_updates=2430, lr=0.00030375, gnorm=2.087, loss_scale=128, train_wall=0, wall=142
2024-12-12 04:48:36 | INFO | train_inner | epoch 001:   2440 / 312876 loss=10.416, nll_loss=9.602, ppl=777.16, wps=11761.6, ups=29.65, wpb=396.7, bsz=14.1, num_updates=2440, lr=0.000305, gnorm=1.905, loss_scale=128, train_wall=0, wall=143
2024-12-12 04:48:36 | INFO | train_inner | epoch 001:   2450 / 312876 loss=10.333, nll_loss=9.522, ppl=734.99, wps=11917.5, ups=29.08, wpb=409.8, bsz=15.8, num_updates=2450, lr=0.00030625, gnorm=1.939, loss_scale=128, train_wall=0, wall=143
2024-12-12 04:48:37 | INFO | train_inner | epoch 001:   2460 / 312876 loss=10.639, nll_loss=9.863, ppl=931.28, wps=11624.2, ups=29.57, wpb=393.1, bsz=9.5, num_updates=2460, lr=0.0003075, gnorm=1.897, loss_scale=128, train_wall=0, wall=143
2024-12-12 04:48:37 | INFO | train_inner | epoch 001:   2470 / 312876 loss=10.761, nll_loss=10.007, ppl=1028.81, wps=11003.3, ups=29.52, wpb=372.8, bsz=10.4, num_updates=2470, lr=0.00030875, gnorm=2.07, loss_scale=128, train_wall=0, wall=144
2024-12-12 04:48:37 | INFO | train_inner | epoch 001:   2480 / 312876 loss=10.506, nll_loss=9.71, ppl=837.61, wps=10409.6, ups=30.12, wpb=345.6, bsz=12.8, num_updates=2480, lr=0.00031, gnorm=2.017, loss_scale=128, train_wall=0, wall=144
2024-12-12 04:48:38 | INFO | train_inner | epoch 001:   2490 / 312876 loss=10.334, nll_loss=9.514, ppl=731.2, wps=10917.5, ups=29.57, wpb=369.2, bsz=11, num_updates=2490, lr=0.00031125, gnorm=2.021, loss_scale=128, train_wall=0, wall=144
2024-12-12 04:48:38 | INFO | train_inner | epoch 001:   2500 / 312876 loss=10.342, nll_loss=9.52, ppl=734.22, wps=11679.1, ups=28.97, wpb=403.2, bsz=12.6, num_updates=2500, lr=0.0003125, gnorm=1.89, loss_scale=128, train_wall=0, wall=145
2024-12-12 04:48:38 | INFO | train_inner | epoch 001:   2510 / 312876 loss=10.253, nll_loss=9.421, ppl=685.29, wps=9934.2, ups=29.78, wpb=333.6, bsz=12, num_updates=2510, lr=0.00031375, gnorm=2.106, loss_scale=128, train_wall=0, wall=145
2024-12-12 04:48:39 | INFO | train_inner | epoch 001:   2520 / 312876 loss=10.752, nll_loss=9.998, ppl=1022.37, wps=11568.4, ups=29.32, wpb=394.5, bsz=10.6, num_updates=2520, lr=0.000315, gnorm=2.002, loss_scale=128, train_wall=0, wall=145
2024-12-12 04:48:39 | INFO | train_inner | epoch 001:   2530 / 312876 loss=10.38, nll_loss=9.57, ppl=759.98, wps=10594.8, ups=29.37, wpb=360.7, bsz=14.1, num_updates=2530, lr=0.00031625, gnorm=2.068, loss_scale=128, train_wall=0, wall=146
2024-12-12 04:48:39 | INFO | train_inner | epoch 001:   2540 / 312876 loss=10.664, nll_loss=9.888, ppl=947.74, wps=10978.2, ups=29.26, wpb=375.2, bsz=11.2, num_updates=2540, lr=0.0003175, gnorm=1.956, loss_scale=128, train_wall=0, wall=146
2024-12-12 04:48:40 | INFO | train_inner | epoch 001:   2550 / 312876 loss=10.36, nll_loss=9.541, ppl=744.79, wps=11601.4, ups=29.36, wpb=395.2, bsz=14.4, num_updates=2550, lr=0.00031875, gnorm=1.909, loss_scale=128, train_wall=0, wall=146
2024-12-12 04:48:40 | INFO | train_inner | epoch 001:   2560 / 312876 loss=10.671, nll_loss=9.909, ppl=961.6, wps=11305.6, ups=28.89, wpb=391.3, bsz=11.5, num_updates=2560, lr=0.00032, gnorm=1.9, loss_scale=128, train_wall=0, wall=147
2024-12-12 04:48:40 | INFO | train_inner | epoch 001:   2570 / 312876 loss=10.463, nll_loss=9.66, ppl=809.03, wps=12122, ups=28.84, wpb=420.3, bsz=13.3, num_updates=2570, lr=0.00032125, gnorm=1.813, loss_scale=128, train_wall=0, wall=147
2024-12-12 04:48:41 | INFO | train_inner | epoch 001:   2580 / 312876 loss=10.378, nll_loss=9.559, ppl=754.5, wps=10091, ups=29.54, wpb=341.6, bsz=11.8, num_updates=2580, lr=0.0003225, gnorm=2.062, loss_scale=128, train_wall=0, wall=147
2024-12-12 04:48:41 | INFO | train_inner | epoch 001:   2590 / 312876 loss=10.21, nll_loss=9.382, ppl=667.38, wps=10622.3, ups=30.04, wpb=353.6, bsz=11.1, num_updates=2590, lr=0.00032375, gnorm=1.971, loss_scale=128, train_wall=0, wall=148
2024-12-12 04:48:41 | INFO | train_inner | epoch 001:   2600 / 312876 loss=10.405, nll_loss=9.597, ppl=774.63, wps=11984.4, ups=28.81, wpb=416, bsz=14.4, num_updates=2600, lr=0.000325, gnorm=1.854, loss_scale=128, train_wall=0, wall=148
2024-12-12 04:48:42 | INFO | train_inner | epoch 001:   2610 / 312876 loss=10.378, nll_loss=9.564, ppl=756.78, wps=10749.4, ups=29.66, wpb=362.4, bsz=12, num_updates=2610, lr=0.00032625, gnorm=1.866, loss_scale=128, train_wall=0, wall=148
2024-12-12 04:48:42 | INFO | train_inner | epoch 001:   2620 / 312876 loss=10.227, nll_loss=9.409, ppl=679.81, wps=11412.6, ups=29.11, wpb=392, bsz=15, num_updates=2620, lr=0.0003275, gnorm=1.933, loss_scale=128, train_wall=0, wall=149
2024-12-12 04:48:42 | INFO | train_inner | epoch 001:   2630 / 312876 loss=10.39, nll_loss=9.562, ppl=755.86, wps=10650.2, ups=30.05, wpb=354.4, bsz=12, num_updates=2630, lr=0.00032875, gnorm=1.954, loss_scale=128, train_wall=0, wall=149
2024-12-12 04:48:43 | INFO | train_inner | epoch 001:   2640 / 312876 loss=10.508, nll_loss=9.715, ppl=840.39, wps=12248.8, ups=29.67, wpb=412.9, bsz=13.9, num_updates=2640, lr=0.00033, gnorm=1.877, loss_scale=128, train_wall=0, wall=149
2024-12-12 04:48:43 | INFO | train_inner | epoch 001:   2650 / 312876 loss=10.417, nll_loss=9.606, ppl=779.38, wps=11278.3, ups=29.04, wpb=388.4, bsz=13.6, num_updates=2650, lr=0.00033125, gnorm=2.042, loss_scale=128, train_wall=0, wall=150
2024-12-12 04:48:43 | INFO | train_inner | epoch 001:   2660 / 312876 loss=10.576, nll_loss=9.797, ppl=889.87, wps=10740.2, ups=30.12, wpb=356.6, bsz=10.4, num_updates=2660, lr=0.0003325, gnorm=2.109, loss_scale=128, train_wall=0, wall=150
2024-12-12 04:48:44 | INFO | train_inner | epoch 001:   2670 / 312876 loss=10.417, nll_loss=9.613, ppl=782.8, wps=10785.5, ups=30.36, wpb=355.2, bsz=11.2, num_updates=2670, lr=0.00033375, gnorm=2.019, loss_scale=128, train_wall=0, wall=150
2024-12-12 04:48:44 | INFO | train_inner | epoch 001:   2680 / 312876 loss=10.206, nll_loss=9.368, ppl=660.71, wps=11512.5, ups=28.87, wpb=398.7, bsz=12.7, num_updates=2680, lr=0.000335, gnorm=1.779, loss_scale=128, train_wall=0, wall=151
2024-12-12 04:48:44 | INFO | train_inner | epoch 001:   2690 / 312876 loss=10.377, nll_loss=9.569, ppl=759.45, wps=11458.3, ups=29.89, wpb=383.3, bsz=14.9, num_updates=2690, lr=0.00033625, gnorm=1.943, loss_scale=128, train_wall=0, wall=151
2024-12-12 04:48:45 | INFO | train_inner | epoch 001:   2700 / 312876 loss=10.157, nll_loss=9.32, ppl=639.07, wps=10879.7, ups=29.98, wpb=362.9, bsz=15.7, num_updates=2700, lr=0.0003375, gnorm=1.987, loss_scale=128, train_wall=0, wall=151
2024-12-12 04:48:45 | INFO | train_inner | epoch 001:   2710 / 312876 loss=10.256, nll_loss=9.423, ppl=686.37, wps=11415.3, ups=28.52, wpb=400.3, bsz=13.3, num_updates=2710, lr=0.00033875, gnorm=1.849, loss_scale=128, train_wall=0, wall=152
2024-12-12 04:48:46 | INFO | train_inner | epoch 001:   2720 / 312876 loss=10.383, nll_loss=9.572, ppl=761.27, wps=11399.4, ups=28.14, wpb=405.1, bsz=13.5, num_updates=2720, lr=0.00034, gnorm=1.912, loss_scale=128, train_wall=0, wall=152
2024-12-12 04:48:46 | INFO | train_inner | epoch 001:   2730 / 312876 loss=10.338, nll_loss=9.528, ppl=738.03, wps=10514.6, ups=29.87, wpb=352, bsz=12.8, num_updates=2730, lr=0.00034125, gnorm=2.097, loss_scale=128, train_wall=0, wall=152
2024-12-12 04:48:46 | INFO | train_inner | epoch 001:   2740 / 312876 loss=10.459, nll_loss=9.655, ppl=806.45, wps=11872.7, ups=29.1, wpb=408, bsz=16, num_updates=2740, lr=0.0003425, gnorm=1.931, loss_scale=128, train_wall=0, wall=153
2024-12-12 04:48:47 | INFO | train_inner | epoch 001:   2750 / 312876 loss=10.457, nll_loss=9.662, ppl=809.98, wps=11216.1, ups=29.83, wpb=376, bsz=13.6, num_updates=2750, lr=0.00034375, gnorm=1.917, loss_scale=128, train_wall=0, wall=153
2024-12-12 04:48:47 | INFO | train_inner | epoch 001:   2760 / 312876 loss=10.424, nll_loss=9.627, ppl=790.48, wps=10443.1, ups=29.2, wpb=357.6, bsz=13.6, num_updates=2760, lr=0.000345, gnorm=1.87, loss_scale=128, train_wall=0, wall=153
2024-12-12 04:48:47 | INFO | train_inner | epoch 001:   2770 / 312876 loss=10.057, nll_loss=9.203, ppl=589.27, wps=10674.7, ups=29.99, wpb=356, bsz=12.8, num_updates=2770, lr=0.00034625, gnorm=2.064, loss_scale=128, train_wall=0, wall=154
2024-12-12 04:48:48 | INFO | train_inner | epoch 001:   2780 / 312876 loss=10.224, nll_loss=9.384, ppl=668.12, wps=9988.8, ups=30.45, wpb=328, bsz=11.2, num_updates=2780, lr=0.0003475, gnorm=2.04, loss_scale=128, train_wall=0, wall=154
2024-12-12 04:48:48 | INFO | train_inner | epoch 001:   2790 / 312876 loss=10.316, nll_loss=9.504, ppl=726.16, wps=10099.4, ups=29.36, wpb=344, bsz=12, num_updates=2790, lr=0.00034875, gnorm=2.114, loss_scale=128, train_wall=0, wall=154
2024-12-12 04:48:48 | INFO | train_inner | epoch 001:   2800 / 312876 loss=10.135, nll_loss=9.286, ppl=624.35, wps=11551.4, ups=27.71, wpb=416.8, bsz=19.2, num_updates=2800, lr=0.00035, gnorm=1.935, loss_scale=128, train_wall=0, wall=155
2024-12-12 04:48:49 | INFO | train_inner | epoch 001:   2810 / 312876 loss=10.467, nll_loss=9.673, ppl=816.55, wps=10624.7, ups=29.56, wpb=359.4, bsz=10.2, num_updates=2810, lr=0.00035125, gnorm=2.083, loss_scale=128, train_wall=0, wall=155
2024-12-12 04:48:49 | INFO | train_inner | epoch 001:   2820 / 312876 loss=10.605, nll_loss=9.815, ppl=900.75, wps=11494.2, ups=29.08, wpb=395.3, bsz=9.3, num_updates=2820, lr=0.0003525, gnorm=1.923, loss_scale=128, train_wall=0, wall=155
2024-12-12 04:48:49 | INFO | train_inner | epoch 001:   2830 / 312876 loss=10.26, nll_loss=9.435, ppl=692.11, wps=10750.6, ups=29.34, wpb=366.4, bsz=12.4, num_updates=2830, lr=0.00035375, gnorm=1.893, loss_scale=128, train_wall=0, wall=156
2024-12-12 04:48:50 | INFO | train_inner | epoch 001:   2840 / 312876 loss=10.344, nll_loss=9.528, ppl=738.06, wps=10049.4, ups=29.49, wpb=340.8, bsz=9.6, num_updates=2840, lr=0.000355, gnorm=1.921, loss_scale=128, train_wall=0, wall=156
2024-12-12 04:48:50 | INFO | train_inner | epoch 001:   2850 / 312876 loss=10.21, nll_loss=9.379, ppl=665.86, wps=10455.9, ups=27.87, wpb=375.2, bsz=15.2, num_updates=2850, lr=0.00035625, gnorm=1.895, loss_scale=128, train_wall=0, wall=157
2024-12-12 04:48:50 | INFO | train_inner | epoch 001:   2860 / 312876 loss=10.538, nll_loss=9.732, ppl=850.47, wps=10591.1, ups=28.66, wpb=369.6, bsz=12, num_updates=2860, lr=0.0003575, gnorm=2.175, loss_scale=128, train_wall=0, wall=157
2024-12-12 04:48:51 | INFO | train_inner | epoch 001:   2870 / 312876 loss=10.531, nll_loss=9.75, ppl=861.34, wps=9641.7, ups=29.43, wpb=327.6, bsz=8.6, num_updates=2870, lr=0.00035875, gnorm=2.091, loss_scale=128, train_wall=0, wall=157
2024-12-12 04:48:51 | INFO | train_inner | epoch 001:   2880 / 312876 loss=10.273, nll_loss=9.46, ppl=704.28, wps=11724.9, ups=27.86, wpb=420.9, bsz=15.1, num_updates=2880, lr=0.00036, gnorm=1.77, loss_scale=128, train_wall=0, wall=158
2024-12-12 04:48:51 | INFO | train_inner | epoch 001:   2890 / 312876 loss=10.397, nll_loss=9.579, ppl=765.03, wps=10471.6, ups=29.02, wpb=360.8, bsz=12.8, num_updates=2890, lr=0.00036125, gnorm=1.966, loss_scale=128, train_wall=0, wall=158
2024-12-12 04:48:52 | INFO | train_inner | epoch 001:   2900 / 312876 loss=10.128, nll_loss=9.275, ppl=619.53, wps=10471.6, ups=27.78, wpb=377, bsz=16.6, num_updates=2900, lr=0.0003625, gnorm=1.886, loss_scale=128, train_wall=0, wall=158
2024-12-12 04:48:52 | INFO | train_inner | epoch 001:   2910 / 312876 loss=10.417, nll_loss=9.622, ppl=787.87, wps=10042.3, ups=28.66, wpb=350.4, bsz=9.6, num_updates=2910, lr=0.00036375, gnorm=2.095, loss_scale=128, train_wall=0, wall=159
2024-12-12 04:48:52 | INFO | train_inner | epoch 001:   2920 / 312876 loss=10.295, nll_loss=9.468, ppl=708.19, wps=10944.8, ups=28.74, wpb=380.8, bsz=16, num_updates=2920, lr=0.000365, gnorm=1.979, loss_scale=128, train_wall=0, wall=159
2024-12-12 04:48:53 | INFO | train_inner | epoch 001:   2930 / 312876 loss=10.323, nll_loss=9.51, ppl=729.23, wps=11301.1, ups=27.95, wpb=404.4, bsz=12.6, num_updates=2930, lr=0.00036625, gnorm=1.961, loss_scale=128, train_wall=0, wall=159
2024-12-12 04:48:53 | INFO | train_inner | epoch 001:   2940 / 312876 loss=10.413, nll_loss=9.604, ppl=778.09, wps=9052.3, ups=29.01, wpb=312, bsz=8.8, num_updates=2940, lr=0.0003675, gnorm=2.201, loss_scale=128, train_wall=0, wall=160
2024-12-12 04:48:53 | INFO | train_inner | epoch 001:   2950 / 312876 loss=10.268, nll_loss=9.449, ppl=698.78, wps=10929.9, ups=29.57, wpb=369.6, bsz=15.2, num_updates=2950, lr=0.00036875, gnorm=1.911, loss_scale=128, train_wall=0, wall=160
2024-12-12 04:48:54 | INFO | train_inner | epoch 001:   2960 / 312876 loss=10.105, nll_loss=9.253, ppl=610.09, wps=12151.6, ups=27.99, wpb=434.2, bsz=17.5, num_updates=2960, lr=0.00037, gnorm=1.718, loss_scale=128, train_wall=0, wall=160
2024-12-12 04:48:54 | INFO | train_inner | epoch 001:   2970 / 312876 loss=10.514, nll_loss=9.732, ppl=850.45, wps=9856.1, ups=27.92, wpb=353, bsz=9.3, num_updates=2970, lr=0.00037125, gnorm=2.01, loss_scale=128, train_wall=0, wall=161
2024-12-12 04:48:55 | INFO | train_inner | epoch 001:   2980 / 312876 loss=10.443, nll_loss=9.638, ppl=796.69, wps=10670.2, ups=27.85, wpb=383.1, bsz=8.3, num_updates=2980, lr=0.0003725, gnorm=1.869, loss_scale=128, train_wall=0, wall=161
2024-12-12 04:48:55 | INFO | train_inner | epoch 001:   2990 / 312876 loss=10.391, nll_loss=9.577, ppl=763.78, wps=11204.9, ups=27.95, wpb=400.9, bsz=12.7, num_updates=2990, lr=0.00037375, gnorm=1.857, loss_scale=128, train_wall=0, wall=161
2024-12-12 04:48:55 | INFO | train_inner | epoch 001:   3000 / 312876 loss=10.39, nll_loss=9.576, ppl=763.49, wps=10725, ups=28.28, wpb=379.2, bsz=13.1, num_updates=3000, lr=0.000375, gnorm=1.931, loss_scale=128, train_wall=0, wall=162
2024-12-12 04:48:56 | INFO | train_inner | epoch 001:   3010 / 312876 loss=10.449, nll_loss=9.655, ppl=806.4, wps=11052, ups=28.14, wpb=392.7, bsz=11, num_updates=3010, lr=0.00037625, gnorm=1.932, loss_scale=128, train_wall=0, wall=162
2024-12-12 04:48:56 | INFO | train_inner | epoch 001:   3020 / 312876 loss=10.236, nll_loss=9.407, ppl=678.97, wps=10977.7, ups=28.23, wpb=388.8, bsz=15.2, num_updates=3020, lr=0.0003775, gnorm=1.912, loss_scale=128, train_wall=0, wall=163
2024-12-12 04:48:56 | INFO | train_inner | epoch 001:   3030 / 312876 loss=10.373, nll_loss=9.563, ppl=756.61, wps=10108.7, ups=28.59, wpb=353.6, bsz=11.2, num_updates=3030, lr=0.00037875, gnorm=1.942, loss_scale=128, train_wall=0, wall=163
2024-12-12 04:48:57 | INFO | train_inner | epoch 001:   3040 / 312876 loss=10.222, nll_loss=9.39, ppl=671.1, wps=10404.3, ups=28.54, wpb=364.6, bsz=10, num_updates=3040, lr=0.00038, gnorm=2.094, loss_scale=128, train_wall=0, wall=163
2024-12-12 04:48:57 | INFO | train_inner | epoch 001:   3050 / 312876 loss=10.357, nll_loss=9.552, ppl=750.45, wps=10626.7, ups=28.57, wpb=372, bsz=12.9, num_updates=3050, lr=0.00038125, gnorm=2.227, loss_scale=128, train_wall=0, wall=164
2024-12-12 04:48:57 | INFO | train_inner | epoch 001:   3060 / 312876 loss=10.22, nll_loss=9.376, ppl=664.31, wps=10807.7, ups=29.46, wpb=366.8, bsz=13.8, num_updates=3060, lr=0.0003825, gnorm=2.236, loss_scale=128, train_wall=0, wall=164
2024-12-12 04:48:58 | INFO | train_inner | epoch 001:   3070 / 312876 loss=10.153, nll_loss=9.305, ppl=632.54, wps=10579.3, ups=30.3, wpb=349.2, bsz=13.5, num_updates=3070, lr=0.00038375, gnorm=2.246, loss_scale=128, train_wall=0, wall=164
2024-12-12 04:48:58 | INFO | train_inner | epoch 001:   3080 / 312876 loss=10.111, nll_loss=9.262, ppl=614.14, wps=11331.8, ups=28.41, wpb=398.8, bsz=13.6, num_updates=3080, lr=0.000385, gnorm=1.922, loss_scale=128, train_wall=0, wall=165
2024-12-12 04:48:58 | INFO | train_inner | epoch 001:   3090 / 312876 loss=10.393, nll_loss=9.58, ppl=765.17, wps=11182.1, ups=29.12, wpb=384, bsz=10.8, num_updates=3090, lr=0.00038625, gnorm=2.021, loss_scale=128, train_wall=0, wall=165
2024-12-12 04:48:59 | INFO | train_inner | epoch 001:   3100 / 312876 loss=10.701, nll_loss=9.946, ppl=986.44, wps=10388.1, ups=29.84, wpb=348.1, bsz=10.9, num_updates=3100, lr=0.0003875, gnorm=2.023, loss_scale=128, train_wall=0, wall=165
2024-12-12 04:48:59 | INFO | train_inner | epoch 001:   3110 / 312876 loss=10.371, nll_loss=9.555, ppl=751.96, wps=11415.4, ups=29.6, wpb=385.6, bsz=13.6, num_updates=3110, lr=0.00038875, gnorm=1.962, loss_scale=128, train_wall=0, wall=166
2024-12-12 04:48:59 | INFO | train_inner | epoch 001:   3120 / 312876 loss=10.136, nll_loss=9.289, ppl=625.61, wps=11364.6, ups=29.37, wpb=386.9, bsz=14.3, num_updates=3120, lr=0.00039, gnorm=1.91, loss_scale=128, train_wall=0, wall=166
2024-12-12 04:49:00 | INFO | train_inner | epoch 001:   3130 / 312876 loss=10.138, nll_loss=9.286, ppl=624.42, wps=10530, ups=30.12, wpb=349.6, bsz=8.4, num_updates=3130, lr=0.00039125, gnorm=2.002, loss_scale=128, train_wall=0, wall=166
2024-12-12 04:49:00 | INFO | train_inner | epoch 001:   3140 / 312876 loss=10.22, nll_loss=9.395, ppl=673.18, wps=10449.6, ups=30.22, wpb=345.8, bsz=10.7, num_updates=3140, lr=0.0003925, gnorm=2.066, loss_scale=128, train_wall=0, wall=167
2024-12-12 04:49:00 | INFO | train_inner | epoch 001:   3150 / 312876 loss=10.297, nll_loss=9.471, ppl=709.5, wps=9773.1, ups=29.85, wpb=327.4, bsz=10.2, num_updates=3150, lr=0.00039375, gnorm=1.997, loss_scale=128, train_wall=0, wall=167
2024-12-12 04:49:01 | INFO | train_inner | epoch 001:   3160 / 312876 loss=10.312, nll_loss=9.489, ppl=718.58, wps=11117.5, ups=29.66, wpb=374.8, bsz=12.6, num_updates=3160, lr=0.000395, gnorm=2.031, loss_scale=128, train_wall=0, wall=167
2024-12-12 04:49:01 | INFO | train_inner | epoch 001:   3170 / 312876 loss=10.328, nll_loss=9.51, ppl=728.95, wps=11724.5, ups=28.43, wpb=412.4, bsz=14, num_updates=3170, lr=0.00039625, gnorm=1.791, loss_scale=128, train_wall=0, wall=168
2024-12-12 04:49:01 | INFO | train_inner | epoch 001:   3180 / 312876 loss=10.439, nll_loss=9.646, ppl=801.42, wps=11126.3, ups=28.4, wpb=391.8, bsz=13.4, num_updates=3180, lr=0.0003975, gnorm=2.031, loss_scale=128, train_wall=0, wall=168
2024-12-12 04:49:02 | INFO | train_inner | epoch 001:   3190 / 312876 loss=10.213, nll_loss=9.375, ppl=663.92, wps=10691.2, ups=28.8, wpb=371.2, bsz=14.4, num_updates=3190, lr=0.00039875, gnorm=1.958, loss_scale=128, train_wall=0, wall=168
2024-12-12 04:49:02 | INFO | train_inner | epoch 001:   3200 / 312876 loss=10.07, nll_loss=9.223, ppl=597.47, wps=9749.9, ups=28.91, wpb=337.3, bsz=13.2, num_updates=3200, lr=0.0004, gnorm=2.305, loss_scale=128, train_wall=0, wall=169
2024-12-12 04:49:02 | INFO | train_inner | epoch 001:   3210 / 312876 loss=10.144, nll_loss=9.301, ppl=630.99, wps=10638.1, ups=27.26, wpb=390.3, bsz=13.2, num_updates=3210, lr=0.00040125, gnorm=1.916, loss_scale=128, train_wall=0, wall=169
2024-12-12 04:49:03 | INFO | train_inner | epoch 001:   3220 / 312876 loss=10.614, nll_loss=9.837, ppl=914.55, wps=9461.6, ups=26.33, wpb=359.3, bsz=9.9, num_updates=3220, lr=0.0004025, gnorm=2.057, loss_scale=128, train_wall=0, wall=169
2024-12-12 04:49:03 | INFO | train_inner | epoch 001:   3230 / 312876 loss=10.147, nll_loss=9.321, ppl=639.71, wps=10647.7, ups=27.73, wpb=384, bsz=18.1, num_updates=3230, lr=0.00040375, gnorm=1.911, loss_scale=128, train_wall=0, wall=170
2024-12-12 04:49:04 | INFO | train_inner | epoch 001:   3240 / 312876 loss=10.418, nll_loss=9.611, ppl=781.94, wps=10615.4, ups=28.35, wpb=374.4, bsz=10, num_updates=3240, lr=0.000405, gnorm=2.044, loss_scale=128, train_wall=0, wall=170
2024-12-12 04:49:04 | INFO | train_inner | epoch 001:   3250 / 312876 loss=10.449, nll_loss=9.636, ppl=795.51, wps=11278.4, ups=27.78, wpb=406, bsz=10.8, num_updates=3250, lr=0.00040625, gnorm=1.955, loss_scale=128, train_wall=0, wall=170
2024-12-12 04:49:04 | INFO | train_inner | epoch 001:   3260 / 312876 loss=10.477, nll_loss=9.688, ppl=824.98, wps=9705.9, ups=29.16, wpb=332.8, bsz=11.2, num_updates=3260, lr=0.0004075, gnorm=2.041, loss_scale=128, train_wall=0, wall=171
2024-12-12 04:49:05 | INFO | train_inner | epoch 001:   3270 / 312876 loss=10.131, nll_loss=9.283, ppl=622.82, wps=10494.8, ups=28.43, wpb=369.1, bsz=11.8, num_updates=3270, lr=0.00040875, gnorm=1.908, loss_scale=128, train_wall=0, wall=171
2024-12-12 04:49:05 | INFO | train_inner | epoch 001:   3280 / 312876 loss=10.167, nll_loss=9.332, ppl=644.49, wps=10118.5, ups=28.36, wpb=356.8, bsz=12.8, num_updates=3280, lr=0.00041, gnorm=1.948, loss_scale=128, train_wall=0, wall=172
2024-12-12 04:49:05 | INFO | train_inner | epoch 001:   3290 / 312876 loss=10.377, nll_loss=9.566, ppl=758.05, wps=10791.9, ups=28.13, wpb=383.7, bsz=13.3, num_updates=3290, lr=0.00041125, gnorm=1.946, loss_scale=128, train_wall=0, wall=172
2024-12-12 04:49:06 | INFO | train_inner | epoch 001:   3300 / 312876 loss=9.981, nll_loss=9.11, ppl=552.49, wps=10952.1, ups=27.74, wpb=394.8, bsz=15.9, num_updates=3300, lr=0.0004125, gnorm=1.907, loss_scale=128, train_wall=0, wall=172
2024-12-12 04:49:06 | INFO | train_inner | epoch 001:   3310 / 312876 loss=10.652, nll_loss=9.885, ppl=945.6, wps=10138.2, ups=29.4, wpb=344.8, bsz=9.5, num_updates=3310, lr=0.00041375, gnorm=2.032, loss_scale=128, train_wall=0, wall=173
2024-12-12 04:49:06 | INFO | train_inner | epoch 001:   3320 / 312876 loss=9.917, nll_loss=9.044, ppl=527.8, wps=10710.6, ups=29.1, wpb=368, bsz=16.8, num_updates=3320, lr=0.000415, gnorm=2.045, loss_scale=128, train_wall=0, wall=173
2024-12-12 04:49:07 | INFO | train_inner | epoch 001:   3330 / 312876 loss=10.279, nll_loss=9.459, ppl=703.9, wps=12810.1, ups=28.96, wpb=442.4, bsz=14.4, num_updates=3330, lr=0.00041625, gnorm=1.769, loss_scale=128, train_wall=0, wall=173
2024-12-12 04:49:07 | INFO | train_inner | epoch 001:   3340 / 312876 loss=10.036, nll_loss=9.178, ppl=579.28, wps=12190.3, ups=29.16, wpb=418, bsz=16.5, num_updates=3340, lr=0.0004175, gnorm=1.863, loss_scale=128, train_wall=0, wall=174
2024-12-12 04:49:07 | INFO | train_inner | epoch 001:   3350 / 312876 loss=10.007, nll_loss=9.147, ppl=566.94, wps=11165.6, ups=29.38, wpb=380, bsz=17.4, num_updates=3350, lr=0.00041875, gnorm=1.971, loss_scale=128, train_wall=0, wall=174
2024-12-12 04:49:08 | INFO | train_inner | epoch 001:   3360 / 312876 loss=10.274, nll_loss=9.454, ppl=701.57, wps=11591.7, ups=29.25, wpb=396.3, bsz=11.1, num_updates=3360, lr=0.00042, gnorm=1.918, loss_scale=128, train_wall=0, wall=174
2024-12-12 04:49:08 | INFO | train_inner | epoch 001:   3370 / 312876 loss=10.046, nll_loss=9.192, ppl=584.92, wps=10981.1, ups=29.61, wpb=370.8, bsz=15.1, num_updates=3370, lr=0.00042125, gnorm=1.969, loss_scale=128, train_wall=0, wall=175
2024-12-12 04:49:08 | INFO | train_inner | epoch 001:   3380 / 312876 loss=10.187, nll_loss=9.353, ppl=653.77, wps=11105.1, ups=30.11, wpb=368.8, bsz=10.4, num_updates=3380, lr=0.0004225, gnorm=1.96, loss_scale=128, train_wall=0, wall=175
2024-12-12 04:49:09 | INFO | train_inner | epoch 001:   3390 / 312876 loss=10.202, nll_loss=9.364, ppl=658.99, wps=11125.9, ups=29.88, wpb=372.4, bsz=10.8, num_updates=3390, lr=0.00042375, gnorm=1.939, loss_scale=128, train_wall=0, wall=175
2024-12-12 04:49:09 | INFO | train_inner | epoch 001:   3400 / 312876 loss=9.985, nll_loss=9.12, ppl=556.46, wps=10668.6, ups=30.31, wpb=352, bsz=11.2, num_updates=3400, lr=0.000425, gnorm=1.962, loss_scale=128, train_wall=0, wall=176
2024-12-12 04:49:09 | INFO | train_inner | epoch 001:   3410 / 312876 loss=10.415, nll_loss=9.609, ppl=781.09, wps=12071.4, ups=29.2, wpb=413.4, bsz=10, num_updates=3410, lr=0.00042625, gnorm=2.057, loss_scale=128, train_wall=0, wall=176
2024-12-12 04:49:10 | INFO | train_inner | epoch 001:   3420 / 312876 loss=10.293, nll_loss=9.478, ppl=713.04, wps=10916.9, ups=29.79, wpb=366.4, bsz=11.2, num_updates=3420, lr=0.0004275, gnorm=1.943, loss_scale=128, train_wall=0, wall=176
2024-12-12 04:49:10 | INFO | train_inner | epoch 001:   3430 / 312876 loss=10.1, nll_loss=9.252, ppl=609.63, wps=10797.1, ups=29.4, wpb=367.2, bsz=13.6, num_updates=3430, lr=0.00042875, gnorm=1.972, loss_scale=128, train_wall=0, wall=177
2024-12-12 04:49:10 | INFO | train_inner | epoch 001:   3440 / 312876 loss=10.397, nll_loss=9.582, ppl=766.23, wps=10905.6, ups=30.16, wpb=361.6, bsz=9.6, num_updates=3440, lr=0.00043, gnorm=1.927, loss_scale=128, train_wall=0, wall=177
2024-12-12 04:49:11 | INFO | train_inner | epoch 001:   3450 / 312876 loss=10.116, nll_loss=9.271, ppl=617.76, wps=11870.7, ups=29.5, wpb=402.4, bsz=12.8, num_updates=3450, lr=0.00043125, gnorm=1.871, loss_scale=128, train_wall=0, wall=177
2024-12-12 04:49:11 | INFO | train_inner | epoch 001:   3460 / 312876 loss=9.903, nll_loss=9.032, ppl=523.65, wps=12034.8, ups=28.96, wpb=415.5, bsz=14.2, num_updates=3460, lr=0.0004325, gnorm=1.955, loss_scale=128, train_wall=0, wall=178
2024-12-12 04:49:11 | INFO | train_inner | epoch 001:   3470 / 312876 loss=10.112, nll_loss=9.269, ppl=617.03, wps=10775.8, ups=29.1, wpb=370.3, bsz=11.1, num_updates=3470, lr=0.00043375, gnorm=1.996, loss_scale=128, train_wall=0, wall=178
2024-12-12 04:49:12 | INFO | train_inner | epoch 001:   3480 / 312876 loss=10.37, nll_loss=9.553, ppl=751.14, wps=11100, ups=29.39, wpb=377.7, bsz=9.4, num_updates=3480, lr=0.000435, gnorm=1.92, loss_scale=128, train_wall=0, wall=178
2024-12-12 04:49:12 | INFO | train_inner | epoch 001:   3490 / 312876 loss=10.234, nll_loss=9.406, ppl=678.23, wps=11333.6, ups=29.47, wpb=384.6, bsz=14.1, num_updates=3490, lr=0.00043625, gnorm=1.88, loss_scale=128, train_wall=0, wall=179
2024-12-12 04:49:13 | INFO | train_inner | epoch 001:   3500 / 312876 loss=10.231, nll_loss=9.4, ppl=675.45, wps=10742.6, ups=29.59, wpb=363, bsz=11, num_updates=3500, lr=0.0004375, gnorm=2.005, loss_scale=128, train_wall=0, wall=179
2024-12-12 04:49:13 | INFO | train_inner | epoch 001:   3510 / 312876 loss=10.385, nll_loss=9.586, ppl=768.76, wps=11941.3, ups=29.15, wpb=409.7, bsz=12.6, num_updates=3510, lr=0.00043875, gnorm=2.126, loss_scale=128, train_wall=0, wall=179
2024-12-12 04:49:13 | INFO | train_inner | epoch 001:   3520 / 312876 loss=10.383, nll_loss=9.571, ppl=760.76, wps=10792.6, ups=29.34, wpb=367.8, bsz=12.5, num_updates=3520, lr=0.00044, gnorm=2.068, loss_scale=128, train_wall=0, wall=180
2024-12-12 04:49:13 | INFO | fairseq_cli.train | begin save checkpoint
2024-12-12 04:49:18 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 1 @ 3528 updates, score None) (writing took 4.408299433000138 seconds)
2024-12-12 04:49:18 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2024-12-12 04:49:18 | INFO | train | epoch 001 | loss 11.105 | nll_loss 10.382 | ppl 1334.49 | wps 10618.7 | ups 28.18 | wpb 376.9 | bsz 12.6 | num_updates 3528 | lr 0.000441 | gnorm 2.187 | loss_scale 128 | train_wall 118 | wall 184
2024-12-12 04:49:18 | INFO | fairseq_cli.train | done training in 125.5 seconds
