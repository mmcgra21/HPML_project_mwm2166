2024-12-12 06:01:54 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='transformer_wmt_en_de_big_t2t', attention_dropout=0.1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/tmp/wmt14_en_de/', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=1024, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.3, empty_cache_freq=0, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=True, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=False, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format='simple', log_interval=10, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=2048, max_tokens_valid=2048, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=True, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang=None, stop_time_hours=0.05, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, update_freq=[1], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, zero_sharding='none')
2024-12-12 06:01:54 | INFO | fairseq.tasks.translation | [en] dictionary: 40480 types
2024-12-12 06:01:54 | INFO | fairseq.tasks.translation | [de] dictionary: 42720 types
2024-12-12 06:01:54 | INFO | fairseq.data.data_utils | loaded 39414 examples from: /tmp/wmt14_en_de/valid.en-de.en
2024-12-12 06:01:54 | INFO | fairseq.data.data_utils | loaded 39414 examples from: /tmp/wmt14_en_de/valid.en-de.de
2024-12-12 06:01:54 | INFO | fairseq.tasks.translation | /tmp/wmt14_en_de/ valid en-de 39414 examples
2024-12-12 06:01:57 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(40480, 1024, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(42720, 1024, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=1024, out_features=42720, bias=False)
  )
)
2024-12-12 06:01:57 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2024-12-12 06:01:57 | INFO | fairseq_cli.train | model: transformer_wmt_en_de_big_t2t (TransformerModel)
2024-12-12 06:01:57 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2024-12-12 06:01:57 | INFO | fairseq_cli.train | num. model params: 305303552 (num. trained: 305303552)
2024-12-12 06:01:59 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-12-12 06:01:59 | INFO | fairseq.utils | rank   0: capabilities =  7.0  ; total memory = 15.782 GB ; name = Tesla V100-SXM2-16GB                    
2024-12-12 06:01:59 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-12-12 06:01:59 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2024-12-12 06:01:59 | INFO | fairseq_cli.train | max tokens per GPU = 2048 and max sentences per GPU = None
2024-12-12 06:01:59 | INFO | fairseq.trainer | no existing checkpoint found checkpoints/checkpoint_last.pt
2024-12-12 06:01:59 | INFO | fairseq.trainer | loading train data for epoch 1
2024-12-12 06:01:59 | INFO | fairseq.data.data_utils | loaded 3900502 examples from: /tmp/wmt14_en_de/train.en-de.en
2024-12-12 06:01:59 | INFO | fairseq.data.data_utils | loaded 3900502 examples from: /tmp/wmt14_en_de/train.en-de.de
2024-12-12 06:01:59 | INFO | fairseq.tasks.translation | /tmp/wmt14_en_de/ train en-de 3900502 examples
2024-12-12 06:02:03 | INFO | fairseq.optim.adam | using FusedAdam
2024-12-12 06:02:03 | INFO | fairseq.trainer | begin training epoch 1
2024-12-12 06:02:05 | INFO | train_inner | epoch 001:     10 / 65628 loss=16.1, nll_loss=16.1, ppl=70217.3, wps=14494.2, ups=8.78, wpb=1687.2, bsz=52, num_updates=10, lr=1.25e-06, gnorm=4.879, loss_scale=128, train_wall=2, wall=6
2024-12-12 06:02:06 | INFO | train_inner | epoch 001:     20 / 65628 loss=16.015, nll_loss=16.005, ppl=65756.6, wps=19021.2, ups=10.55, wpb=1803.4, bsz=55.2, num_updates=20, lr=2.5e-06, gnorm=5.047, loss_scale=128, train_wall=1, wall=7
2024-12-12 06:02:06 | INFO | train_inner | epoch 001:     30 / 65628 loss=15.722, nll_loss=15.68, ppl=52488.8, wps=19836.7, ups=10.67, wpb=1859.2, bsz=64.8, num_updates=30, lr=3.75e-06, gnorm=5.076, loss_scale=128, train_wall=1, wall=8
2024-12-12 06:02:07 | INFO | train_inner | epoch 001:     40 / 65628 loss=15.232, nll_loss=15.134, ppl=35968.8, wps=18923.6, ups=10.73, wpb=1764.2, bsz=68, num_updates=40, lr=5e-06, gnorm=4.9, loss_scale=128, train_wall=1, wall=9
2024-12-12 06:02:08 | INFO | train_inner | epoch 001:     50 / 65628 loss=14.535, nll_loss=14.352, ppl=20907.4, wps=19588.1, ups=10.86, wpb=1803.2, bsz=60, num_updates=50, lr=6.25e-06, gnorm=3.313, loss_scale=128, train_wall=1, wall=10
2024-12-12 06:02:09 | INFO | train_inner | epoch 001:     60 / 65628 loss=14.082, nll_loss=13.841, ppl=14672.4, wps=18591.2, ups=10.74, wpb=1730.4, bsz=59.2, num_updates=60, lr=7.5e-06, gnorm=2.8, loss_scale=128, train_wall=1, wall=10
2024-12-12 06:02:10 | INFO | train_inner | epoch 001:     70 / 65628 loss=13.938, nll_loss=13.678, ppl=13105.9, wps=19694.9, ups=10.85, wpb=1814.4, bsz=60.8, num_updates=70, lr=8.75e-06, gnorm=2.21, loss_scale=128, train_wall=1, wall=11
2024-12-12 06:02:11 | INFO | train_inner | epoch 001:     80 / 65628 loss=13.795, nll_loss=13.518, ppl=11727.8, wps=18857, ups=10.54, wpb=1789.1, bsz=44.8, num_updates=80, lr=1e-05, gnorm=2.03, loss_scale=128, train_wall=1, wall=12
2024-12-12 06:02:12 | INFO | train_inner | epoch 001:     90 / 65628 loss=13.514, nll_loss=13.211, ppl=9483.35, wps=18529.6, ups=9.85, wpb=1881.6, bsz=86.4, num_updates=90, lr=1.125e-05, gnorm=2.385, loss_scale=128, train_wall=1, wall=13
2024-12-12 06:02:13 | INFO | train_inner | epoch 001:    100 / 65628 loss=13.441, nll_loss=13.121, ppl=8910.42, wps=19029.8, ups=11.13, wpb=1710, bsz=38.4, num_updates=100, lr=1.25e-05, gnorm=2.41, loss_scale=128, train_wall=1, wall=14
2024-12-12 06:02:14 | INFO | train_inner | epoch 001:    110 / 65628 loss=13.185, nll_loss=12.843, ppl=7345.18, wps=19865.7, ups=10.69, wpb=1859, bsz=100.8, num_updates=110, lr=1.375e-05, gnorm=2.349, loss_scale=128, train_wall=1, wall=15
2024-12-12 06:02:15 | INFO | train_inner | epoch 001:    120 / 65628 loss=13.139, nll_loss=12.785, ppl=7059.57, wps=19658.7, ups=11.12, wpb=1768.1, bsz=47.2, num_updates=120, lr=1.5e-05, gnorm=2.366, loss_scale=128, train_wall=1, wall=16
2024-12-12 06:02:16 | INFO | train_inner | epoch 001:    130 / 65628 loss=12.958, nll_loss=12.59, ppl=6166.74, wps=19851.5, ups=10.94, wpb=1814.4, bsz=65.6, num_updates=130, lr=1.625e-05, gnorm=1.972, loss_scale=128, train_wall=1, wall=17
2024-12-12 06:02:17 | INFO | train_inner | epoch 001:    140 / 65628 loss=12.867, nll_loss=12.483, ppl=5726.74, wps=18978.2, ups=10.07, wpb=1884, bsz=60, num_updates=140, lr=1.75e-05, gnorm=1.463, loss_scale=128, train_wall=1, wall=18
2024-12-12 06:02:18 | INFO | train_inner | epoch 001:    150 / 65628 loss=12.717, nll_loss=12.318, ppl=5104.53, wps=18473.7, ups=10.44, wpb=1769.5, bsz=56.8, num_updates=150, lr=1.875e-05, gnorm=1.531, loss_scale=128, train_wall=1, wall=19
2024-12-12 06:02:19 | INFO | train_inner | epoch 001:    160 / 65628 loss=12.65, nll_loss=12.24, ppl=4837.83, wps=20477.7, ups=10.8, wpb=1896.7, bsz=48, num_updates=160, lr=2e-05, gnorm=1.371, loss_scale=128, train_wall=1, wall=20
2024-12-12 06:02:20 | INFO | train_inner | epoch 001:    170 / 65628 loss=12.597, nll_loss=12.179, ppl=4636.82, wps=20216.9, ups=11.02, wpb=1834.6, bsz=47.2, num_updates=170, lr=2.125e-05, gnorm=1.298, loss_scale=128, train_wall=1, wall=21
2024-12-12 06:02:21 | INFO | train_inner | epoch 001:    180 / 65628 loss=12.332, nll_loss=11.881, ppl=3771.94, wps=18142.3, ups=10.57, wpb=1716, bsz=56, num_updates=180, lr=2.25e-05, gnorm=1.384, loss_scale=128, train_wall=1, wall=22
2024-12-12 06:02:21 | INFO | train_inner | epoch 001:    190 / 65628 loss=12.342, nll_loss=11.886, ppl=3784.47, wps=20019.7, ups=10.71, wpb=1869.6, bsz=55.2, num_updates=190, lr=2.375e-05, gnorm=1.218, loss_scale=128, train_wall=1, wall=23
2024-12-12 06:02:22 | INFO | train_inner | epoch 001:    200 / 65628 loss=12.258, nll_loss=11.791, ppl=3542.82, wps=18040.9, ups=10.85, wpb=1662.9, bsz=51.2, num_updates=200, lr=2.5e-05, gnorm=1.385, loss_scale=128, train_wall=1, wall=24
2024-12-12 06:02:23 | INFO | train_inner | epoch 001:    210 / 65628 loss=12.114, nll_loss=11.621, ppl=3150.45, wps=19410.3, ups=10.18, wpb=1906.4, bsz=60, num_updates=210, lr=2.625e-05, gnorm=1.241, loss_scale=128, train_wall=1, wall=25
2024-12-12 06:02:24 | INFO | train_inner | epoch 001:    220 / 65628 loss=12.032, nll_loss=11.526, ppl=2949.82, wps=18910, ups=10.93, wpb=1729.6, bsz=57.6, num_updates=220, lr=2.75e-05, gnorm=1.343, loss_scale=128, train_wall=1, wall=25
2024-12-12 06:02:25 | INFO | train_inner | epoch 001:    230 / 65628 loss=11.916, nll_loss=11.391, ppl=2684.67, wps=20478.7, ups=10.8, wpb=1896.9, bsz=75.2, num_updates=230, lr=2.875e-05, gnorm=2.252, loss_scale=128, train_wall=1, wall=26
2024-12-12 06:02:26 | INFO | train_inner | epoch 001:    240 / 65628 loss=11.815, nll_loss=11.268, ppl=2466.6, wps=18826.9, ups=11.12, wpb=1693, bsz=70.4, num_updates=240, lr=3e-05, gnorm=1.998, loss_scale=128, train_wall=1, wall=27
2024-12-12 06:02:27 | INFO | train_inner | epoch 001:    250 / 65628 loss=11.65, nll_loss=11.081, ppl=2166.14, wps=18864.7, ups=10.65, wpb=1771.1, bsz=83.2, num_updates=250, lr=3.125e-05, gnorm=1.768, loss_scale=128, train_wall=1, wall=28
2024-12-12 06:02:28 | INFO | train_inner | epoch 001:    260 / 65628 loss=11.756, nll_loss=11.191, ppl=2338.52, wps=19391.7, ups=10.66, wpb=1818.8, bsz=62.4, num_updates=260, lr=3.25e-05, gnorm=1.58, loss_scale=128, train_wall=1, wall=29
2024-12-12 06:02:29 | INFO | train_inner | epoch 001:    270 / 65628 loss=11.667, nll_loss=11.089, ppl=2178.59, wps=19604, ups=10.97, wpb=1787.2, bsz=64, num_updates=270, lr=3.375e-05, gnorm=1.345, loss_scale=128, train_wall=1, wall=30
2024-12-12 06:02:30 | INFO | train_inner | epoch 001:    280 / 65628 loss=11.702, nll_loss=11.123, ppl=2229.7, wps=19299.5, ups=10.44, wpb=1849.1, bsz=53.6, num_updates=280, lr=3.5e-05, gnorm=1.401, loss_scale=128, train_wall=1, wall=31
2024-12-12 06:02:31 | INFO | train_inner | epoch 001:    290 / 65628 loss=11.622, nll_loss=11.026, ppl=2085.56, wps=19306.3, ups=10.78, wpb=1790.4, bsz=68, num_updates=290, lr=3.625e-05, gnorm=1.291, loss_scale=128, train_wall=1, wall=32
2024-12-12 06:02:32 | INFO | train_inner | epoch 001:    300 / 65628 loss=11.549, nll_loss=10.937, ppl=1960.97, wps=20100.4, ups=10.33, wpb=1945.6, bsz=84, num_updates=300, lr=3.75e-05, gnorm=1.466, loss_scale=128, train_wall=1, wall=33
2024-12-12 06:02:33 | INFO | train_inner | epoch 001:    310 / 65628 loss=11.474, nll_loss=10.856, ppl=1853, wps=18714.4, ups=10.26, wpb=1823.2, bsz=70.4, num_updates=310, lr=3.875e-05, gnorm=1.606, loss_scale=128, train_wall=1, wall=34
2024-12-12 06:02:34 | INFO | train_inner | epoch 001:    320 / 65628 loss=11.644, nll_loss=11.04, ppl=2105.62, wps=19780.3, ups=10.71, wpb=1847.2, bsz=53.6, num_updates=320, lr=4e-05, gnorm=1.539, loss_scale=128, train_wall=1, wall=35
2024-12-12 06:02:35 | INFO | train_inner | epoch 001:    330 / 65628 loss=11.446, nll_loss=10.816, ppl=1802.54, wps=19361.2, ups=10.7, wpb=1808.8, bsz=78.4, num_updates=330, lr=4.125e-05, gnorm=1.86, loss_scale=128, train_wall=1, wall=36
2024-12-12 06:02:35 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 64.0
2024-12-12 06:02:36 | INFO | train_inner | epoch 001:    341 / 65628 loss=11.529, nll_loss=10.904, ppl=1916.08, wps=18158, ups=10.09, wpb=1799.5, bsz=56, num_updates=340, lr=4.25e-05, gnorm=1.866, loss_scale=64, train_wall=1, wall=37
2024-12-12 06:02:37 | INFO | train_inner | epoch 001:    351 / 65628 loss=11.472, nll_loss=10.835, ppl=1826.46, wps=19739.6, ups=10.54, wpb=1873.6, bsz=62.4, num_updates=350, lr=4.375e-05, gnorm=1.963, loss_scale=64, train_wall=1, wall=38
2024-12-12 06:02:37 | INFO | train_inner | epoch 001:    361 / 65628 loss=11.385, nll_loss=10.738, ppl=1707.59, wps=19800.1, ups=10.83, wpb=1828, bsz=59.2, num_updates=360, lr=4.5e-05, gnorm=1.433, loss_scale=64, train_wall=1, wall=39
2024-12-12 06:02:38 | INFO | train_inner | epoch 001:    371 / 65628 loss=11.557, nll_loss=10.929, ppl=1949.69, wps=18632.3, ups=11.12, wpb=1675.7, bsz=42.4, num_updates=370, lr=4.625e-05, gnorm=1.514, loss_scale=64, train_wall=1, wall=40
2024-12-12 06:02:39 | INFO | train_inner | epoch 001:    381 / 65628 loss=11.329, nll_loss=10.67, ppl=1629.56, wps=19028.2, ups=10.78, wpb=1765.6, bsz=55.2, num_updates=380, lr=4.75e-05, gnorm=1.336, loss_scale=64, train_wall=1, wall=40
2024-12-12 06:02:40 | INFO | train_inner | epoch 001:    391 / 65628 loss=11.441, nll_loss=10.797, ppl=1778.66, wps=18406, ups=10.69, wpb=1721, bsz=53.6, num_updates=390, lr=4.875e-05, gnorm=1.679, loss_scale=64, train_wall=1, wall=41
2024-12-12 06:02:41 | INFO | train_inner | epoch 001:    401 / 65628 loss=11.3, nll_loss=10.633, ppl=1587.82, wps=19542.6, ups=10.75, wpb=1818.4, bsz=73.6, num_updates=400, lr=5e-05, gnorm=1.569, loss_scale=64, train_wall=1, wall=42
2024-12-12 06:02:42 | INFO | train_inner | epoch 001:    411 / 65628 loss=11.322, nll_loss=10.658, ppl=1615.28, wps=20044.9, ups=10.98, wpb=1825.6, bsz=72, num_updates=410, lr=5.125e-05, gnorm=1.644, loss_scale=64, train_wall=1, wall=43
2024-12-12 06:02:43 | INFO | train_inner | epoch 001:    421 / 65628 loss=11.348, nll_loss=10.681, ppl=1642.19, wps=19060.3, ups=10.73, wpb=1776, bsz=75.2, num_updates=420, lr=5.25e-05, gnorm=2.21, loss_scale=64, train_wall=1, wall=44
2024-12-12 06:02:44 | INFO | train_inner | epoch 001:    431 / 65628 loss=11.245, nll_loss=10.563, ppl=1512.66, wps=19590.5, ups=10.4, wpb=1883.2, bsz=70.4, num_updates=430, lr=5.375e-05, gnorm=1.386, loss_scale=64, train_wall=1, wall=45
2024-12-12 06:02:45 | INFO | train_inner | epoch 001:    441 / 65628 loss=11.411, nll_loss=10.754, ppl=1726.87, wps=18850.4, ups=10.65, wpb=1769.6, bsz=54.4, num_updates=440, lr=5.5e-05, gnorm=1.368, loss_scale=64, train_wall=1, wall=46
2024-12-12 06:02:46 | INFO | train_inner | epoch 001:    451 / 65628 loss=11.289, nll_loss=10.615, ppl=1568.79, wps=19448.7, ups=10.74, wpb=1810.4, bsz=58.4, num_updates=450, lr=5.625e-05, gnorm=1.259, loss_scale=64, train_wall=1, wall=47
2024-12-12 06:02:47 | INFO | train_inner | epoch 001:    461 / 65628 loss=11.263, nll_loss=10.584, ppl=1534.51, wps=19192.4, ups=10.65, wpb=1801.6, bsz=64, num_updates=460, lr=5.75e-05, gnorm=1.563, loss_scale=64, train_wall=1, wall=48
2024-12-12 06:02:48 | INFO | train_inner | epoch 001:    471 / 65628 loss=11.317, nll_loss=10.649, ppl=1605.59, wps=19175.2, ups=10.78, wpb=1778.2, bsz=56.8, num_updates=470, lr=5.875e-05, gnorm=1.513, loss_scale=64, train_wall=1, wall=49
2024-12-12 06:02:49 | INFO | train_inner | epoch 001:    481 / 65628 loss=11.306, nll_loss=10.633, ppl=1588.05, wps=19604.2, ups=10.77, wpb=1819.6, bsz=48.8, num_updates=480, lr=6e-05, gnorm=1.535, loss_scale=64, train_wall=1, wall=50
2024-12-12 06:02:50 | INFO | train_inner | epoch 001:    491 / 65628 loss=11.275, nll_loss=10.596, ppl=1547.72, wps=19635.5, ups=10.56, wpb=1858.9, bsz=56, num_updates=490, lr=6.125e-05, gnorm=1.34, loss_scale=64, train_wall=1, wall=51
2024-12-12 06:02:50 | INFO | train_inner | epoch 001:    501 / 65628 loss=11.314, nll_loss=10.644, ppl=1600.46, wps=18969, ups=10.74, wpb=1766, bsz=46.4, num_updates=500, lr=6.25e-05, gnorm=1.306, loss_scale=64, train_wall=1, wall=52
2024-12-12 06:02:51 | INFO | train_inner | epoch 001:    511 / 65628 loss=10.971, nll_loss=10.249, ppl=1217.23, wps=19849, ups=10.37, wpb=1913.6, bsz=85.6, num_updates=510, lr=6.375e-05, gnorm=2.088, loss_scale=64, train_wall=1, wall=53
2024-12-12 06:02:52 | INFO | train_inner | epoch 001:    521 / 65628 loss=11.223, nll_loss=10.536, ppl=1484.54, wps=19850.5, ups=10.84, wpb=1831.2, bsz=55.2, num_updates=520, lr=6.5e-05, gnorm=1.62, loss_scale=64, train_wall=1, wall=54
2024-12-12 06:02:53 | INFO | train_inner | epoch 001:    531 / 65628 loss=11.246, nll_loss=10.564, ppl=1513.97, wps=18623.4, ups=10.79, wpb=1726.2, bsz=52, num_updates=530, lr=6.625e-05, gnorm=1.407, loss_scale=64, train_wall=1, wall=55
2024-12-12 06:02:54 | INFO | train_inner | epoch 001:    541 / 65628 loss=11.197, nll_loss=10.507, ppl=1455.39, wps=19240.2, ups=10.67, wpb=1804, bsz=56, num_updates=540, lr=6.75e-05, gnorm=1.466, loss_scale=64, train_wall=1, wall=55
2024-12-12 06:02:55 | INFO | train_inner | epoch 001:    551 / 65628 loss=11.194, nll_loss=10.506, ppl=1453.74, wps=19804.2, ups=10.94, wpb=1809.6, bsz=50.4, num_updates=550, lr=6.875e-05, gnorm=1.974, loss_scale=64, train_wall=1, wall=56
2024-12-12 06:02:56 | INFO | train_inner | epoch 001:    561 / 65628 loss=11.231, nll_loss=10.54, ppl=1489.21, wps=18600.4, ups=10.62, wpb=1751.9, bsz=45.6, num_updates=560, lr=7e-05, gnorm=1.339, loss_scale=64, train_wall=1, wall=57
2024-12-12 06:02:57 | INFO | train_inner | epoch 001:    571 / 65628 loss=11.26, nll_loss=10.577, ppl=1528.07, wps=18938.8, ups=10.8, wpb=1754.1, bsz=40.8, num_updates=570, lr=7.125e-05, gnorm=1.282, loss_scale=64, train_wall=1, wall=58
2024-12-12 06:02:58 | INFO | train_inner | epoch 001:    581 / 65628 loss=11.146, nll_loss=10.452, ppl=1401.04, wps=19730.5, ups=10.82, wpb=1823.2, bsz=48.8, num_updates=580, lr=7.25e-05, gnorm=1.301, loss_scale=64, train_wall=1, wall=59
2024-12-12 06:02:59 | INFO | train_inner | epoch 001:    591 / 65628 loss=10.984, nll_loss=10.268, ppl=1232.63, wps=19341.8, ups=10.69, wpb=1808.8, bsz=68, num_updates=590, lr=7.375e-05, gnorm=1.378, loss_scale=64, train_wall=1, wall=60
2024-12-12 06:03:00 | INFO | train_inner | epoch 001:    601 / 65628 loss=10.953, nll_loss=10.223, ppl=1195.03, wps=19879, ups=10.69, wpb=1859.2, bsz=80.8, num_updates=600, lr=7.5e-05, gnorm=2.105, loss_scale=64, train_wall=1, wall=61
2024-12-12 06:03:01 | INFO | train_inner | epoch 001:    611 / 65628 loss=11.088, nll_loss=10.38, ppl=1332.33, wps=19280.8, ups=10.65, wpb=1811.2, bsz=60, num_updates=610, lr=7.625e-05, gnorm=1.628, loss_scale=64, train_wall=1, wall=62
2024-12-12 06:03:02 | INFO | train_inner | epoch 001:    621 / 65628 loss=11.145, nll_loss=10.443, ppl=1391.75, wps=18866.7, ups=10.87, wpb=1735.2, bsz=39.2, num_updates=620, lr=7.75e-05, gnorm=1.606, loss_scale=64, train_wall=1, wall=63
2024-12-12 06:03:03 | INFO | train_inner | epoch 001:    631 / 65628 loss=10.972, nll_loss=10.256, ppl=1223.06, wps=19307.3, ups=10.05, wpb=1920.8, bsz=70.4, num_updates=630, lr=7.875e-05, gnorm=1.648, loss_scale=64, train_wall=1, wall=64
2024-12-12 06:03:04 | INFO | train_inner | epoch 001:    641 / 65628 loss=10.879, nll_loss=10.148, ppl=1134.29, wps=19149.5, ups=10.71, wpb=1788, bsz=70.4, num_updates=640, lr=8e-05, gnorm=1.553, loss_scale=64, train_wall=1, wall=65
2024-12-12 06:03:05 | INFO | train_inner | epoch 001:    651 / 65628 loss=11.034, nll_loss=10.312, ppl=1271.04, wps=18664.1, ups=10.3, wpb=1811.2, bsz=53.6, num_updates=650, lr=8.125e-05, gnorm=1.676, loss_scale=64, train_wall=1, wall=66
2024-12-12 06:03:06 | INFO | train_inner | epoch 001:    661 / 65628 loss=11.05, nll_loss=10.341, ppl=1296.86, wps=18256.6, ups=10.79, wpb=1692.7, bsz=55.2, num_updates=660, lr=8.25e-05, gnorm=1.476, loss_scale=64, train_wall=1, wall=67
2024-12-12 06:03:06 | INFO | train_inner | epoch 001:    671 / 65628 loss=10.882, nll_loss=10.149, ppl=1135.48, wps=18315.6, ups=10.63, wpb=1723.8, bsz=62.4, num_updates=670, lr=8.375e-05, gnorm=1.272, loss_scale=64, train_wall=1, wall=68
2024-12-12 06:03:07 | INFO | train_inner | epoch 001:    681 / 65628 loss=10.866, nll_loss=10.135, ppl=1124.33, wps=17776.3, ups=9.59, wpb=1853.2, bsz=60, num_updates=680, lr=8.5e-05, gnorm=1.193, loss_scale=64, train_wall=1, wall=69
2024-12-12 06:03:08 | INFO | train_inner | epoch 001:    691 / 65628 loss=11.025, nll_loss=10.311, ppl=1270.38, wps=18513.3, ups=10.93, wpb=1694.2, bsz=47.2, num_updates=690, lr=8.625e-05, gnorm=1.206, loss_scale=64, train_wall=1, wall=70
2024-12-12 06:03:09 | INFO | train_inner | epoch 001:    701 / 65628 loss=10.918, nll_loss=10.189, ppl=1167.16, wps=19488.3, ups=10.65, wpb=1830.4, bsz=60, num_updates=700, lr=8.75e-05, gnorm=1.272, loss_scale=64, train_wall=1, wall=71
2024-12-12 06:03:10 | INFO | train_inner | epoch 001:    711 / 65628 loss=10.987, nll_loss=10.269, ppl=1233.58, wps=18267.8, ups=10.85, wpb=1683.2, bsz=43.2, num_updates=710, lr=8.875e-05, gnorm=1.453, loss_scale=64, train_wall=1, wall=71
2024-12-12 06:03:11 | INFO | train_inner | epoch 001:    721 / 65628 loss=10.842, nll_loss=10.103, ppl=1099.88, wps=18825.9, ups=10.94, wpb=1720.1, bsz=56, num_updates=720, lr=9e-05, gnorm=1.654, loss_scale=64, train_wall=1, wall=72
2024-12-12 06:03:12 | INFO | train_inner | epoch 001:    731 / 65628 loss=10.915, nll_loss=10.187, ppl=1166.1, wps=18590.4, ups=10.46, wpb=1776.8, bsz=48, num_updates=730, lr=9.125e-05, gnorm=1.387, loss_scale=64, train_wall=1, wall=73
2024-12-12 06:03:13 | INFO | train_inner | epoch 001:    741 / 65628 loss=10.646, nll_loss=9.882, ppl=943.6, wps=17978.3, ups=10.54, wpb=1705.6, bsz=73.6, num_updates=740, lr=9.25e-05, gnorm=1.736, loss_scale=64, train_wall=1, wall=74
2024-12-12 06:03:14 | INFO | train_inner | epoch 001:    751 / 65628 loss=11.051, nll_loss=10.339, ppl=1295.15, wps=18025.6, ups=10.62, wpb=1697.7, bsz=39.2, num_updates=750, lr=9.375e-05, gnorm=1.586, loss_scale=64, train_wall=1, wall=75
2024-12-12 06:03:15 | INFO | train_inner | epoch 001:    761 / 65628 loss=10.643, nll_loss=9.878, ppl=941.22, wps=19823.5, ups=10.73, wpb=1848, bsz=67.2, num_updates=760, lr=9.5e-05, gnorm=1.417, loss_scale=64, train_wall=1, wall=76
2024-12-12 06:03:16 | INFO | train_inner | epoch 001:    771 / 65628 loss=10.721, nll_loss=9.962, ppl=997.27, wps=19485.6, ups=10.61, wpb=1836, bsz=54.4, num_updates=770, lr=9.625e-05, gnorm=1.223, loss_scale=64, train_wall=1, wall=77
2024-12-12 06:03:17 | INFO | train_inner | epoch 001:    781 / 65628 loss=10.697, nll_loss=9.941, ppl=982.89, wps=19509.6, ups=10.58, wpb=1843.3, bsz=50.4, num_updates=780, lr=9.75e-05, gnorm=1.16, loss_scale=64, train_wall=1, wall=78
2024-12-12 06:03:18 | INFO | train_inner | epoch 001:    791 / 65628 loss=10.788, nll_loss=10.045, ppl=1056.5, wps=18950.9, ups=10.79, wpb=1756.7, bsz=56.8, num_updates=790, lr=9.875e-05, gnorm=1.289, loss_scale=64, train_wall=1, wall=79
2024-12-12 06:03:19 | INFO | train_inner | epoch 001:    801 / 65628 loss=10.668, nll_loss=9.906, ppl=959.43, wps=19388.9, ups=10.68, wpb=1815.2, bsz=66.4, num_updates=800, lr=0.0001, gnorm=1.601, loss_scale=64, train_wall=1, wall=80
2024-12-12 06:03:20 | INFO | train_inner | epoch 001:    811 / 65628 loss=10.764, nll_loss=10.009, ppl=1030.53, wps=19715.2, ups=10.62, wpb=1857.1, bsz=61.6, num_updates=810, lr=0.00010125, gnorm=1.344, loss_scale=64, train_wall=1, wall=81
2024-12-12 06:03:21 | INFO | train_inner | epoch 001:    821 / 65628 loss=10.636, nll_loss=9.869, ppl=935.44, wps=19248.7, ups=11.1, wpb=1733.5, bsz=64.8, num_updates=820, lr=0.0001025, gnorm=1.445, loss_scale=64, train_wall=1, wall=82
2024-12-12 06:03:22 | INFO | train_inner | epoch 001:    831 / 65628 loss=10.69, nll_loss=9.927, ppl=973.4, wps=18915.7, ups=10.6, wpb=1784, bsz=50.4, num_updates=830, lr=0.00010375, gnorm=1.341, loss_scale=64, train_wall=1, wall=83
2024-12-12 06:03:22 | INFO | train_inner | epoch 001:    841 / 65628 loss=10.533, nll_loss=9.75, ppl=861.26, wps=18329, ups=10.81, wpb=1695.3, bsz=60, num_updates=840, lr=0.000105, gnorm=1.509, loss_scale=64, train_wall=1, wall=84
2024-12-12 06:03:23 | INFO | train_inner | epoch 001:    851 / 65628 loss=10.766, nll_loss=10.01, ppl=1030.78, wps=19080.6, ups=10.84, wpb=1760.5, bsz=54.4, num_updates=850, lr=0.00010625, gnorm=1.399, loss_scale=64, train_wall=1, wall=85
2024-12-12 06:03:24 | INFO | train_inner | epoch 001:    861 / 65628 loss=10.413, nll_loss=9.618, ppl=785.93, wps=19063, ups=10.94, wpb=1742.4, bsz=68.8, num_updates=860, lr=0.0001075, gnorm=1.333, loss_scale=64, train_wall=1, wall=85
2024-12-12 06:03:25 | INFO | train_inner | epoch 001:    871 / 65628 loss=10.45, nll_loss=9.655, ppl=806.14, wps=18754.6, ups=10.98, wpb=1708, bsz=62.4, num_updates=870, lr=0.00010875, gnorm=1.397, loss_scale=64, train_wall=1, wall=86
2024-12-12 06:03:26 | INFO | train_inner | epoch 001:    881 / 65628 loss=10.277, nll_loss=9.464, ppl=706.06, wps=19188.7, ups=10.47, wpb=1832.8, bsz=79.2, num_updates=880, lr=0.00011, gnorm=1.417, loss_scale=64, train_wall=1, wall=87
2024-12-12 06:03:27 | INFO | train_inner | epoch 001:    891 / 65628 loss=10.529, nll_loss=9.74, ppl=855, wps=18625.4, ups=10.62, wpb=1754.4, bsz=51.2, num_updates=890, lr=0.00011125, gnorm=1.338, loss_scale=64, train_wall=1, wall=88
2024-12-12 06:03:28 | INFO | train_inner | epoch 001:    901 / 65628 loss=10.258, nll_loss=9.443, ppl=695.8, wps=19852.7, ups=10.74, wpb=1848.8, bsz=77.6, num_updates=900, lr=0.0001125, gnorm=1.152, loss_scale=64, train_wall=1, wall=89
2024-12-12 06:03:29 | INFO | train_inner | epoch 001:    911 / 65628 loss=10.35, nll_loss=9.543, ppl=745.85, wps=18600.7, ups=10.68, wpb=1742, bsz=56, num_updates=910, lr=0.00011375, gnorm=1.341, loss_scale=64, train_wall=1, wall=90
2024-12-12 06:03:30 | INFO | train_inner | epoch 001:    921 / 65628 loss=10.059, nll_loss=9.214, ppl=593.78, wps=19488.1, ups=10.55, wpb=1846.4, bsz=91.2, num_updates=920, lr=0.000115, gnorm=1.417, loss_scale=64, train_wall=1, wall=91
2024-12-12 06:03:31 | INFO | train_inner | epoch 001:    931 / 65628 loss=10.428, nll_loss=9.629, ppl=792.04, wps=18982.4, ups=10.54, wpb=1800.8, bsz=41.6, num_updates=930, lr=0.00011625, gnorm=1.15, loss_scale=64, train_wall=1, wall=92
2024-12-12 06:03:32 | INFO | train_inner | epoch 001:    941 / 65628 loss=10.373, nll_loss=9.571, ppl=760.76, wps=19631.3, ups=10.9, wpb=1801, bsz=54.4, num_updates=940, lr=0.0001175, gnorm=1.25, loss_scale=64, train_wall=1, wall=93
2024-12-12 06:03:33 | INFO | train_inner | epoch 001:    951 / 65628 loss=10.439, nll_loss=9.641, ppl=798.41, wps=20463.8, ups=11.04, wpb=1852.8, bsz=58.4, num_updates=950, lr=0.00011875, gnorm=1.461, loss_scale=64, train_wall=1, wall=94
2024-12-12 06:03:34 | INFO | train_inner | epoch 001:    961 / 65628 loss=10.326, nll_loss=9.517, ppl=732.6, wps=19459.6, ups=10.22, wpb=1904.8, bsz=56, num_updates=960, lr=0.00012, gnorm=1.165, loss_scale=64, train_wall=1, wall=95
2024-12-12 06:03:35 | INFO | train_inner | epoch 001:    971 / 65628 loss=10.086, nll_loss=9.236, ppl=603.08, wps=19798.8, ups=10.66, wpb=1856.5, bsz=88.8, num_updates=970, lr=0.00012125, gnorm=1.914, loss_scale=64, train_wall=1, wall=96
2024-12-12 06:03:36 | INFO | train_inner | epoch 001:    981 / 65628 loss=9.876, nll_loss=9.004, ppl=513.48, wps=18446.3, ups=10.11, wpb=1824, bsz=99.2, num_updates=980, lr=0.0001225, gnorm=1.327, loss_scale=64, train_wall=1, wall=97
2024-12-12 06:03:36 | INFO | train_inner | epoch 001:    991 / 65628 loss=10.603, nll_loss=9.83, ppl=909.92, wps=19092.9, ups=10.8, wpb=1767.5, bsz=48.8, num_updates=990, lr=0.00012375, gnorm=1.35, loss_scale=64, train_wall=1, wall=98
2024-12-12 06:03:37 | INFO | train_inner | epoch 001:   1001 / 65628 loss=10.306, nll_loss=9.487, ppl=717.64, wps=18835.7, ups=10.98, wpb=1715, bsz=59.2, num_updates=1000, lr=0.000125, gnorm=1.435, loss_scale=64, train_wall=1, wall=99
2024-12-12 06:03:38 | INFO | train_inner | epoch 001:   1011 / 65628 loss=9.965, nll_loss=9.107, ppl=551.46, wps=19403, ups=10.7, wpb=1814.2, bsz=84, num_updates=1010, lr=0.00012625, gnorm=1.402, loss_scale=64, train_wall=1, wall=100
2024-12-12 06:03:39 | INFO | train_inner | epoch 001:   1021 / 65628 loss=10.252, nll_loss=9.427, ppl=688.5, wps=19213.1, ups=10.59, wpb=1814.6, bsz=77.6, num_updates=1020, lr=0.0001275, gnorm=1.682, loss_scale=64, train_wall=1, wall=101
2024-12-12 06:03:40 | INFO | train_inner | epoch 001:   1031 / 65628 loss=10.356, nll_loss=9.548, ppl=748.73, wps=17974.2, ups=10.61, wpb=1694.8, bsz=48.8, num_updates=1030, lr=0.00012875, gnorm=1.301, loss_scale=64, train_wall=1, wall=101
2024-12-12 06:03:41 | INFO | train_inner | epoch 001:   1041 / 65628 loss=10.272, nll_loss=9.452, ppl=700.57, wps=18719.4, ups=10.92, wpb=1714.1, bsz=46.4, num_updates=1040, lr=0.00013, gnorm=1.119, loss_scale=64, train_wall=1, wall=102
2024-12-12 06:03:42 | INFO | train_inner | epoch 001:   1051 / 65628 loss=10.019, nll_loss=9.163, ppl=573.13, wps=18130.4, ups=10.95, wpb=1656, bsz=68.8, num_updates=1050, lr=0.00013125, gnorm=1.15, loss_scale=64, train_wall=1, wall=103
2024-12-12 06:03:43 | INFO | train_inner | epoch 001:   1061 / 65628 loss=10.309, nll_loss=9.496, ppl=722.14, wps=18279.6, ups=11.25, wpb=1624.9, bsz=47.2, num_updates=1060, lr=0.0001325, gnorm=1.311, loss_scale=64, train_wall=1, wall=104
2024-12-12 06:03:44 | INFO | train_inner | epoch 001:   1071 / 65628 loss=10.134, nll_loss=9.292, ppl=626.72, wps=19453.6, ups=10.44, wpb=1864, bsz=67.2, num_updates=1070, lr=0.00013375, gnorm=1.279, loss_scale=64, train_wall=1, wall=105
2024-12-12 06:03:45 | INFO | train_inner | epoch 001:   1081 / 65628 loss=10.261, nll_loss=9.438, ppl=693.51, wps=19613.2, ups=10.94, wpb=1792.8, bsz=68, num_updates=1080, lr=0.000135, gnorm=1.401, loss_scale=64, train_wall=1, wall=106
2024-12-12 06:03:46 | INFO | train_inner | epoch 001:   1091 / 65628 loss=10.271, nll_loss=9.45, ppl=699.36, wps=19367.2, ups=10.8, wpb=1792.8, bsz=55.2, num_updates=1090, lr=0.00013625, gnorm=1.427, loss_scale=64, train_wall=1, wall=107
2024-12-12 06:03:47 | INFO | train_inner | epoch 001:   1101 / 65628 loss=10.3, nll_loss=9.48, ppl=714.14, wps=19522.6, ups=10.69, wpb=1825.7, bsz=51.2, num_updates=1100, lr=0.0001375, gnorm=1.217, loss_scale=64, train_wall=1, wall=108
2024-12-12 06:03:48 | INFO | train_inner | epoch 001:   1111 / 65628 loss=9.977, nll_loss=9.111, ppl=553.03, wps=18605.8, ups=10.63, wpb=1750.4, bsz=63.2, num_updates=1110, lr=0.00013875, gnorm=1.282, loss_scale=64, train_wall=1, wall=109
2024-12-12 06:03:49 | INFO | train_inner | epoch 001:   1121 / 65628 loss=10.088, nll_loss=9.242, ppl=605.54, wps=19845.6, ups=10.46, wpb=1896.4, bsz=60, num_updates=1120, lr=0.00014, gnorm=1.166, loss_scale=64, train_wall=1, wall=110
2024-12-12 06:03:50 | INFO | train_inner | epoch 001:   1131 / 65628 loss=9.932, nll_loss=9.067, ppl=536.25, wps=19869.2, ups=10.69, wpb=1859.2, bsz=72, num_updates=1130, lr=0.00014125, gnorm=1.277, loss_scale=64, train_wall=1, wall=111
2024-12-12 06:03:50 | INFO | train_inner | epoch 001:   1141 / 65628 loss=10.064, nll_loss=9.213, ppl=593.66, wps=18993, ups=10.79, wpb=1760, bsz=58.4, num_updates=1140, lr=0.0001425, gnorm=1.218, loss_scale=64, train_wall=1, wall=112
2024-12-12 06:03:51 | INFO | train_inner | epoch 001:   1151 / 65628 loss=10.114, nll_loss=9.276, ppl=619.95, wps=18876.8, ups=10.79, wpb=1748.8, bsz=45.6, num_updates=1150, lr=0.00014375, gnorm=1.334, loss_scale=64, train_wall=1, wall=113
2024-12-12 06:03:52 | INFO | train_inner | epoch 001:   1161 / 65628 loss=10.104, nll_loss=9.255, ppl=611.05, wps=19222.5, ups=10.97, wpb=1752.8, bsz=43.2, num_updates=1160, lr=0.000145, gnorm=1.197, loss_scale=64, train_wall=1, wall=113
2024-12-12 06:03:53 | INFO | train_inner | epoch 001:   1171 / 65628 loss=10.125, nll_loss=9.284, ppl=623.56, wps=20603.3, ups=10.91, wpb=1888.8, bsz=62.4, num_updates=1170, lr=0.00014625, gnorm=1.239, loss_scale=64, train_wall=1, wall=114
2024-12-12 06:03:54 | INFO | train_inner | epoch 001:   1181 / 65628 loss=10.208, nll_loss=9.375, ppl=664.16, wps=20600.3, ups=10.96, wpb=1879.1, bsz=51.2, num_updates=1180, lr=0.0001475, gnorm=1.244, loss_scale=64, train_wall=1, wall=115
2024-12-12 06:03:55 | INFO | train_inner | epoch 001:   1191 / 65628 loss=10.059, nll_loss=9.209, ppl=591.65, wps=18670.5, ups=10.68, wpb=1748.7, bsz=54.4, num_updates=1190, lr=0.00014875, gnorm=1.307, loss_scale=64, train_wall=1, wall=116
2024-12-12 06:03:56 | INFO | train_inner | epoch 001:   1201 / 65628 loss=10.168, nll_loss=9.334, ppl=645.22, wps=18718.7, ups=10.63, wpb=1760.6, bsz=60, num_updates=1200, lr=0.00015, gnorm=1.45, loss_scale=64, train_wall=1, wall=117
2024-12-12 06:03:57 | INFO | train_inner | epoch 001:   1211 / 65628 loss=10.056, nll_loss=9.2, ppl=588.12, wps=19821.8, ups=10.59, wpb=1871.2, bsz=60.8, num_updates=1210, lr=0.00015125, gnorm=1.119, loss_scale=64, train_wall=1, wall=118
2024-12-12 06:03:58 | INFO | train_inner | epoch 001:   1221 / 65628 loss=9.955, nll_loss=9.085, ppl=542.99, wps=19653.9, ups=10.72, wpb=1832.8, bsz=52.8, num_updates=1220, lr=0.0001525, gnorm=1.145, loss_scale=64, train_wall=1, wall=119
2024-12-12 06:03:59 | INFO | train_inner | epoch 001:   1231 / 65628 loss=9.957, nll_loss=9.097, ppl=547.49, wps=18457.6, ups=10.73, wpb=1719.4, bsz=46.4, num_updates=1230, lr=0.00015375, gnorm=1.121, loss_scale=64, train_wall=1, wall=120
2024-12-12 06:04:00 | INFO | train_inner | epoch 001:   1241 / 65628 loss=9.928, nll_loss=9.06, ppl=533.69, wps=18898, ups=10.62, wpb=1779.4, bsz=67.2, num_updates=1240, lr=0.000155, gnorm=1.401, loss_scale=64, train_wall=1, wall=121
2024-12-12 06:04:01 | INFO | train_inner | epoch 001:   1251 / 65628 loss=9.932, nll_loss=9.058, ppl=532.85, wps=19258.5, ups=10.86, wpb=1774.1, bsz=53.6, num_updates=1250, lr=0.00015625, gnorm=1.284, loss_scale=64, train_wall=1, wall=122
2024-12-12 06:04:02 | INFO | train_inner | epoch 001:   1261 / 65628 loss=9.74, nll_loss=8.842, ppl=458.88, wps=19325.3, ups=10.48, wpb=1843.2, bsz=81.6, num_updates=1260, lr=0.0001575, gnorm=1.273, loss_scale=64, train_wall=1, wall=123
2024-12-12 06:04:03 | INFO | train_inner | epoch 001:   1271 / 65628 loss=10.003, nll_loss=9.144, ppl=565.76, wps=18305.8, ups=10.68, wpb=1713.9, bsz=56, num_updates=1270, lr=0.00015875, gnorm=1.332, loss_scale=64, train_wall=1, wall=124
2024-12-12 06:04:04 | INFO | train_inner | epoch 001:   1281 / 65628 loss=9.896, nll_loss=9.023, ppl=520.29, wps=18132.8, ups=10.53, wpb=1722.2, bsz=51.2, num_updates=1280, lr=0.00016, gnorm=1.184, loss_scale=64, train_wall=1, wall=125
2024-12-12 06:04:04 | INFO | train_inner | epoch 001:   1291 / 65628 loss=9.774, nll_loss=8.881, ppl=471.39, wps=19223.4, ups=10.81, wpb=1777.6, bsz=57.6, num_updates=1290, lr=0.00016125, gnorm=1.229, loss_scale=64, train_wall=1, wall=126
2024-12-12 06:04:05 | INFO | train_inner | epoch 001:   1301 / 65628 loss=9.959, nll_loss=9.092, ppl=545.66, wps=20449.5, ups=10.94, wpb=1868.6, bsz=62.4, num_updates=1300, lr=0.0001625, gnorm=1.128, loss_scale=64, train_wall=1, wall=127
2024-12-12 06:04:06 | INFO | train_inner | epoch 001:   1311 / 65628 loss=9.574, nll_loss=8.659, ppl=404.15, wps=19957.8, ups=10.73, wpb=1859.2, bsz=94.4, num_updates=1310, lr=0.00016375, gnorm=1.495, loss_scale=64, train_wall=1, wall=127
2024-12-12 06:04:07 | INFO | train_inner | epoch 001:   1321 / 65628 loss=10.175, nll_loss=9.337, ppl=646.52, wps=18479.9, ups=11.12, wpb=1662, bsz=38.4, num_updates=1320, lr=0.000165, gnorm=1.316, loss_scale=64, train_wall=1, wall=128
2024-12-12 06:04:08 | INFO | train_inner | epoch 001:   1331 / 65628 loss=10.006, nll_loss=9.141, ppl=564.55, wps=19233, ups=10.74, wpb=1791.2, bsz=58.4, num_updates=1330, lr=0.00016625, gnorm=1.301, loss_scale=64, train_wall=1, wall=129
2024-12-12 06:04:09 | INFO | train_inner | epoch 001:   1341 / 65628 loss=9.671, nll_loss=8.769, ppl=436.25, wps=18077.9, ups=10.49, wpb=1724, bsz=82.4, num_updates=1340, lr=0.0001675, gnorm=1.384, loss_scale=64, train_wall=1, wall=130
2024-12-12 06:04:10 | INFO | train_inner | epoch 001:   1351 / 65628 loss=10.201, nll_loss=9.364, ppl=659.04, wps=16264.6, ups=9.41, wpb=1729.2, bsz=36, num_updates=1350, lr=0.00016875, gnorm=1.196, loss_scale=64, train_wall=1, wall=131
2024-12-12 06:04:11 | INFO | train_inner | epoch 001:   1361 / 65628 loss=9.804, nll_loss=8.911, ppl=481.41, wps=20149.8, ups=10.59, wpb=1902.4, bsz=50.4, num_updates=1360, lr=0.00017, gnorm=1.056, loss_scale=64, train_wall=1, wall=132
2024-12-12 06:04:12 | INFO | train_inner | epoch 001:   1371 / 65628 loss=9.855, nll_loss=8.978, ppl=504.08, wps=18559.7, ups=10.63, wpb=1745.3, bsz=71.2, num_updates=1370, lr=0.00017125, gnorm=1.225, loss_scale=64, train_wall=1, wall=133
2024-12-12 06:04:13 | INFO | train_inner | epoch 001:   1381 / 65628 loss=10.014, nll_loss=9.149, ppl=567.79, wps=18429.6, ups=10.6, wpb=1739, bsz=38.4, num_updates=1380, lr=0.0001725, gnorm=1.298, loss_scale=64, train_wall=1, wall=134
2024-12-12 06:04:14 | INFO | train_inner | epoch 001:   1391 / 65628 loss=9.839, nll_loss=8.951, ppl=494.93, wps=18607.2, ups=10.83, wpb=1718, bsz=49.6, num_updates=1390, lr=0.00017375, gnorm=1.136, loss_scale=64, train_wall=1, wall=135
2024-12-12 06:04:15 | INFO | train_inner | epoch 001:   1401 / 65628 loss=9.878, nll_loss=9.005, ppl=513.68, wps=19604.2, ups=10.64, wpb=1842.4, bsz=50.4, num_updates=1400, lr=0.000175, gnorm=1.073, loss_scale=64, train_wall=1, wall=136
2024-12-12 06:04:16 | INFO | train_inner | epoch 001:   1411 / 65628 loss=9.845, nll_loss=8.959, ppl=497.59, wps=19088.2, ups=11.01, wpb=1733.2, bsz=59.2, num_updates=1410, lr=0.00017625, gnorm=1.36, loss_scale=64, train_wall=1, wall=137
2024-12-12 06:04:17 | INFO | train_inner | epoch 001:   1421 / 65628 loss=9.829, nll_loss=8.942, ppl=491.72, wps=18925.4, ups=10.93, wpb=1732, bsz=51.2, num_updates=1420, lr=0.0001775, gnorm=1.336, loss_scale=64, train_wall=1, wall=138
2024-12-12 06:04:18 | INFO | train_inner | epoch 001:   1431 / 65628 loss=9.652, nll_loss=8.741, ppl=427.85, wps=19207.6, ups=10.82, wpb=1774.8, bsz=68, num_updates=1430, lr=0.00017875, gnorm=1.382, loss_scale=64, train_wall=1, wall=139
2024-12-12 06:04:19 | INFO | train_inner | epoch 001:   1441 / 65628 loss=9.998, nll_loss=9.136, ppl=562.66, wps=19055.6, ups=10.64, wpb=1790.3, bsz=47.2, num_updates=1440, lr=0.00018, gnorm=1.252, loss_scale=64, train_wall=1, wall=140
2024-12-12 06:04:19 | INFO | train_inner | epoch 001:   1451 / 65628 loss=9.538, nll_loss=8.613, ppl=391.49, wps=19418, ups=10.44, wpb=1859.8, bsz=75.2, num_updates=1450, lr=0.00018125, gnorm=1.356, loss_scale=64, train_wall=1, wall=141
2024-12-12 06:04:20 | INFO | train_inner | epoch 001:   1461 / 65628 loss=9.741, nll_loss=8.843, ppl=459.3, wps=19026.7, ups=10.28, wpb=1850.4, bsz=49.6, num_updates=1460, lr=0.0001825, gnorm=1.176, loss_scale=64, train_wall=1, wall=142
2024-12-12 06:04:21 | INFO | train_inner | epoch 001:   1471 / 65628 loss=9.664, nll_loss=8.758, ppl=432.84, wps=18196.5, ups=10.03, wpb=1814.4, bsz=64.8, num_updates=1470, lr=0.00018375, gnorm=1.304, loss_scale=64, train_wall=1, wall=143
2024-12-12 06:04:22 | INFO | train_inner | epoch 001:   1481 / 65628 loss=9.451, nll_loss=8.515, ppl=365.7, wps=18342.1, ups=10.2, wpb=1797.6, bsz=88.8, num_updates=1480, lr=0.000185, gnorm=1.196, loss_scale=64, train_wall=1, wall=144
2024-12-12 06:04:23 | INFO | train_inner | epoch 001:   1491 / 65628 loss=10.057, nll_loss=9.205, ppl=590.04, wps=19697.7, ups=10.55, wpb=1866.2, bsz=51.2, num_updates=1490, lr=0.00018625, gnorm=1.453, loss_scale=64, train_wall=1, wall=145
2024-12-12 06:04:24 | INFO | train_inner | epoch 001:   1501 / 65628 loss=9.73, nll_loss=8.827, ppl=454.2, wps=19682.2, ups=10.6, wpb=1857.6, bsz=52, num_updates=1500, lr=0.0001875, gnorm=1.129, loss_scale=64, train_wall=1, wall=146
2024-12-12 06:04:25 | INFO | train_inner | epoch 001:   1511 / 65628 loss=9.728, nll_loss=8.823, ppl=452.82, wps=19101, ups=11.06, wpb=1726.6, bsz=48, num_updates=1510, lr=0.00018875, gnorm=1.1, loss_scale=64, train_wall=1, wall=146
2024-12-12 06:04:26 | INFO | train_inner | epoch 001:   1521 / 65628 loss=9.603, nll_loss=8.685, ppl=411.71, wps=19633.3, ups=10.5, wpb=1870.4, bsz=68.8, num_updates=1520, lr=0.00019, gnorm=1.149, loss_scale=64, train_wall=1, wall=147
2024-12-12 06:04:27 | INFO | train_inner | epoch 001:   1531 / 65628 loss=9.645, nll_loss=8.737, ppl=426.56, wps=18991, ups=10.66, wpb=1782.1, bsz=58.4, num_updates=1530, lr=0.00019125, gnorm=1.156, loss_scale=64, train_wall=1, wall=148
2024-12-12 06:04:28 | INFO | train_inner | epoch 001:   1541 / 65628 loss=9.668, nll_loss=8.762, ppl=434.07, wps=19546.6, ups=10.99, wpb=1778.4, bsz=63.2, num_updates=1540, lr=0.0001925, gnorm=1.117, loss_scale=64, train_wall=1, wall=149
2024-12-12 06:04:29 | INFO | train_inner | epoch 001:   1551 / 65628 loss=9.598, nll_loss=8.682, ppl=410.71, wps=17550.2, ups=10.65, wpb=1648.5, bsz=53.6, num_updates=1550, lr=0.00019375, gnorm=1.224, loss_scale=64, train_wall=1, wall=150
2024-12-12 06:04:30 | INFO | train_inner | epoch 001:   1561 / 65628 loss=9.785, nll_loss=8.893, ppl=475.33, wps=19174.8, ups=10.86, wpb=1765.4, bsz=52.8, num_updates=1560, lr=0.000195, gnorm=1.2, loss_scale=64, train_wall=1, wall=151
2024-12-12 06:04:31 | INFO | train_inner | epoch 001:   1571 / 65628 loss=9.346, nll_loss=8.398, ppl=337.21, wps=19652.2, ups=10.9, wpb=1802.4, bsz=80.8, num_updates=1570, lr=0.00019625, gnorm=1.216, loss_scale=64, train_wall=1, wall=152
2024-12-12 06:04:32 | INFO | train_inner | epoch 001:   1581 / 65628 loss=9.559, nll_loss=8.635, ppl=397.48, wps=19836.1, ups=10.8, wpb=1836.5, bsz=70.4, num_updates=1580, lr=0.0001975, gnorm=1.283, loss_scale=64, train_wall=1, wall=153
2024-12-12 06:04:33 | INFO | train_inner | epoch 001:   1591 / 65628 loss=9.543, nll_loss=8.615, ppl=392.01, wps=18884.4, ups=10.56, wpb=1788.8, bsz=61.6, num_updates=1590, lr=0.00019875, gnorm=1.242, loss_scale=64, train_wall=1, wall=154
2024-12-12 06:04:34 | INFO | train_inner | epoch 001:   1601 / 65628 loss=9.405, nll_loss=8.462, ppl=352.72, wps=19795.1, ups=10.53, wpb=1880, bsz=63.2, num_updates=1600, lr=0.0002, gnorm=1.043, loss_scale=64, train_wall=1, wall=155
2024-12-12 06:04:35 | INFO | train_inner | epoch 001:   1611 / 65628 loss=9.574, nll_loss=8.654, ppl=402.75, wps=19196.2, ups=10.47, wpb=1832.8, bsz=64, num_updates=1610, lr=0.00020125, gnorm=1.198, loss_scale=64, train_wall=1, wall=156
2024-12-12 06:04:35 | INFO | train_inner | epoch 001:   1621 / 65628 loss=9.767, nll_loss=8.87, ppl=467.81, wps=17995.8, ups=10.99, wpb=1636.8, bsz=52.8, num_updates=1620, lr=0.0002025, gnorm=1.388, loss_scale=64, train_wall=1, wall=157
2024-12-12 06:04:36 | INFO | train_inner | epoch 001:   1631 / 65628 loss=9.587, nll_loss=8.668, ppl=406.8, wps=17984.6, ups=10.66, wpb=1687.2, bsz=59.2, num_updates=1630, lr=0.00020375, gnorm=1.138, loss_scale=64, train_wall=1, wall=158
2024-12-12 06:04:37 | INFO | train_inner | epoch 001:   1641 / 65628 loss=9.434, nll_loss=8.498, ppl=361.48, wps=18506, ups=10.34, wpb=1789.6, bsz=60, num_updates=1640, lr=0.000205, gnorm=1.141, loss_scale=64, train_wall=1, wall=159
2024-12-12 06:04:38 | INFO | train_inner | epoch 001:   1651 / 65628 loss=9.517, nll_loss=8.586, ppl=384.33, wps=19073.5, ups=10.56, wpb=1805.9, bsz=48, num_updates=1650, lr=0.00020625, gnorm=1.089, loss_scale=64, train_wall=1, wall=160
2024-12-12 06:04:39 | INFO | train_inner | epoch 001:   1661 / 65628 loss=9.404, nll_loss=8.458, ppl=351.62, wps=19728.6, ups=10.58, wpb=1864.8, bsz=60.8, num_updates=1660, lr=0.0002075, gnorm=1.084, loss_scale=64, train_wall=1, wall=160
2024-12-12 06:04:40 | INFO | train_inner | epoch 001:   1671 / 65628 loss=9.398, nll_loss=8.453, ppl=350.46, wps=18182.9, ups=10.19, wpb=1784.8, bsz=59.2, num_updates=1670, lr=0.00020875, gnorm=1.132, loss_scale=64, train_wall=1, wall=161
2024-12-12 06:04:41 | INFO | train_inner | epoch 001:   1681 / 65628 loss=9.351, nll_loss=8.402, ppl=338.16, wps=18916.2, ups=10.62, wpb=1781.8, bsz=66.4, num_updates=1680, lr=0.00021, gnorm=1.204, loss_scale=64, train_wall=1, wall=162
2024-12-12 06:04:42 | INFO | train_inner | epoch 001:   1691 / 65628 loss=9.442, nll_loss=8.506, ppl=363.59, wps=19183.3, ups=10.65, wpb=1801.6, bsz=56, num_updates=1690, lr=0.00021125, gnorm=1.296, loss_scale=64, train_wall=1, wall=163
2024-12-12 06:04:43 | INFO | train_inner | epoch 001:   1701 / 65628 loss=9.666, nll_loss=8.75, ppl=430.45, wps=18662.8, ups=10.19, wpb=1830.9, bsz=52.8, num_updates=1700, lr=0.0002125, gnorm=1.293, loss_scale=64, train_wall=1, wall=164
2024-12-12 06:04:44 | INFO | train_inner | epoch 001:   1711 / 65628 loss=9.748, nll_loss=8.851, ppl=461.78, wps=19763.2, ups=10.44, wpb=1892.7, bsz=51.2, num_updates=1710, lr=0.00021375, gnorm=1.045, loss_scale=64, train_wall=1, wall=165
2024-12-12 06:04:45 | INFO | train_inner | epoch 001:   1721 / 65628 loss=9.288, nll_loss=8.325, ppl=320.7, wps=19188.1, ups=10.58, wpb=1814.3, bsz=66.4, num_updates=1720, lr=0.000215, gnorm=1.1, loss_scale=64, train_wall=1, wall=166
2024-12-12 06:04:46 | INFO | train_inner | epoch 001:   1731 / 65628 loss=9.494, nll_loss=8.562, ppl=378.06, wps=19352.4, ups=10.51, wpb=1841.5, bsz=67.2, num_updates=1730, lr=0.00021625, gnorm=1.333, loss_scale=64, train_wall=1, wall=167
2024-12-12 06:04:47 | INFO | train_inner | epoch 001:   1741 / 65628 loss=9.431, nll_loss=8.489, ppl=359.34, wps=18466.9, ups=10.31, wpb=1790.9, bsz=54.4, num_updates=1740, lr=0.0002175, gnorm=1.135, loss_scale=64, train_wall=1, wall=168
2024-12-12 06:04:48 | INFO | train_inner | epoch 001:   1751 / 65628 loss=9.515, nll_loss=8.582, ppl=383.25, wps=18730.3, ups=10.39, wpb=1802, bsz=53.6, num_updates=1750, lr=0.00021875, gnorm=1.114, loss_scale=64, train_wall=1, wall=169
2024-12-12 06:04:49 | INFO | train_inner | epoch 001:   1761 / 65628 loss=9.364, nll_loss=8.419, ppl=342.19, wps=18358.2, ups=10.56, wpb=1738.4, bsz=51.2, num_updates=1760, lr=0.00022, gnorm=1.222, loss_scale=64, train_wall=1, wall=170
2024-12-12 06:04:50 | INFO | train_inner | epoch 001:   1771 / 65628 loss=9.314, nll_loss=8.358, ppl=328.16, wps=19089.4, ups=10.6, wpb=1800.8, bsz=65.6, num_updates=1770, lr=0.00022125, gnorm=1.166, loss_scale=64, train_wall=1, wall=171
2024-12-12 06:04:51 | INFO | train_inner | epoch 001:   1781 / 65628 loss=9.191, nll_loss=8.217, ppl=297.47, wps=17826.5, ups=10.71, wpb=1664.8, bsz=64.8, num_updates=1780, lr=0.0002225, gnorm=1.346, loss_scale=64, train_wall=1, wall=172
2024-12-12 06:04:52 | INFO | train_inner | epoch 001:   1791 / 65628 loss=9.327, nll_loss=8.372, ppl=331.31, wps=19058.8, ups=10.7, wpb=1781.5, bsz=53.6, num_updates=1790, lr=0.00022375, gnorm=1.125, loss_scale=64, train_wall=1, wall=173
2024-12-12 06:04:53 | INFO | train_inner | epoch 001:   1801 / 65628 loss=9.286, nll_loss=8.329, ppl=321.65, wps=19176.3, ups=10.56, wpb=1816, bsz=77.6, num_updates=1800, lr=0.000225, gnorm=1.202, loss_scale=64, train_wall=1, wall=174
2024-12-12 06:04:54 | INFO | train_inner | epoch 001:   1811 / 65628 loss=9.179, nll_loss=8.202, ppl=294.45, wps=19739.8, ups=10.38, wpb=1900.8, bsz=76.8, num_updates=1810, lr=0.00022625, gnorm=1.105, loss_scale=64, train_wall=1, wall=175
2024-12-12 06:04:55 | INFO | train_inner | epoch 001:   1821 / 65628 loss=9.364, nll_loss=8.418, ppl=341.98, wps=19489.9, ups=10.53, wpb=1850.1, bsz=61.6, num_updates=1820, lr=0.0002275, gnorm=1.213, loss_scale=64, train_wall=1, wall=176
2024-12-12 06:04:55 | INFO | train_inner | epoch 001:   1831 / 65628 loss=9.337, nll_loss=8.383, ppl=333.78, wps=19171.1, ups=10.7, wpb=1792, bsz=48.8, num_updates=1830, lr=0.00022875, gnorm=1.229, loss_scale=64, train_wall=1, wall=177
2024-12-12 06:04:56 | INFO | train_inner | epoch 001:   1841 / 65628 loss=9.425, nll_loss=8.479, ppl=356.83, wps=19245.4, ups=10.94, wpb=1758.4, bsz=52, num_updates=1840, lr=0.00023, gnorm=1.365, loss_scale=64, train_wall=1, wall=178
2024-12-12 06:04:57 | INFO | train_inner | epoch 001:   1851 / 65628 loss=9.27, nll_loss=8.308, ppl=317, wps=19791.1, ups=10.72, wpb=1846.4, bsz=59.2, num_updates=1850, lr=0.00023125, gnorm=1.114, loss_scale=64, train_wall=1, wall=179
2024-12-12 06:04:58 | INFO | train_inner | epoch 001:   1861 / 65628 loss=9.437, nll_loss=8.499, ppl=361.69, wps=18569.6, ups=10.77, wpb=1723.5, bsz=57.6, num_updates=1860, lr=0.0002325, gnorm=1.188, loss_scale=64, train_wall=1, wall=179
2024-12-12 06:04:59 | INFO | fairseq_cli.train | begin save checkpoint
2024-12-12 06:05:04 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_last.pt (epoch 1 @ 1866 updates, score None) (writing took 5.538438992999545 seconds)
2024-12-12 06:05:04 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2024-12-12 06:05:04 | INFO | train | epoch 001 | loss 10.727 | nll_loss 9.98 | ppl 1009.92 | wps 18492.1 | ups 10.32 | wpb 1792.7 | bsz 60.1 | num_updates 1866 | lr 0.00023325 | gnorm 1.49 | loss_scale 64 | train_wall 171 | wall 186
2024-12-12 06:05:04 | INFO | fairseq_cli.train | done training in 181.7 seconds
